[
  {
    "content": "# Touch response\n\ntitle: Touch response\n\nThe `touch_response` plug-in allows you to work with touch responses (or mouse clicks) in an easy way, by dividing the display into rows and columns. Each response is encoded by a single number, which corresponds to the position counting from left-to-right and top-down. For example, if you have specified 2 columns and 3 rows, the display is divided into the following response regions:\n\n```bash\n1\t2\n3\t4\n5\t6\n```\n\nSimilarly, if you have specified 4 columns and 1 row, the display is sliced horizontally into the following response regions:\n\n```bash\n1\t2\t3\t4\n```",
    "title": "Touch response",
    "url": "https://osdoc.cogsci.nl/4.1/items/touch_response",
    "path": "content/pages/items/touch_response.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Advanced_delay\n\ntitle: Advanced_delay\n\nThe `advanced_delay` plug-in delays the experiment for a pre-specified average duration plus a random margin.\n\n- *Duration* is the average duration of the delay in milliseconds.\n- *Jitter* is the size of the variation in the delay in milliseconds.\n- *Jitter mode* is how the jitter is defined:\n\t- *Standard deviation* will draw values from a Gaussian distribution with Jitter as the standard deviation.\n\t- *Uniform* will draw values from a Uniform distribution centered at Duration, with Jitter as the width.",
    "title": "Advanced_delay",
    "url": "https://osdoc.cogsci.nl/4.1/items/advanced_delay",
    "path": "content/pages/items/advanced_delay.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Quest staircase next\n\ntitle: Quest staircase next\n\nProcesses a response and updates the Quest test value.",
    "title": "Quest staircase next",
    "url": "https://osdoc.cogsci.nl/4.1/items/quest_staircase_next",
    "path": "content/pages/items/quest_staircase_next.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Repeat_cycle\n\ntitle: Repeat_cycle\n\nThis plug-in allows you to repeat cycles from a `loop`. Most commonly, this will be to repeat a trial when a participant made a mistake or was too slow.\n\nFor example, to repeat all trials on which a response was slower than 3000 ms, you can add a `repeat_cycle` item after (typically) the `keyboard_response` and add the following repeat-if expression:\n\n```bash\nresponse_time > 3000\n```\n\nYou can also force a cycle to be repeated by setting the variable `repeat_cycle` to 1 in an `inline_script`, like so:\n\n```python\nrepeat_cycle = 1\n```",
    "title": "Repeat_cycle",
    "url": "https://osdoc.cogsci.nl/4.1/items/repeat_cycle",
    "path": "content/pages/items/repeat_cycle.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Reset_feedback\n\ntitle: Reset_feedback\n\nThis plug-in has the same effect as presenting a FEEDBACK item with a duration of 0 ms\n{: .page-notification}\n\nIf you do not reset feedback variables, you may confound your feedback with responses that are not relevant to the task. For example, the key presses made during the instruction phase may affect the feedback during the first block of the experiment. Therefore, you will need to reset the feedback variables at appropriate moments.\n\nThis plug-in will reset the following variables to 0:\n\n- `total_response_time`\n- `total_response`\n- `acc`\n- `accuracy`\n- `avg_rt`\n- `average_response_time`",
    "title": "Reset_feedback",
    "url": "https://osdoc.cogsci.nl/4.1/items/reset_feedback",
    "path": "content/pages/items/reset_feedback.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Quest staircase init\n\ntitle: Quest staircase init\n\nInitializes a new Quest staircase procedure.",
    "title": "Quest staircase init",
    "url": "https://osdoc.cogsci.nl/4.1/items/quest_staircase_init",
    "path": "content/pages/items/quest_staircase_init.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Runners\n\ntitle: Runners\n\n\n[TOC]\n\n\n## About runners\n\nThere are several technically different ways in which you can execute your experiment. Each of these corresponds to a *runner*. You can select a runner under Menu \u2192 Tools \u2192 Preferences \u2192 Runner.\n\nUnless you have a reason not to, you should use the *multiprocess* runner. However, if OpenSesame sometimes crashes, you can try whether selecting a different runner resolves this.\n\n\n## Available runners\n\n### Multiprocess\n\nThe *multiprocess* runner executes your experiment in a different process. The benefit of this approach is that your experiment can crash without bringing the user interface down with it. Another advantage of the *multiprocess* runner is that it allows the variable inspector to show your experimental variables while the experiment is running.\n\n### Inprocess\n\nThe *inprocess* runner executes the experiment in the same process as the user interface. The benefit of this approach is its simplicity. The downside is that the user interface may crash if the experiment crashes, and vice versa.\n\n### External\n\nThe *external* runner executes the experiment by launching opensesamerun as a separate application. The benefit of this approach is that your experiment can crash without bringing the user interface down with it.",
    "title": "Runners",
    "url": "https://osdoc.cogsci.nl/4.1/manual/runners",
    "path": "content/pages/manual/runners.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# OpenSesame script\n\ntitle: OpenSesame script\nreviewed: false\n\n[TOC]\n\n## About OpenSesame script\n\nOpenSesame script is a simple definitional language that defines an experiment. It is not a full fledged programming language, and does not include features such a `for` loops. The OpenSesame script is interpreted by an OpenSesame runtime environment.\n\nOpenSesame script is different from the Python scripts that are used in inline_script items. Python is a real programming language with all the flexibility and complexities that this entails. In contrast, OpenSesame script is used to define experiments in a simple, human-readable way.\n\n## General remarks\n\n### Keywords\n\nSome items, such as form_base and sketchpad accept keywords. Keywords are of the form `keyword=value`. Keywords are optional and should fall back to a default value.\n\n### Comments\n\nStrings preceded by a hash should be interpreted as comments.\n\n*Example*\n\n\t# This is a comment\n\n### Quotation\n\nQuotation is not necessary, except around strings that contain spaces or other forms of punctuation. So the following lines should be interpreted as identical:\n\n\tset my_var 'my_value'\n\tset my_var \"my_value\"\n\tset my_var my_value\n\nHowever, the following lines are not. In fact, the first line is not valid, because it has an unexpected third parameter.\n\n\tset my_var my value\n\tset my_var \"my value\"\n\n### Types\n\nThere are no types. No distinction is made between strings, integers, etc.\n\n### Item-specific syntax\n\nSome items have a specific syntax. This is indicated in the \u201cApplies to\u201d section for each of the keywords discussed below.\n\n### Resolving path names\n\nTODO\n\n## *define* statement\n\nStarts the definition of an item. After a define statement, all lines are indented by a single tab. The end of the item definition is the first string that is no longer indented. Nested define statements are not allowed.\n\n*Applies to*\n\nAll items\n\n*Format*\n\n\tdefine [item name] [item type]\n\t\t[item definition]\n\n*Parameters*\n\n|`item name`\t|the name of the item\t|\n|`item type`\t|the type of the item\t|\n\n*Example*\n\n\tdefine get_key keyboard_response\n\t\tset allowed_responses \"a;x\"\n\t\tset description \"Collects keyboard responses\"\n\t\tset timeout \"infinite\"\n\t\tset flush \"yes\"\n\n## *draw* statement\n\nDefines a visual element of a sketchpad or feedback item.\n\n*Applies to*\n\nsketchpad, feedback\n\n*Format*\n\nThe format depends on the element.\n\n\tdraw ellipse [left] [top] [width] [height] [keywords]\n\tdraw circle [x] [y] [radius] [keywords]\n\tdraw line [left] [right] [top] [bottom] [keywords]\n\tdraw arrow [left] [right] [top] [bottom] [keywords]\n\tdraw textline [x] [y] [text]\n\tdraw image [x] [y] [path]\n\tdraw gabor [x] [y]\n\tdraw noise [x] [y]\n\tdraw fixdot [x] [y]\n\n*Parameters*\n\n|`left` \t\t|the left-most x-coordinate\t\t|\n|`right`\t\t|the right-most x-coordinate\t|\n|`top`\t\t\t|the top y-coordinate\t\t\t|\n|`bottom`\t\t|the bottom y-coordinate\t\t|\n|`x` \t\t\t|the x-coordinate\t\t\t\t|\n|`y`\t\t\t|the y-coordinate\t\t\t\t|\n|`text` \t\t|text string\t\t\t\t\t|\n|`path` \t\t|the path to an image file\t\t|\n\n*Keywords*\n\nTODO\n\n*Example*\n\n\tdraw fixdot 0 0\n\n## *log* statement\n\nIndicates that a variable should be written to the log-file.\n\n*Applies to*\n\nlogger\n\n*Format*\n\n\tlog [variable name]\n\n*Parameters*\n\n|`variable name`\t\t|the name of a variable\t|\n\n*Example*\n\n\tlog response_time\n\n## *run* statement\n\nIndicates that an item should be run. In the case of the sequence, the order of the run statements determines the order in which items are called. In the case of the coroutines plugin all items are called at the same time.\n\n*Applies to*\n\nsequence\n\n*Format*\n\n\trun [item name] [optional: condition] [optional: disabled]\n\n*Parameters*\n\n|`item name`\t\t\t|the name of the item to run\t|\n|`condition` (optional)\t|the conditional statement, which determines the item is actually called. If no condition is provided, the item is always called.|\n\n*Example*\n\n\trun correct_feedback '[correct] = 1'\n\n## *set* statement\n\nDefines single-line variables.\n\n*Applies to*\n\nAll items\n\n*Format*\n\n\tset [variable name] [value]\n\n*Parameters*\n\n|`variable name`\t|the variable name\t|\n|`value`\t\t\t|the variable value\t|\n\n*Example*\n\n\tset timeout 1000\n\n*Notes*\n\nMulti-line variables are defined using the `__[variable name]__` notation. This is mostly useful for items that require large blocks of text. Within an item definition, each line is preceded by a single tab, which should not be interpreted as part of the text. `__end__` indicates the end of the variable.\n\n*For example:*\n\n\t__my_variable__\n\tThis is the first line.\n\tThis is the second line.\n\t__end__\n\n## *setcycle* statement\n\nSimilar to the regular \u201cset\u201d statement, but sets a variable only during a specific cycle of a loop. This is the script equivalent of the loop table.\n\n*Applies to*\n\nLoop\n\n*Format*\n\n\tsetcycle [cycle #] [variable name] [variable value]\n\n*Parameters*\n\n|`Cycle #`\t\t\t|the number of the cycle, where 0 is the first\t|\n|`variable name` \t|the variable name\t\t\t\t\t\t\t\t|\n|`value`\t\t\t|the variable value\t\t\t\t\t\t\t\t|\n\n*Example*\n\n\tsetcycle 0 cue valid\n\n## *widget* statement\n\nAdds a widget (buttons, labels, etc.) to a form. Valid keywords depend on the type of widget. The widget statement is not strictly part of the core OpenSesame syntax, but is used by the form_base plugin.\n\n*Applies to*\n\nform_base (plugin)\n\n*Format*\n\n\twidget [column] [row] [column span] [row span] [widget type] [keywords]\n\n*Parameters*\n\n|`column`\t\t|the widget's column position in the form, where 0 is left-most\t\t\t\t\t\t\t\t|\n|`row`\t\t\t|the widget's row position in the form, where 0 is top\t\t\t\t\t\t\t\t\t\t|\n|`column span`\t|the number of columns that the widget occupies\t\t\t\t\t\t\t\t\t\t\t\t|\n|`row span`\t\t|the number of rows that the widget occupies\t\t\t\t\t\t\t\t\t\t\t\t|\n|`widget type`\t|'button', 'checkbox', 'image', 'image_button', 'label', 'rating_scale', or 'text_input'\t|\n\n*Keywords*\n\nTODO\n\n*Example*\n\n\twidget 0 0 1 1 label text='This is a label'",
    "title": "OpenSesame script",
    "url": "https://osdoc.cogsci.nl/4.1/manual/opensesame-script",
    "path": "content/pages/manual/opensesame-script.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Counterbalancing\n\ntitle: Counterbalancing\n\nCounterbalancing is a way to remove confounding factors from an experiment by having slightly different tasks for different groups of participants. This sounds abstract, so let's consider two examples.\n\n[TOC]\n\n### Example 1: Counterbalancing response rule\n\nConsider a lexical-decision experiment in which participants classify words as verbs by pressing 'z' with their left hand, or as nouns by pressing 'm' with their right hand. This design has a problem: If you find that participants respond faster to nouns than to verbs, this could be because nouns are processed faster than verbs, or because participants respond faster with their right hand than with their left hand. You can fix this problem by counterbalancing the response rule.\n\nFor even participant numbers:\n\n- verb \u2192 z\n- noun \u2192 m\n\nFor uneven participant numbers:\n\n- verb \u2192 m\n- noun \u2192 z\n\n### Example 2: Rotating stimulus conditions\n\nConsider a masked-priming experiment in which participants read target words aloud. On each trial, the target word is preceded by one of three types of priming words:\n\n- An unrelated prime, e.g. priming with 'berry' for target 'house'.\n- An ortoghraphically related prime, e.g. priming with 'mouse' for target 'house'\n- A semantically related prime, e.g. priming with 'garden' for target 'house'\n\nTo avoid repetition effects, you only want to show target words only once per participant. Therefore, you create three different sets of target words, one for each prime type. This is a between-word design, which has less statistical power than a within-word design, in which each target word occurs in each condition. (For the same reason that between-subject designs are less powerful than within-subject designs.)\n\nYou can use counterbalancing to change this experiment into a within-word design by 'rotating' the condition in which each word occurs between participants. We have three conditions, and we therefore have three groups of participants:\n\n- Participants 1, 4, 7, etc.\n    - Word A in condition 1\n    - Word B in condition 2\n    - Word C in condition 3\n- Participants 2, 5, 8, etc.\n    - Word A in condition 2\n    - Word B in condition 3\n    - Word C in condition 1\n- Participants 3, 6, 9, etc.\n    - Word A in condition 3\n    - Word B in condition 1\n    - Word C in condition 2\n\n\n## Implementing counterbalancing\n\n\n### Using the subject number\n\nWhen you run an experiment in OpenSesame on the desktop, you are asked for a subject number. When you run an experiment online, a subject number is randomly selected from the list of possible subject numbers that you have specified in the [OSWeb extension](%url:osweb). (This means that for online experiments you cannot ensure that the number of participants is exactly equal for the different conditions that you want to counterbalance, at least not if you rely on the subject number.)\n\nThis subject number is available as the experimental variable `subject_nr`. In  addition, the experimental variable `subject_parity` has the value 'odd' or 'even', depending on whether the subject number is odd or even. Now say that you want to counterbalance the response rule as in Example 1, you could add the following INLINE_SCRIPT to the start of the experiment.\n\n```python\nif subject_parity == 'odd':\n    verb_response = 'z'\n    noun_response = 'm'\nelse:\n    verb_response = 'm'\n    noun_response = 'z'\n```\n\nOr, when creating an OSWeb experiment, add the following INLINE_JAVASCRIPT to the start of the experiment:\n\n```javascript\nif (subject_parity === 'odd') {\n    verb_response = 'z'\n    noun_response = 'm'\n} else {\n    verb_response = 'm'\n    noun_response = 'z'\n}\n```\n\nNow, in your *block_loop*, instead of setting `correct_response` to a fixed value, you set it to a variable: `{verb_response}` or `{noun_response}`. You can take a look at the *lexical-decision task* example to see how this works (Menu -> Tools -> Example experiments).\n\n\n### Using Batch Session Data (JATOS and OSWeb only)\n\nWhen running an OSWeb experiment that is hosted on JATOS, you can make use of [Batch Session Data](https://www.jatos.org/jatos.js-Reference.html#functions-to-access-the-batch-session). This is data that is shared between all experimental sessions that are part of the same worker batch. Therefore, you can use this data to define a list of conditions that should be distributed across participants. At the start of each experimental session, one condition is removed from this list and used for the current session. This is the most sophisticated way to implement counterbalancing for OSWeb experiments that are hosted on JATOS.\n\nYou can download a template experiment here:\n\n- %static:attachments/counterbalancing-osweb-jatos.osexp%\n\nWhen running from JATOS, the experiment retrieves a single condition from the Batch Session Data (see below) and registers this as the experimental variable `condition`. When doing a test run, `condition` is set to a default value specified at the end of *init_condition*.\n\nThe experiment itself should be implemented in the *experiment* SEQUENCE, which in the template contains only the *show_condition* SKETCHPAD (see %FigCounterbalancingOSWebJATOS).\n\n%--\nfigure:\n    source: counterbalancing-osweb-jatos.png\n    id: FigCounterbalancingOSWebJATOS\n    caption: |\n        The overview area of the template experiment for implementing counterbalancing with JATOS Batch Session Data.\n--%\n\nWhen importing the experiment into JATOS, all conditions should be specified in the Batch Session Data as the `pending` list (under Worker & Batch Manager; see %FigBatchSessionData). Each condition from `pending` corresponds to a single experimental session; therefore, if condition `a` should be used for two experimental sessions, then `a` needs to occur twice in the `pending` list. The conditions are used in the order in which they are defined.\n\n%--\nfigure:\n    source: batch-session-data.png\n    id: FigBatchSessionData\n    caption: |\n        The conditions should be specified in the Batch Session Data in JATOS.\n--%\n\nAt the start of an experimental session, a single condition is moved from `pending` to `started`. (When the `pending` list is empty, the participant is informed that he or she can no longer participate in the experiment.) At the end of the experimental session, the condition is appended to the `finished` list.\n\nTo make this more concrete, let's say that you've defined the Batch Session Data as shown in %FigBatchSessionData. Then, four experimental sessions are started, but the second experimental session, with condition `a`, never finishes, for example because the participant closes the browser halfway the experiment. The Batch Session Data will then look as in %FigBatchSessionAfter:\n\n%--\nfigure:\n    source: batch-session-data-after.png\n    id: FigBatchSessionAfter\n    caption: |\n        The Batch Session Data after all conditions have been consumed. One session, with condition `a`, never finished.\n--%\n\nYou can tell from the Batch Session Data that one experimental session started with condition `a` but never finished. To nevertheless collect an experimental session with this condition, you have to manually add a new `a` to the `pending` list and collect a new session.",
    "title": "Counterbalancing",
    "url": "https://osdoc.cogsci.nl/4.1/manual/counterbalancing",
    "path": "content/pages/manual/counterbalancing.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Variables\n\ntitle: Variables\n\n[TOC]\n\n## What is an experimental variable in OpenSesame?\n\nExperimental variables in OpenSesame are those variables that:\n\n- You can refer to in the user interface with the '{variable_name}' syntax.\n- Are available as global variables in a Python INLINE_SCRIPT.\n- Are available as global variables in a JavaScript INLINE_JAVASCRIPT.\n- Contain things like:\n\t- The variables that you have defined in a LOOP item.\n\t- The responses that you have collected.\n\t- Various properties of the experiment.\n\t- Etc.\n\n## The variable inspector\n\nThe variable inspector (`Ctrl+I`) provides an overview of available variables (%FigVariableInspector). When the experiment is not running, this overview is based on a best guess of which variables will become available during the experiment. However, when the experiment is running, the variable inspector shows a live overview of variables and their values. This is useful for debugging your experiment.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: The variable inspector provides an overview of all variables that OpenSesame knows about.\n--%\n\n## Defining variables\n\nThe simplest way to define a variable is through the LOOP item. For example, %FigLoop shows how to define a variable named `gaze_cue`. In this example, *trial_sequence* item is called four times while `gaze_cue` is 'left' and another four times while 'gaze_cue' is 'right'.\n\n%--\nfigure:\n id: FigLoop\n source: defining-variables-in-a-loop.png\n caption: The most common way to define independent variables is using the LOOP table.\n--%\n\n## Built-in variables\n\nThe following variables are always available:\n\n### Experiment variables\n\n|Variable name\t\t\t|Description|\n|-----------------------|-----------|\n|`title`\t\t\t\t|The title of the experiment|\n|`description`\t\t\t|The description of the experiment|\n|`foreground`\t\t\t|The default foreground color. E.g., 'white' or '#FFFFFF'.|\n|`background`\t\t\t|The default background color. E.g., 'black' or '#000000'.|\n|`height`\t\t\t\t|The height-part of the display resolution. E.g., '768'|\n|`width`\t\t\t\t|The width-part of the display resolution. E.g., '1024'|\n|`subject_nr`\t\t\t|The subject number, which is asked when the experiment is started.|\n|`subject_parity`\t\t|Is 'odd' if `subject_nr` is odd and 'even' if `subject_nr` is even. Useful for counterbalancing.|\n|`experiment_path`\t\t|The folder of the current experiment, without the experiment filename itself. If the experiment is unsaved, it has the value `None`.|\n|`pool_folder`\t\t\t|The folder where the contents of the file pool have been extracted to. This is generally a temporary folder.|\n|`logfile`\t\t\t\t|The path to the logfile.|\n\n### Item variables\n\nThere are also variables that keep track of all the items in the experiment.\n\n|Variable name\t\t\t|Description|\n|-----------------------|-----------|\n|`time_[item_name]`\t\t|Contains a timestamp of when the item was last executed. For SKETCHPAD items, this can be used to verify the timing of display presentation.|\n|`count_[item_name]`\t|Is equal the number of times minus one (starting at 0, in other words) that an item has been called. This can, for example, be used as a trial or block counter.|\n\n### Response variables\n\nWhen you use the standard response items, such as the KEYBOARD_RESPONSE and MOUSE_RESPONSE, a number of variables are set based on the participant's response.\n\n|Variable name\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`response`\t\t\t\t\t\t|Contains the last response that has been given.|\n|`response_[item_name]`\t\t\t|Contains the last response for a specific response item. This is useful in case there are multiple response items.|\n|`response_time`\t\t\t\t|Contains the interval in milliseconds between the start of the response interval and the last response.|\n|`response_time_[item_name]`\t|Contains the response time for a specific response item.|\n|`correct`\t\t\t\t\t\t|Is set to '1' if the last `response` matches the variable `correct_response`, '0' if not, and 'undefined' if the variable `correct_response` has not been set.|\n|`correct_[item_name]`\t\t\t|As `correct` but for a specifc response item.|\n\n### Feedback variables\n\nFeedback variables maintain a running average of accuracy and response times.\n\n|Variable name\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`average_response_time`\t\t|The average response time. This is variable is useful for presenting feedback to the participant.|\n|`avg_rt`\t\t\t\t\t\t|Synonym for `average_response_time`|\n|`accuracy`\t\t\t\t\t\t|The average percentage of correct responses. This is variable is useful for presenting feedback to the participant.|\n|`acc`\t\t\t\t\t\t\t|Synonym for `accuracy`|\n\n\n## Using variables in the user interface\n\nWherever you see a value in the user interface, you can replace that value by a variable using the '{variable name}' notation. For example, if you have defined a variable `soa` in a LOOP item, you can use this variable for the duration of a sketchpad as shown in %FigSketchpad.\n\n%--\nfigure:\n id: FigSketchpad\n source: variable-duration.png\n caption: The duration '{soa}' indicates that the duration of the SKETCHPAD depends on the variable `soa`.\n--%\n\nThis works throughout the user interface. For example, if you have the defined a variable `my_freq`, you can use this variable as the frequency in a SYNTH item, as shown in %FigSynth.\n\n%--\nfigure:\n id: FigSynth\n source: variable-frequency.png\n caption: The frequency '{my_freq}' indicates that the frequency of the SYNTH depends on the variable `my_freq`.\n--%\n\nSometimes, the user interface doesn't let you type in arbitrary text. For example, the elements of a SKETCHPAD are shown visually, and you cannot directly change an X coordinate to a variable. However, you can click on the *Select view \u2192 View script* button on the top right, and edit the script directly.\n\nFor example, you can change the position of a fixation dot from the center:\n\n```text\ndraw fixdot x=0 y=0\n```\n\n\u2026 to a position defined by the variables `xpos` and `ypos`:\n\n```text\ndraw fixdot x={xpos} y={ypos}\n```\n\n\n## Using Python expressions in the user interface\n\nWhen referring to variables using the `{my_var}` notation, you are in fact using a so-called [f-string](https://peps.python.org/pep-0498/), which is a way to embed Python code in strings of text. You can also use f-strings to evaluate arbitrary Python code. For example, you can multiply the variables `width` and `height` and include the result in a SKETCHPAD, like so:\n\n%--\nfigure:\n id: FigFString\n source: fstrings.png\n caption: You can embed Python expressions using f-strings.\n--%\n\nf-strings are Python code, and are therefore only supported on the desktop, but see below for a JavaScript alternative for browser experiments.\n\n\n## Using JavaScript expressions in the user interface\n\nWhen using OSWeb, expressions included between curly braces are interpreted as [template literals](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals). This is very similar to f-strings in Python, with the important difference that it uses JavaScript.\n\nIn normal JavaScript, expressions inside template literals are prefixed with a `$`, like so: `${expression}`. This is allowed in OpenSesame but not necessary: the prefix is automatically added to improve compatibility between browser and desktop experiments. In most cases, as in the figure below, the exact same expression is valid as a Python f-string on the desktop and a JavaScript template literal in the browser.\n\n\n%--\nfigure:\n id: FigTempalteLiteral\n source: template-literals.png\n caption: You can embed JavaScript expressions using template literals.\n--%\n\n\n## Using variables in Python\n\nIn an INLINE_SCRIPT, experimental variables are available as global variables. For example, if you have defined `example_variable` in a LOOP, then the following will print the value `example_variable` to the debug window:\n\n~~~ .python\nprint(example_variable)\n~~~\n\nYou can set the experimental variable `example_variable` to the value 'some value' as follows:\n\n~~~ .python\nexample_variable = 'some value'\n~~~\n\n\n## Using variables in JavaScript\n\nIn an INLINE_JAVASCRIPT, experimental variables are available as global variables. For example, if you have defined `example_variable` in a LOOP, then the following will print the value `example_variable` to the browser console:\n\n```js\nconsole.log(example_variable)\n```\n\nYou can set the experimental variable `example_variable` to the value 'some value' as follows:\n\n```js\nexample_variable = 'some value'\n```\n\n\n## Using conditional (\"if\") statements\n\nConditional statements, or 'if statements', provide a way to indicate that something should happen only under specific circumstances, such when some variable has a specific value. Conditional statements are regular Python expressions.\n\nThe most commonly used if-statement in OpenSesame is the run-if statement of the SEQUENCE, which allows you to specify the conditions under which a particular element is executed. If you open a SEQUENCE item, you see that every item from the sequence has a 'Run if \u2026'' option. The default value is 'always', which means that the item is always run; but you can also enter a condition here. For example, if you want to show a green fixation dot after a correct response, and a red fixation dot after an incorrect response, you can create a SEQUENCE like the following (this makes use of the fact that a KEYBOARD_RESPONSE item automatically sets the `correct` variable, as discussed above) as shown in %FigRunIf.\n\n*Important:* Run-if statements only apply to the Run phase of items. The Prepare phase is always executed. See also [this page](%link:prepare-run%).\n\n%--\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: |\n  'Run if' statements can be used to indicate that certain items from a SEQUENCE should only be executed under specific circumstances.\n--%\n\nYou can use more complex conditions as well. Let's take a look at a few examples:\n\n```python\ncorrect == 1 and response_time > 2000\ncorrect != 1 or response_time > max_response_time or response_time < min_response_time\n```\n\nThe same principle applies to 'Show if' fields in SKETCHPAD items. For example, if you want to draw a right-upwards-pointing arrow only if the variable `quadrant` has been set to 'upper right', simply type the proper condition in the 'Show if ...' field and draw the arrow, as in %FigShowIf. Make sure that you draw the arrow after you have set the condition.\n\n%--\nfigure:\n id: FigShowIf\n source: show-if.png\n caption: \"'Show if' statements can be used to indicate that certain elements from a SKETCHPAD or FEEDBACK item should only be shown under specific circumstances.\"\n--%\n\nImportant: The moment at which a conditional statement is evaluated may affect how your experiment works. This is related to the prepare-run strategy employed by OpenSesame, which is explained here:\n\n- %link:prepare-run%",
    "title": "Variables",
    "url": "https://osdoc.cogsci.nl/4.1/manual/variables",
    "path": "content/pages/manual/variables.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Examples\n\ntitle: Examples\n\nExample experiments are included with OpenSesame. A list of curated examples is available through Menu \u2192 Tools \u2192 Example experiments. You can also search for publicly available experiments on the OpenScienceFramework by using 'osexp' as search term.\n\n- <https://osf.io/search/?q=osexp>",
    "title": "Examples",
    "url": "https://osdoc.cogsci.nl/4.1/manual/examples",
    "path": "content/pages/manual/examples.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Mouse tracking\n\ntitle: Mouse tracking\n\nMousetrap is a third-party plugin, and is not maintained by the OpenSesame team.\n{: .alert .alert-info}\n\n## About\n\nPascal Kieslich and Felix Henninger have developed the [mousetrap plugins](https://github.com/PascalKieslich/mousetrap-os) for OpenSesame [(Kieslich & Henninger, 2017)](https://dx.doi.org/10.3758/s13428-017-0900-z). These plugins allow you to track the movement of the mouse cursor, which has been used to investigate the time course of cognitive processes in many psychological domains [(Freeman, Dale, & Farmer, 2011)](https://dx.doi.org/10.3389/fpsyg.2011.00059).\n\nMousetrap offers two plugins for mouse tracking in OpenSesame that can be included in the experiment via drag-and-drop.\nThe [mousetrap response plugin](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_response/mousetrap_response.md) tracks mouse movements while another stimulus (e.g., a sketchpad) is shown, analogous to a keyboard or mouse response item.\nThe [mousetrap form plugin](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_form/mousetrap_form.md) allows for tracking of mouse movements in [custom forms](%link:manual/forms/custom%).\nBesides, both plugins also provide Python classes, which can be used in Python inline scripts for maximum customizability.\n\nOnce data have been collected with the plugins, the data can be processed, analyzed and visualized using the [mousetrap R package](http://pascalkieslich.github.io/mousetrap/).\n\n## Installation\n\nInformation about how to install the mousetrap plugin can be found on its [GitHub page](https://github.com/PascalKieslich/mousetrap-os#installation). A number of example experiments that demonstrate the basic features are available in the [examples folder](https://github.com/PascalKieslich/mousetrap-os/tree/master/examples#example-experiments).\n\n\nSee also:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>",
    "title": "Mouse tracking",
    "url": "https://osdoc.cogsci.nl/4.1/manual/mousetracking",
    "path": "content/pages/manual/mousetracking.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Running experiments online\n\ntitle: Running experiments online\n\n\nThis page has been moved to:\n\n- %link:manual/osweb/workflow%",
    "title": "Running experiments online",
    "url": "https://osdoc.cogsci.nl/4.1/manual/osweb",
    "path": "content/pages/manual/osweb.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Integration with the Open Science Framework\n\ntitle: Integration with the Open Science Framework\n\n[TOC]\n\n## About\n\nThe OpenScienceFramework extension connects OpenSesame to the [Open Science Framework](https://osf.io) (OSF), which is a web platform for sharing, connecting, and streamlining scientific workflows. To use this extension, [you need an OSF account](https://osf.io/login/?sign_up=True).\n\nWith the OpenScienceFramework extension, you can:\n\n- Automatically save your experiment to the OSF\n- Automatically upload data to the OSF\n- Open experiments from the OSF\n- Share your experiment and data with other researchers, by giving them access through the OSF\n\n## Logging in to the OSF\n\nTo log into the OSF:\n\n- Create an account on <https://osf.io>. (You cannot create an account from within OpenSesame.)\n- In OpenSesame, click on the log-in button in the main toolbar, and enter your credentials.\n- Once logged in, you can open the OSF Explorer by clicking on your name where the login button used to be, and selecting *Show explorer*. The explorer will show an overview of all your OSF projects, and all repositories/ cloud services that are linked to your projects.\n\n## Linking an experiment to the OSF\n\nIf you link an experiment to the OSF, each time that you save the experiment in OpenSesame, a new version is also uploaded to the OSF.\n\nTo link an experiment:\n\n- Save the experiment on your computer.\n- Open the OSF explorer and select a folder or repository where you would like your experiment to be stored on the OSF. Right-click on this folder and select *Sync experiment to this folder*. The OSF node to which the experiment is linked will be shown at the top of the explorer.\n- The experiment is then uploaded to the selected location.\n- If you check *Always upload experiment on save*, a new version is automatically saved to OSF on each save; if you don't enable this option, you will be asked every time whether or not you want to do this.\n\nTo unlink an experiment:\n\n- Open the OSF explorer, and click the *Unlink* button next to the *Experiment linked to* link.\n\n## Linking data to the OSF\n\nIf you link data to the OSF, each time that data has been collected (normally after every experimental session), this data is also uploaded to the OSF.\n\nTo link data to the OSF:\n\n- Save the experiment on your computer.\n- Open the OSF explorer, right-click on the folder that you want the data to be uploaded to, and select *Sync data to this folder*. The OSF node that the data is linked to will be shown at the top of the explorer.\n- If you check *Always upload collected data*, data files will be automatically saved to OSF after they have been collected; if you don't enable this option, you will be asked every time whether or not you want to do this.\n\nTo unlink data from the OSF:\n\n- Open the OSF explorer, and click the *Unlink* button next to the *Data stored to* link.\n\n## Opening an experiment stored on the OSF\n\nTo open an experiment from the OSF:\n\n- Open the OSF explorer, and find the experiment.\n- Right-click on the experiment and select *Open experiment*.\n- Save the experiment on your computer.\n\n## Handling non-matching versions\n\nIf you open an experiment on your computer that is linked to the OSF, but differs from the version on the OSF, you will be asked what you want to do:\n\n- Use the version from your computer; or\n- Use the version from the OSF. If you choose to use the version from the OSF, it will be downloaded and overwrite the experiment on your computer.\n\n## Installing the OpenScienceFramework extension\n\nThe OpenScienceFramework extension is installed by default in the Windows package of OpenSesame. If the extension is not installed, you can install it as follows:\n\nFrom PyPi:\n\n~~~\npip install opensesame-extension-osf\n~~~\n\nIn an Anaconda environment\n\n~~~\nconda install -c cogsci opensesame-extension-osf\n~~~\n\nThe source code of the extension is available on GitHub:\n\n- <https://github.com/dschreij/opensesame-extension-osf>\n\nAnd for the `python-qosf` module, which is used by the extension:\n\n- <https://github.com/dschreij/python-qosf>",
    "title": "Integration with the Open Science Framework",
    "url": "https://osdoc.cogsci.nl/4.1/manual/osf",
    "path": "content/pages/manual/osf.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Installing packages, plugins, and extensions\n\ntitle: Installing packages, plugins, and extensions\n\n\nThis page has moved to:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>",
    "title": "Installing packages, plugins, and extensions",
    "url": "https://osdoc.cogsci.nl/4.1/manual/environment",
    "path": "content/pages/manual/environment.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Using the interface\n\ntitle: Using the interface\n\nOpenSesame has a powerful graphical interface that consists of several components (%FigInterface).\n\n%--\nfigure:\n id: FigInterface\n source: interface.png\n caption: The OpenSesame user interface.\n--%\n\n\n[TOC]\n\n## Toolbars and menubar\n\n### The menubar\n\nThe menubar (%FigMenubar) is shown at the top of the window, or, on some operating systems, is integrated into the border around the window. The menubar contains general functionality, such as saving and opening experiments, running experiments, etc.\n\n%--\nfigure:\n id: FigMenubar\n source: menubar.png\n caption: The menubar.\n--%\n\n### The main toolbar\n\nThe main toolbar (%FigMainToolbar) is (by default) shown at the top of the window, just below the menubar. The main toolbar contains a selection of the most relevant functionality from the menubar.\n\n%--\nfigure:\n id: FigMainToolbar\n source: main-toolbar.png\n caption: The main toolbar.\n--%\n\n### The item toolbar\n\nThe item toolbar (%FigItemToolbar) is (by default) shown at the left of the window. The item toolbar contains all items, that is, all building blocks of an experiment. You can add items to your experiment by dragging them from the item toolbar into the overview area.\n\n%--\nfigure:\n id: FigItemToolbar\n source: item-toolbar.png\n caption: The item toolbar.\n--%\n\n## The tab area\n\nThe tab area is the central part of the window (%FigTabArea). The tab area is where item controls, documentation, important messages, etc. are shown. The tab area can contain multiple tabs, and functions much like a tabbed web browser.\n\n%--\nfigure:\n id: FigTabArea\n source: tab-area.png\n caption: The tab area.\n--%\n\n## The overview area\n\nThe overview area (%FigOverviewArea) is (by default) shown at the left of the window, to the right of the item toolbar. The overview area shows the structure of your experiment as a tree. You can re-order the items in your experiment by dragging them from one position to another in the overview area.\n\n- Shortcut to hide/ show: `Ctrl+\\`\n\n%--\nfigure:\n id: FigOverviewArea\n source: overview-area.png\n caption: The overview area.\n--%\n\n## The file pool\n\nThe file pool (%FigFilePool) is (by default) shown at the right of the window. It provides an overview of all files that are bundled with the experiment.\n\n- Shortcut to hide/ show: `Ctrl+P`\n\n%--\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: The file pool.\n--%\n\n## The debug window\n\nThe debug window (%FigDebugWindow) is (by default) shown at the bottom of the window. It provides an [IPython interpreter](https://ipython.org/), and is used as the standard output while an experiment is running. That is, if you use the Python `print()` function, the result will be printed to the debug window.\n\n- Shortcut to hide/ show: `Ctrl+D`\n\n%--\nfigure:\n id: FigDebugWindow\n source: debug-window.png\n caption: The debug window.\n--%\n\n## The variable inspector\n\nThe variable inspector (%FigVariableInspector) is (by default) shown at the right of the window. It provides a list of all variables that are detected in your experiment. When you are running an experiment, the variable inspector also provides a real-time overview of variables and their values.\n\n- Shortcut to hide/ show: `Ctrl+I`\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: The variable inspector.\n--%\n\n## Keyboard shortcuts\n\nThe keyboard shortcuts listed below are default values. Many of them can be changed through *Menu \u2192 Tools \u2192 Preferences*.\n\n### General shortcuts\n\nThe following keyboard shortcuts are available everywhere:\n\n- Quick switcher: `Ctrl+Space`\n- Command palette: `Ctrl+Shift+P`\n- New experiment: `Ctrl+N`\n- Open experiment: `Ctrl+O`\n- Save experiment: `Ctrl+S`\n- Save experiment as: `Ctrl+Shift+S`\n- Undo: `Ctrl+Alt+Z`\n- Redo: `Ctrl+Alt+Shift+Z`\n- Run experiment fullscreen: `Ctrl+R`\n- Run experiment in window: `Ctrl+W`\n- Quick-run experiment: `Ctrl+Shift+W`\n- Test experiment in browser: `Alt+Ctrl+W`\n- Show/ hide overview area: `Ctrl+\\`\n- Show/ hide debug window: `Ctrl+D`\n- Show/ hide file pool: `Ctrl+P`\n- Show/ hide variable inspector: `Ctrl+I`\n- Focus overview area: `Ctrl+1`\n- Focus tab area: `Ctrl+2`\n- Focus debug window: `Ctrl+3`\n- Focus file pool: `Ctrl+4`\n- Focus variable inspector: `Ctrl+5`\n\n### Editor shortcuts\n\nThe following keyboard shortcuts are available in editor components, such as the INLINE_SCRIPT:\n\n- (Un)comment selected line(s): `Ctrl+/`\n- Find text: `Ctrl+F`\n- Replace text: `Ctrl+H`\n- Hide find/ replace dialog: `Escape`\n- Duplicate line: `Ctrl+Shift+D`\n- Undo: `Ctrl+Z`\n- Redo: `Ctrl+Shift+Z`\n- Copy: `Ctrl+C`\n- Cut: `Ctrl+X`\n- Paste: `Ctrl+V`\n\n### Tab-area shortcuts\n\nThe following keyboard shortcuts are available in the tab area:\n\n- Next tab: `Ctrl+Tab`\n- Previous tab: `Ctrl+Shift+Tab`\n- Close other tabs: `Ctrl+T`\n- Close all tabs: `Ctrl+Alt+T`\n- Close current tab: `Alt+T`\n\n### Overview-area and sequence shortcuts\n\nThe following keyboard shortcuts are available in the overview area and the SEQUENCE item:\n\n- Context menu: `+`\n- Copy item (unlinked): `Ctrl+C`\n- Copy item (linked): `Ctrl+Shift+C`\n- Paste item: `Ctrl+V`\n- Delete item: `Del`\n- Permanently delete item: `Shift+Del`\n- Rename: `F2`\n- Change run-if statement (if applicable): `F3`",
    "title": "Using the interface",
    "url": "https://osdoc.cogsci.nl/4.1/manual/interface",
    "path": "content/pages/manual/interface.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Runtime for Android\n\ntitle: Runtime for Android\n\n\n__Important note:__ The OpenSesame runtime for Android is based on software by others that is no longer developed. As a result, we are unable to make sure that the runtime works with recent versions of Android. Windows 10 tablets with Intel processors are a good alternative.\n{: .alert .alert-warning}\n\n\n[TOC]\n\n\n## OpenSesame runtime for Android\n\n### Download\n\nYou can download the OpenSesame runtime for Android through the Google Play Store:\n\n<a href=\"https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\" style=\"border:none;\">\n  <img alt=\"Get it on Google Play\"\n       src=\"https://developer.android.com/images/brand/en_generic_rgb_wo_45.png\" />\n</a>\n\n### Usage\n\nWhen you start the OpenSesame runtime, you will be asked where your experiments are located. By default, OpenSesame assumes that they are in the `/sdcard/` folder, or (if it exists) in the `/sdcard/Experiments/` folder. If you have no experiments on your device, pressing `enter` will show the example experiments that are bundled with the `.apk`.\n\nThe `Back` button serves the same purpose as the `Escape` key on regular systems, and will exit OpenSesame.\n\n### Supported devices\n\nOpenSesame is developed with the Nexus 4 and 9 as reference devices. In general, any device that runs Android 2.2. 'Froyo' or later appears to work.\n\n### Disabling automatic updates\n\nIf you are using the OpenSesame runtime for Android in a production environment (e.g., while you are running an experiment), it is recommended to disable the Auto-update feature of the Google Play Store, at least for OpenSesame. This will prevent the app from being updated and potentially changing its behavior. In case you need to downgrade to a previous version of the Android runtime, you can find the `.apk` files for previous releases [here](https://github.com/smathot/OpenSesame/releases).\n\n### Automatically start an experiment\n\nIf you want to directly launch a specific experiment when the OpenSesame runtime for Android is started, you can create a file called `opensesame-autorun.yml` in the `/sdcard/` folder of your device. This is a YAML file with the following structure:\n\n~~~\nexperiment: /sdcard/experiments/my_experiment.opensesame\nsubject_nr: 3\nlogfile: /sdcard/data/subject03.csv\n~~~\n\n## Developing experiments for Android\n\n### backend\n\nThe OpenSesame runtime for Android requires the *droid* backend.\n\n### Design tips\n\nImplement most user interactions through the MOUSE_RESPONSE item or TOUCH_RESPONSE plugin. In general, screen touches are registered as mouse clicks. Using keyboard input will work as well, but it will show and hide the virtual keyboard after every key that is entered, which looks messy.\n\nThe resolution for the DROID backend is fixed at 1280x800 (landscape). On Android, your experiment will be automatically scaled up or down depending on the resolution of the device, but the resolution that you design with is always 1280x800.\n\n### Debugging\n\nDebug output is written to `/sdcard/opensesame-debug.txt`.\n\n### Limitations\n\n- The SYNTH item and `openexp.synth` module are not functional.\n- The SAMPLER item and `openexp.sampler` module will ignore panning and pitching.\n\n## Know issue: Frozen or misbehaving virtual keyboard\n\nOn some devices, the default virtual keyboard is unresponsive (i.e. it shows but doesn't respond to taps) or doesn't respond normally. This appears to happen on phones with recent versions of Android. To work around this issue, you can install a third-party keyboard. Keyboards that have been reported to work are:\n\n- [GO Keyboard](https://play.google.com/store/apps/details?id=com.jb.emoji.gokeyboard&hl=en)\n- [Smart Keyboard Trial](https://play.google.com/store/apps/details?id=net.cdeguet.smartkeyboardtrial&hl=en)\n\n## Available Python modules\n\nBelow is a list of Python modules that should be available in the OpenSesame runtime for android. (This list is copied from the pgs4a now-defunct website.)\n\n~~~\npygame\npygame.base\npygame.bufferproxy\npygame.colordict\npygame.color\npygame.compat\npygame.constants\npygame.cursors\npygame.display\npygame.draw\npygame.event\npygame.fastevent\npygame.font\npygame.gfxdraw\npygame.imageext\npygame.image\npygame.joystick\npygame.key\npygame.locals\npygame.mask\npygame.mouse\npygame.overlay\npygame.rect\npygame.rwobject\npygame.sprite\npygame.surface\npygame.surflock\npygame.sysfont\npygame.time\npygame.transform\npygame.version\n_abcoll\nabc\naliases\narray\nast\natexit\nbase64\nbisect\nbinascii\ncalendar\ncmath\ncodecs\ncollections\ncompileall\ncontextlib\ncopy\ncopy_reg\ncStringIO\ncPickle\ndatetime\ndifflib\ndis\ndummy_threading\ndummy_thread\nencodings\nencodings.raw_unicode_escape\nencodings.utf_8\nencodings.zlib_codec\nerrno\nfcntl\nfnmatch\nfunctools\n__future__\ngenericpath\ngetopt\nglob\ngzip\nhashlib\nheapq\nhttplib\ninspect\nitertools\nkeyword\nlinecache\nmath\nmd5\nmimetools\nopcode\noptparse\nos\noperator\nparser\npickle\nplatform\nposix\nposixpath\npprint\npy_compile\npwd\nQueue\nrandom\nrepr\nre\nrfc822\nselect\nsets\nshlex\nshutil\nsite\nsocket\nsre_compile\nsre_constants\nsre_parse\nssl\nstat\nStringIO\nstring\nstruct\nsubprocess\nsymbol\nsymtable\nstrop\ntarfile\ntempfile\ntextwrap\n_threading_local\nthreading\ntime\ntokenize\ntoken\ntraceback\ntypes\nurllib\nurllib2\nurlparse\nUserDict\nwarnings\nweakref\nwebbrowser\nzipfile\nzipimport\nzlib\n~~~\n\n[google-play]: https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\n[forum]: http://forum.cogsci.nl/index.php?p=/discussion/333/a-video-of-opensesame-running-natively-on-android\n[droid]: /backends/droid\n[pgs4a]: http://pygame.renpy.org/",
    "title": "Runtime for Android",
    "url": "https://osdoc.cogsci.nl/4.1/manual/android",
    "path": "content/pages/manual/android.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# OpenSesameRun (no GUI)\n\ntitle: OpenSesameRun (no GUI)\n\n## About\n\n`opensesamerun` is a simple tool that allows you to execute OpenSesame experiments with a minimal GUI, or directly, by specifying all necessary options via the command line. A minimal GUI will automatically appear if not all command line options have been specified, notably the experiment file, the subject number, and the log file.\n\n~~~\nUsage: opensesamerun [experiment] [options]\n\nOptions:\n  --version             show program's version number and exit\n  -h, --help            show this help message and exit\n\n  Subject and log file options:\n    -s SUBJECT, --subject=SUBJECT\n                        Subject number\n    -l LOGFILE, --logfile=LOGFILE\n                        Logfile\n\n  Display options:\n    -f, --fullscreen    Run fullscreen\n    -c, --custom_resolution\n                        Do not use the display resolution specified in the\n                        experiment file\n    -w WIDTH, --width=WIDTH\n                        Display width\n    -e HEIGHT, --height=HEIGHT\n                        Display height\n\n  Miscellaneous options:\n    -d, --debug         Print lots of debugging messages to the standard\n                        output\n    --stack             Print stack information\n\n  Miscellaneous options:\n    --pylink            Load PyLink before PyGame (necessary for using the\n                        Eyelink plug-ins in non-dummy mode)\n~~~\n\n## Example\n\nLet's say that you want to run the gaze cuing example experiment, for subject #1, and save the log file in your Documents folder (this example assumes Linux, but it works analogously on other platforms):\n\n~~~\nopensesamerun /usr/share/opensesame/examples/gaze_cuing.opensesame.tar.gz -s 1 -l /home/sebastiaan/Documents/subject1.tsv -f \n~~~\n\n\n## Alternative `libopensesame`\n\nYou can also start experiments without using the GUI through the `libopensesame` Python module:\n\n- %link:manual/python/nogui%",
    "title": "OpenSesameRun (no GUI)",
    "url": "https://osdoc.cogsci.nl/4.1/manual/opensesamerun",
    "path": "content/pages/manual/opensesamerun.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Debugging\n\ntitle: Debugging\n\nWhile designing a new experiment, you will inevitably encounter bugs. Bugs can manifest as crashes accompanied by error messages, or as unexpected behaviors without any explicit error message.\n\nDebugging, the art and skill of diagnosing and rectifying these errors and unanticipated behaviors, is a critical part of the experimental design process.\n\n\n[TOC]\n\n\n## Debugging in the user interface\n\n### Using the variable inspector\n\nThe Variable Inspector in OpenSesame provides an overview of all variables that are currently active within your experiment. This includes:\n\n- Variables explicitly defined in the user interface, typically in a LOOP item.\n- Response variables, which are set by various response items such as a KEYBOARD_RESPONSE item.\n- Variables that are defined using Python INLINE_SCRIPT items.\n\nWhen an experiment is running, the Variable Inspector dynamically updates, providing a live overview of variables and their values. This feature allows you to monitor the behavior of your experiment in real-time, assisting you in identifying any potential issues or bugs.\n\nFor example, consider a situation where you have defined a variable `left_letter` to define which letter should appearing on the left side of a SKETCHPAD. However, during execution, you notice a mismatch in the Variable Inspector: `left_letter` is actually being shown on the right side of your display. This is indicates a bug such that you have misplaced the right and left letters on the SKETCHPAD.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: You can use the variable inspector to check whether your experiment behaves as it should. In this example, there is a bug such that the letter that is defined through the variable `left_letter` actually appears on the right and vice versa.\n--%\n\nUsing the Variable Inspector regularly to monitor variables helps ensure that your experiment is behaving as expected and aids in identifying problems early on.\n\n\n### Printing debug messages to the IPython/ Jupyter console\n\nThe Python `print()` function is a simple-yet-powerful debugging tool when used inside INLINE_SCRIPT items, and serves a similar purpose to the Variable Inspector. For instance, you can print the values of the variables `left_letter` and `right_letter` during the Prepare phase of an INLINE_SCRIPT at the beginning of each trial.\n\nTo view these debug messages, open the Jupyter/ IPython console and monitor the output while running the experiment. By doing so, you can verify whether the output displayed in the console aligns with the experiment's actual behavior.\n\n%--\nfigure:\n id: FigPrintingOutput\n source: printing-output.png\n caption: The Python `print()` function can be used to output debug messages to the console.\n--%\n\nIn the above example, it becomes evident that the letter assigned to the `left_letter` variable (hence expected to appear on the left) is actually appearing on the right, and vice versa.\n\n\n### Interpreting user-interface error messages\n\nWhen a bug in your experiment causes a crash, OpenSesame displays an error message, also referred to as an 'Exception'. An error message typically consists of the following components:\n\n- **Error type:** Indicates the general class of error. In the example below this is an `FStringError`.\n- **Description:** Provides a more specific explanation of what triggered the error. In this case, 'Failed to evaluate \u2026'.\n- **Source:** Specifies the item that triggered the error and whether it occurred during the Run or Prepare phase.\n- **Traceback:** A detailed Python error message. This information is only shown if the error occurred while evaluating custom Python code, which includes INLINE_SCRIPT items, but also conditional expressions (e.g. run-if expressions), and text with embedded variable references.\n- **Learn more about this error:** An interactive button you can click to get more detailed information about the error message.\n\nLet's look at an example to better understand these components and learn how to fix a common error:\n\n%--\nfigure:\n id: FigFStringError\n source: fstring-error.png\n caption: An `FStringError` indicates an issue when trying to evaluate a text string containing a Python expression.\n--%\n\nThis is an `FStringError`, which means there was an issue while interpreting a text string that includes a Python expression. In this example, the problematic text is `{right_leter}`. Anything enclosed within curly braces is interpreted as a Python expression, and therefore in this case the Python expression is `right_leter`\u2014which is simply a variable name. Trying to evaluate the Python expression `right_leter` triggered a `NameError` because `right_leter` is not defined.\n\nThat's pretty technical, but what exactly went wrong here in simple terms? The issue arises from referring to a non-existent variable: `right_leter`. Looking at the variable name, it seems likely that there's a typo: the intended variable is likely `right_letter`, with a double 't'.\n\nWhere should we correct this mistake? The error message indicates that the source of the error is an item called *target*, which is a SKETCHPAD. To resolve the error, we need to open *target* and change the text from '{right_leter}' to '{right_letter}'. \n\n\n### Interpreting Python error messages\n\nIn Python, errors fall into two categories: syntax errors and exceptions (or runtime errors).\n\n\n#### Python syntax errors\n\nA syntax error occurs when the Python interpreter cannot parse code because it violates Python's syntax rules. This could be due to mismatched parentheses, missing commas, incorrect indentation, and so on. In OpenSesame, this results in a `PythonSyntaxError`.\n\n%--\nfigure:\n id: FigPythonSyntaxError\n source: python-syntax-error.png\n caption: A `PythonSyntaxError` is triggered when the code violates Python's syntax rules and cannot be parsed.\n--%\n\nThe error message above indicates that a syntax error has occurred on line 16 of the Prepare phase of an item named *constants*. Here's the problematic line:\n\n```python\ntarget_orientations = [('z', 0), ('/', 90]\n```\n\nThe message also hints at mismatched parentheses as the potential source of the error. Taking that into consideration, we can fix the issue by adding a missing parenthesis `)` before the closing bracket `]`:\n\n```python\ntarget_orientations = [('z', 0), ('/', 90)]\n```\n\n\n#### Python Exceptions\n\nWhen Python code is syntactically correct but encounters a problem during execution, an exception is raised. In OpenSesame, such exceptions result in a `PythonError`.\n\n%--\nfigure:\n id: FigPythonError\n source: python-error.png\n caption: A `PythonError` is triggered when an exception is raised during the execution of syntactically correct Python code.\n--%\n\nThe error message above indicates that a `NameError` was raised on line 2 of the Run phase of an item named *trial_script*. Specifically, the identifier 'clock_sleep' is not recognized. Looking at the error-causing line, it's apparent that we've used an underscore (`_`) instead of a dot (`.`), incorrectly implying that `clock_sleep()` is a function.\n\n```python\nclock_sleep(495)\n```\n\nTo rectify this, we should correctly reference the `sleep()` function as part of the `clock` object:\n\n```python\nclock.sleep(495)\n```\n\n## Debugging in a web browser (OSWeb)\n\n\n### Printing output to the browser console\n\nThe JavaScript `console.log()` function is a simple-yet-powerful debugging tool when used inside INLINE_JAVASCRIPT items. It serves a similar purpose to the Python `print()` function and the Variable Inspector, neither of which are available in OSWeb. For instance, you can print the values of the variables `left_letter` and `right_letter` during the Prepare phase of an INLINE_SCRIPT at the beginning of each trial.\n\nTo view these debug messages, you need to open the browser console. Here's how to do it in Chrome, Firefox, and Edge:\n\n- **Google Chrome:** Press Ctrl + Shift + J (Windows / Linux) or Cmd + Option + J (Mac).\n- **Mozilla Firefox:** Press Ctrl + Shift + K (Windows / Linux) or Cmd + Option + K (Mac).\n- **Microsoft Edge:** Press F12 to open the developer tools, then select the \"Console\" tab.\n\nOnce the console is open, you can monitor the output while running the experiment, allowing you to check whether the output displayed in the console aligns with the experiment's actual behavior.\n\n%--\nfigure:\n id: FigPrintingOutputOSWeb\n source: printing-output-osweb.png\n caption: The JavaScript `console.log()` function can be used to output debug messages to the browser console.\n--%\n\nIn the above example, it becomes evident that the letter assigned to the `left_letter` variable (which should appear on the left) is actually appearing on the right, and vice versa.\n\n\n### Understanding error messages\n\nWhen your browser-based experiment crashes, OSWeb will show an error message in the browser. An error message typically consists of the following components:\n\n- **Error type:** Indicates the general class of error. In this example below this is a `ReferenceError`.\n- **Description:** Provides a more specific explanation of what triggered the error. In this case, 'right_leter is not defined'.\n- **Source:** Specifies the item that triggered the error and whether it occurred during the Run or Prepare phase.\n- **Source script:** The JavaScript code that caused the error. This information is only shown if the error occurred while evaluating custom JavaScript, which includes INLINE_JAVASCRIPT items, but also conditional expressions (e.g. run-if expressions), and text with embedded variable references.\n\nLet's look at an example to better understand these components and learn how to fix a common error:\n\n%--\nfigure:\n id: FigOSWebError\n source: osweb-error.png\n caption: A `ReferenceError` indicates a reference to a non-existent variable or other non-existent object.\n--%\n\nThis is a `ReferenceError`, which indicates that the experiment refers to a non-existent variable or other non-existent object. In this example, the error arose from the text `${right_leter}`. Anything enclosed within curly braces and prefixed by a `$` is interpreted as JavaScript expression, and in this case, the JavaScript expression is `right_leter`\u2014which is simply a variable name. Trying to evaluate the JavaScript expression `right_leter` triggered a `ReferenceError` because `right_leter` is not defined.\n\nThat's pretty technical, but what exactly went wrong here in simple terms? The issue arises from referring to a non-existent variable: `right_leter`. Looking at the variable name, it seems likely that there's a typographical error: the intended variable is likely `right_letter`, with a double 't'.\n\nWhere should we correct this mistake? The error message indicates that the source of the error is an item called *target*, which is a SKETCHPAD. To resolve the error, we need to open *target* and change the text from '{right_leter}' to '{right_letter}'. \n\n\n### Using the `debugger` statement in INLINE_JAVASCRIPT items\n\nThe JavaScript `debugger` statement is a powerful tool for debugging `INLINE_JAVASCRIPT` items in OpenSesame/OSWeb experiments. It allows you to insert breakpoints in your code, causing the browser's JavaScript execution to pause at that point. This allows you to inspect the current state of the JavaScript workspace.\n\nUsing the `debugger` statement is straightforward. Simply insert the statement `debugger` on the line where you want to pause execution. For example:\n\n```javascript\nconsole.log(`left_letter = ${left_letter}`)\nconsole.log(`right_letter = ${right_letter}`)\ndebugger // Execution will pause here\n```\n\nOnce you've inserted the `debugger` statement into your code, you need to open the browser console as explained above. After you open the browser console, run your experiment. When the JavaScript interpreter reaches the `debugger` statement, it will pause execution, and the developer tools will switch to the \"Sources\" (Chrome/Edge) or \"Debugger\" (Firefox) tab, highlighting the breakpoint line.\n\n%--\nfigure:\n id: FigJavaScriptDebugger\n source: javascript-debugger.png\n caption: When the JavaScript interpreter reaches the `debugger` statement, it will pause execution and allow you to inspect the JavaScript workspace. The `debugger` statement only works when the browser console is open.\n--%\n\nWhile execution is paused, you can inspect variable values, step through the code line by line, and investigate the call stack to better understand the state of your program at the breakpoint.\n\nRemember to remove or comment out the `debugger` statements when you're finished debugging, as leaving them in can interfere with the normal operation of your experiment.\n\n\n## Handling ExperimentProcessDied errors\n\nOccasionally, you might encounter an `ExperimentProcessDied` error during an experiment.\n\n%--\nfigure:\n id: FigExperimentProcessDied\n source: experiment-process-died.png\n caption: The `ExperimentProcessDied` error generally indicates an issue with the underlying Python process or associated libraries, not your experiment's code.\n--%\n\nThis error implies that the Python process in which the experiment was running terminated unexpectedly. It typically doesn't indicate a bug in your experiment, but rather suggests a problem in one of the low-level libraries used by OpenSesame, or even a bug in Python itself.\n\nDetermining the exact cause of this error can be challenging, and fixing it may be even more so. However, there are a few workarounds you can try to mitigate the issue:\n\n- **Change the backend:** Select a different backend under 'Run Experiment' in the experiment properties. This might resolve the issue as different backends use different sets of low-level libraries.\n- **Update OpenSesame and relevant packages:** Regularly updating OpenSesame and all associated packages can potentially resolve this issue, as bugs are routinely fixed in new versions.",
    "title": "Debugging",
    "url": "https://osdoc.cogsci.nl/4.1/manual/debugging",
    "path": "content/pages/manual/debugging.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Logging and reading data files\n\ntitle: Logging and reading data files\n\nAlways triple check whether your data has been logged correctly before running your experiment!\n{: .page-notification}\n\n[TOC]\n\n\n## Using the logger item\n\nOpenSesame will not log your data automatically. Instead, you need to insert a LOGGER item, typically at the end of your trial sequence.\n\n%--\nfigure:\n id: FigLogger\n source: logger.png\n caption: |\n  The LOGGER item.\n--%\n\nThe simplest way to use the LOGGER is by leaving the option 'Automatically log all variables' enabled. That way, all variables that OpenSesame knows about are written the log file, except for those that are explicitly excluded (see below).\n\nYou can explicitly *include* which variables you want to log. The main reason for doing so is when you find that some variables are missing (because OpenSesame did not automatically detect them), or if you have disabled the option 'Automatically log all variables', \n\nYou can also explicitly exclude certain variables from the log file. The main reason for doing so is to keep the log files clean by excluding variables that are generally not useful.\n\nIn general, you should create only one logger item, and reuse that LOGGER at different locations in your experiment if necessary (i.e. use linked copies of the same LOGGER item). If you create multiple LOGGERs (rather than using a single LOGGER multiple times), they will all write to the same log file, and the result will be a mess!\n\n## Using Python inline script\n\nYou can write to the log file using the `log` object:\n\n~~~ .python\nlog.write('This will be written to the log file!')\n~~~\n\nFor more information, see:\n\n- %link:log%\n\nYou should generally not write to the log file directly and use a LOGGER item at the same time; doing so will result in messy log files.\n\n## Format of the data files\n\nIf you have used the standard LOGGER item, data files are in the following format format (simply standard csv):\n\n- plain-text\n- comma-separated\n- double-quoted (literal double-quotes are escaped with backward slashes)\n- unix-style line endings\n- UTF-8 encoded\n- column names on the first row\n\n## Which variables are logged?\n\nBy default, variables that are defined in the user interface, such as columns in a `loop` table or response variables are always logged.\n\nBy default, variables that are defined in an `inline_script` or `inline_javascript` are logged if they are numbers (`int` and `float`), strings (`str` and `bytes`), and `None` values. This is to avoid log files from becoming unreasonably large due to logging of long lists and other large values. (As of OpenSesame 4.0, there is no longer a need to use the `var` (Python) or `vars` (JavaScript) object.)\n\nIf you want to explicitly log a variable that is not logged by default, you can use the 'Include' field in the LOGGER item.\n\n\n## Reading and processing data files\n\n### In Python with pandas or DataMatrix\n\nIn Python, you can use [pandas](http://pandas.pydata.org/) to read csv files.\n\n```python\nimport pandas\ndf = pandas.read_csv('subject-1.csv')\nprint(df)\n```\n\nOr [DataMatrix](https://datamatrix.cogsci.nl/):\n\n```python\nfrom datamatrix import io\ndm = io.readtxt('subject-1.csv')\nprint(dm)\n```\n\n### In R\n\nIn R, you can simply use the `read.csv()` function to read a single data file.\n\n~~~ .R\ndf = read.csv('subject-1.csv', encoding = 'UTF-8')\nhead(df)\n~~~\n\nIn addition, you can use the `read_opensesame()` function from the [readbulk](https://github.com/pascalkieslich/readbulk) package to easily read and merge multiple data files into one large data frame. The package is available on CRAN and can be installed via `install.packages('readbulk')`.\n\n~~~ .R\n# Read and merge all data files stored in the folder 'raw_data'\nlibrary(readbulk)\ndf = read_opensesame('raw_data')\n~~~\n\n### In JASP\n\n[JASP](http://jasp-stats.org/), an open-source statistics package, opens csv files straight away.\n\n### In LibreOffice Calc\n\nIf you open a csv file in LibreOffice Calc, you have to indicate the exact data format, as indicated in %FigLibreOffice. (The default settings are often correct.)\n\n%--\nfigure:\n source: libreoffice.png\n id: FigLibreOffice\n--%\n\n### In Microsoft Excel\n\nIn Microsoft Excel, you need to use the Text Import Wizard.\n\n### Merging multiple data files into one large file\n\nFor some purposes, such as using pivot tables, it may be convenient to merge all data files into one large file. With Python DataMatrix, you can do this with the following script:\n\n```python\nimport os\nfrom datamatrix import DataMatrix, io, operations as ops\n\n# Change this to the folder that contains the .csv files\nSRC_FOLDER = 'student_data'\n# Change this to a list of column names that you want to keep\nCOLUMNS_TO_KEEP = [\n    'RT_search',\n    'load',\n    'memory_resp'\n]\n\n\ndm = DataMatrix()\nfor basename in os.listdir(SRC_FOLDER):\n    path = os.path.join(SRC_FOLDER, basename)\n    print('Reading {}'.format(path))\n    dm <<= ops.keep_only(io.readtxt(path), *COLUMNS_TO_KEEP)\nio.writetxt(dm, 'merged-data.csv')\n```\n\n\n## Logging in OSWeb\n\nWhen you run an experiment in a browser with OSWeb, logging works differently from when you run an experiment on the desktop.\n\nSpecifically, when you launch an OSWeb experiment directly from within OpenSesame, the log file is downloaded at the end of the experiment. This log file is in `.json` format. When you launch an OSWeb experiment from JATOS, there is no log file as such, but rather all data is sent to JATOS from where it can be downloaded.\n\nSee also:\n\n- %link:manual/osweb/workflow%\n\n\n\n[libreoffice]: http://www.libreoffice.org/\n[openoffice]: http://www.openoffice.org/\n[gnumeric]: http://projects.gnome.org/gnumeric/\n[log-func]: /python/inline-script/#inline_script.log\n[codecs]: http://docs.python.org/2/library/codecs.html\n[ppa]: https://launchpad.net/~smathot/+archive/cogscinl/",
    "title": "Logging and reading data files",
    "url": "https://osdoc.cogsci.nl/4.1/manual/logging",
    "path": "content/pages/manual/logging.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Timing\n\ntitle: Timing\nreviewed: false\n\nThis page describes various issues related to timing, and provides benchmark results and tips for testing your own system. If you experience problems with timing, please take the time to read this page. Many issues are resolved by taking into account things such as stimulus preparation and the properties of your monitor.\n\n[TOC]\n\n## Is OpenSesame capable of millisecond precision timing?\n\nThe short answer is: yes. The long answer is the rest of this page.\n\n\n## Important considerations for time-critical experiments\n\n### Check your timing!\n\nOpenSesame allows you to control your experimental timing very accurately. But this does not guarantee accurate timing in every specific experiment! For any number of reasons, many of which are described on this page, you may experience issues with timing. Therefore, in time-critical experiments you should always check whether the timing in your experiment is as intended. The easiest way to do this is by checking the display timestamps reported by OpenSesame.\n\nEvery SKETCHPAD item has a variable called `time_[sketchpad name]` that contains the timestamp of the last time that the SKETCHPAD was shown. Therefore, if you want the SKETCHPAD *target* to be shown for 100 ms, followed by the SKETCHPAD *mask*, you should verify that `time_mask` - `time_target` is indeed 100. When using Python inline code, you can make use of the fact that `canvas.show()` returns the display timestamp.\n\n\n### Understanding your monitor\n\nComputer monitors refresh periodically. For example, if the refresh rate of your monitor is 100 Hz, the display is refreshed every 10 ms (1000 ms / 100 Hz). This means that a visual stimulus is always presented for a duration that is a multiple of 10 ms, and you will not be able to present a stimulus for, say, 5 or 37 ms. The most common refresh rate is 60 Hz (= 16.67 ms refresh cycle), although monitors with much higher refresh rates are sometimes used for experimental systems.\n\nIn %VidRefresh you can see what a monitor refresh looks like in slow motion. On CRT monitors (i.e. non-flatscreen, center) the refresh is a single pixel that traces across the monitor from left to right and top to bottom. Therefore, only one pixel is lighted at a time, which is why CRT monitors flicker slightly. On LCD or TFT monitors (flatscreen, left and right) the refresh is a 'flood fill' from top to bottom. Therefore, LCD and TFT monitors do not flicker. (Unless you present a flickering stimulus, of course.)\n\n%--\nvideo:\n id: VidRefresh\n source: vimeo\n videoid: 24216910\n width: 640\n height: 240\n caption: A slow-motion video of the refresh cycle on CRT (center) and LCD/ TFT monitors. Video courtesy of Jarik den Hartog and the VU University Amsterdam technical support staff.\n--%\n\nIf a new stimulus display is presented while the refresh cycle is halfway, you will observe 'tearing'. That is, the upper half of the monitor will show the old display, while the lower part will show the new display. This is generally considered undesirable, and therefore a new display should be presented at the exact moment that the refresh cycle starts from the top. This is called 'synchronization to the vertical refresh' or simply 'v-sync'. When v-sync is enabled, tearing is no longer visible, because the tear coincides with the upper edge of the monitor. However, v-sync does not change anything about the fact that a monitor does not refresh instantaneously and will therefore always, for some time, show both the old and the new display.\n\nAnother important concept is that of 'blocking on the vertical retrace' or the 'blocking flip'. Usually, when you send a command to show a new display, the computer will accept this command right away and put the to-be-shown display in a queue. However, the display may not actually appear on the monitor until some time later, typically until the start of the next refresh cycle (assuming that v-sync is enabled). Therefore, you don't know exactly when the display has appeared, because your timestamp reflects the moment that the display was queued, rather than the moment that it was presented. To get around this issue, you can use a so-called 'blocking flip'. This basically means that when you send a command to show a new display, the computer will freeze until the display actually appears. This allows you to get very accurate display timestamps, at the cost of a significant performance hit due to the computer being frozen for much of the time while it is waiting for a display to be shown. But for the purpose of experiments, a blocking flip is generally considered the optimal strategy.\n\nFinally, LCD monitors may suffer from 'input lag'. This means that there is an additional and sometimes variable delay between the moment that the computer 'thinks' that a display appears, and the moment that the display actually appears. This delay results from various forms of digital processing that are performed by the monitor, such as color correction or image smoothing. As far as I know, input lag is not something that can be resolved programmatically, and you should avoid monitors with significant input lag for time-critical experiments. \n\nFor a related discussion, see:\n\n- <http://docs.expyriment.org/Timing.html#visual>\n\n\n### Making the refresh deadline\n\nImagine that you arrive at a train station at 10:30. Your train leaves at 11:00, which gives you exactly 30 minutes to get a cup of coffee. However, if you have coffee for exactly 30 minutes, then you will arrive back at the platform just in time to see your train depart, and you will have to wait for the next train. Therefore, if you have 30 minutes waiting time, you should have a coffee for slightly less than 30 minutes, such as 25 minutes.\n\nThe situation is analogous when specifying intervals for visual-stimulus presentation. Let's say that you have a 100 Hz monitor (so 1 refresh every 10 ms) and want to present a target stimulus for 100 ms, followed by a mask. Your first inclination might be to specify an interval of 100 ms between the target and the mask, because that's after all what you want. However, specifying an interval of exactly 100 ms will likely cause the mask to 'miss the refresh deadline', and the mask will be presented only on the next refresh cycle, which is 10 ms later (assuming that v-sync is enabled). So if you specify an interval of 100 ms, you will in most cases end up with an interval of 110 ms!\n\nThe solution is simple: You should specify an interval that is slightly shorter than what you are aiming for, such as 95 ms. Don't worry about the interval being too short, because on a 100 Hz monitor the interval between two stimulus displays is necessarily a multiple of 10 ms. Therefore, 95 ms will become 100 ms (10 frames), 1 ms will become 10 ms (1 frame), etc. Phrased differently, intervals will be rounded up (and never rounded down!) to the nearest interval that is consistent with your monitor's refresh rate.\n\n\n### Disabling desktop effects\n\nMany modern operating systems make use of graphical desktop effects. These provide, for example, the transparency effects and the smooth window minimization and maximization effects that you see on most modern operating systems. Although the software that underlies these effects differs from system to system, they generally form an additional layer between your application and the display. This additional layer may prevent OpenSesame from synchronizing to the vertical refresh and/ or from implementing a blocking flip.\n\nAlthough desktop effects *may* cause problems, they usually don't. This appears to vary from system to system and from video card to video card. Nevertheless, when the operating systems allows it, it's best to disable desktop effects on systems that are used for experimental testing.\n\nSome tips regarding desktop effects for the various operating systems:\n\n- Under *Windows XP* there are no desktop effects at all.\n- Under *Windows 7* desktop effects can be disabled by selecting any of the themes listed under 'Basic and High Contrast Themes' in the 'Personalization' section.\n- Under *Windows 10* there is no way to completely disable desktop effects.\n- Under *Ubuntu and other Linux distributions using Gnome 3* there is no way to completely disable desktop effects.\n- Under *Linux distributions using KDE* you can disable desktop effects in the 'Desktop Effects' section of the System Settings.\n- Under *Mac OS* there is apparently no way to completely disable desktop effects.\n\n\n### Taking into account stimulus-preparation time/ the prepare-run structure\n\nIf you care about accurate timing during visual-stimulus presentation, you should prepare your stimuli in advance. That way, you will not get any unpredictable delays due to stimulus preparation during the time-critical parts of your experiment.\n\nLet's first consider a script (you can paste this into an INLINE_SCRIPT item) that includes stimulus-preparation time in the interval between `canvas1` and `canvas2` (%LstStimPrepBad). The interval that is specified is 95 ms, so--taking into account the 'rounding up' rule described in [Making the refresh deadline]--you would expect an interval of 100 ms on my 60 Hz monitor. However, on my test system the script below results in an interval of 150 ms, which corresponds to 9 frames on a 60 Hz monitor. This is an unexpected delay of 50 ms, or 3 frames, due to the preparation of `canvas2`.\n\n%--\ncode:\n id: LstStimPrepBad\n syntax: python\n source: stimulus-preparation-bad.py\n caption: \"In this script, the duration between `canvas1` and `canvas2` is confounded by stimulus-preparation time.\"\n--%\n\nNow let's consider a simple variation of the script above (%LstStimPrepGood). This time, we first prepare both `canvas1` and `canvas2` and only afterwards present them. On my test system, this results in a consistent 100 ms interval, just as it should!\n\n%--\ncode:\n id: LstStimPrepGood\n syntax: python\n source: stimulus-preparation-good.py\n caption: \"In this script, the duration between `canvas1` and `canvas2` is not confounded by stimulus-preparation time.\"\n--%\n\nWhen using the graphical interface, the same considerations apply, but OpenSesame helps you by automatically handling most of the stimulus preparation in advance. However, you have to take into account that this preparation occurs at the level of SEQUENCE items, and not at the level of LOOP items. Practically speaking, this means that the timing *within* a SEQUENCE is not confounded by stimulus-preparation time. But the timing *between* SEQUENCEs is.\n\nTo make this more concrete, let's consider the structure shown below (%FigStimPrepBad). Suppose that the duration of the SKETCHPAD item is set to 95 ms, thus aiming for a 100 ms duration, or 6 frames on a 60 Hz monitor. On my test system the actual duration is 133 ms, or 8 frames, because the timing is confounded by preparation of the SKETCHPAD item, which occurs each time that that the sequence is executed. So this is an example of how you should *not* implement time-critical parts of your experiment.\n\n%--\nfigure:\n id: FigStimPrepBad\n source: stimulus-preparation-incorrect.png\n caption: \"An example of an experimental structure in which the timing between successive presentations of SKETCHPAD is confounded by stimulus-preparation time. The sequence of events in this case is as follows: prepare SKETCHPAD (2 frames), show SKETCHPAD (6 frames), prepare SKETCHPAD (2 frames), show SKETCHPAD (6 frames), etc.\"\n--%\n\nNow let's consider the structure shown below (%FigStimPrepGood). Suppose that the duration of `sketchpad1` is set to 95 ms, thus aiming for a 100 ms interval between `sketchpad1` and `sketchpad2`. In this case, both items are shown as part of the same SEQUENCE and the timing will not be confounded by stimulus-preparation time. On my test system the actual interval between `sketchpad1` and `sketchpad2` is therefore indeed 100 ms, or 6 frames on a 60 Hz monitor.\n\nNote that this only applies to the interval between `sketchpad1` and `sketchpad2`, because they are executed in that order as part of the same sequence. The interval between `sketchpad2` on run *i* and `sketchpad1` on run *i+1* is again confounded by stimulus-preparation time.\n\n%--\nfigure:\n id: FigStimPrepGood\n source: stimulus-preparation-correct.png\n caption: \"An example of an experimental structure in which the timing between the presentation of `sketchpad1` and `sketchpad2` is not confounded by stimulus-preparation time. The sequence of events in this case is as follows: prepare `sketchpad1` (2 frames), prepare `sketchpad2` (2 frames), show `sketchpad1` (6 frames), show `sketchpad2` (6 frames), prepare `sketchpad1` (2 frames), prepare `sketchpad2` (2 frames), show `sketchpad1` (6 frames), show `sketchpad2` (6 frames), etc.\"\n--%\n\nFor more information, see:\n\n- [usage/prepare-run]\n\n### Differences between backends\n\nOpenSesame is not tied to one specific way of controlling the display, system timer, etc. Therefore, OpenSesame *per se* does not have specific timing properties, because these depend on the backend that is used. The performance characteristics of the various backends are not perfectly correlated: It is possible that on some system the [psycho] backend works best, whereas on another system the [xpyriment] backend works best. Therefore, one of the great things about OpenSesame is that you can choose which backend works best for you!\n\nIn general, the [xpyriment] and [psycho] backends are preferable for time-critical experiments, because they use a blocking flip. On the other hand, the [legacy] backend is slightly more stable and also considerably faster when using [forms].\n\nUnder normal circumstances the three current OpenSesame backends have the properties shown in %TblBackendInfo.\n\n%--\ntable:\n id: TblBackendInfo\n source: backend-info.csv\n caption: backend properties.\n--%\n\nSee also:\n\n- [backends]\n\n## Benchmark results and tips for testing your own system\n\n### Checking whether v-sync is enabled\n\nAs described in [Understanding your monitor], the presentation of a new display should ideally coincide with the start of a new refresh cycle (i.e. 'v-sync'). You can test whether this is the case by presenting displays of different colors in rapid alternation. If v-sync is not enabled you will clearly observe horizontal lines running across the monitor (i.e. 'tearing'). To perform this test, run an experiment with the following script in an INLINE_SCRIPT item (%LstVSync):\n\n%--\ncode:\n id: LstVSync\n syntax: python\n source: v-sync-check.py\n caption: A script that presents yellow and blue displays in rapid alternation. A lack of synchronization with the vertical refresh can be observed as horizontal lines running through the monitor.\n--%\n\n### Testing precision and accuracy of timing\n\nTiming is precise or consistent when you can present visual stimuli over and over again with the same timing. Timestamps are accurate when they accurately reflect when visual stimuli appear on the monitor. The script below shows how you can check precision and accuracy of timing. This test can be performed both with and without an external photodiode, although the use of a photodiode provides extra verification.\n\nTo keep things simple, let's assume that your monitor is running at 100 Hz, which means that a single frame takes 10 ms. The script then presents a white canvas for 1 frame (10 ms). Next, the script presents a black canvas for 9 frames (90 ms). Note that we have specified a duration of 85, which is rounded up as explained under [Making the refresh deadline]. Therefore, we expect that the interval between the onsets of two consecutive white displays will be 10 frames or 100 ms (= 10 ms + 90 ms).\n\nWe can use two ways to verify whether the interval between two white displays is indeed 100 ms:\n\n1. Using the timestamps reported by OpenSesame. This is the easiest way and is generally accurate when the backend uses a blocking flip.\n2. Using a photodiode that responds to the onsets of the white displays and logs the timestamps of these onsets to an external computer. This is the best way to verify the timing, because it does not rely on introspection of the software. Certain issues, such as TFT input lag, discussed above, will come out only using external photodiode measurement.\n\n%--\ncode:\n id: LstIntervalBenchmark\n syntax: python\n source: interval-benchmark.py\n caption: A Python script to test the timing consistency and accuracy of display timestamps. You can paste this code into an INLINE_SCRIPT item.\n--%\n\nI ran %LstIntervalBenchmark on Windows XP, using all three backends. I also recorded the onsets of the white displays using a photodiode connected to a second computer. The results are summarized in %TblBenchmarkResults.\n\n%--\ntable:\n id: TblBenchmarkResults\n source: benchmark-results.csv\n caption: Benchmark results for %LstIntervalBenchmark. Tested with Windows XP, HP Compaq dc7900, Intel Core 2 Quad Q9400 @ 2.66Ghz, 3GB, 21\" ViewSonic P227f CRT. Each test was conducted twice (i.e. two sessions). The column `Session` corresponds to different test runs. The column `Source` indicates whether the measurements are from an external photiodiode, or based on OpenSesame's internal timestamps.\n--%\n\nAs you can see, the [xpyriment] and [psycho] backends consistently show a 100 ms interval. This is good and just as we would expect. However, the [legacy] backend shows a 90 ms interval. This discrepancy is due to the fact that the [legacy] backend does not use a blocking flip (see [Understanding your monitor]), which leads to some unpredictability in display timing. Note also that there is close agreement between the timestamps as recorded by the external photodiode and the timestamps reported by OpenSesame. This agreement demonstrates that OpenSesame's timestamps are reliable, although, again, they are slightly less reliable for the [legacy] backend due to the lack of a blocking-flip.\n\n\n## Expyriment benchmarks and test suite\n\nA very nice set of benchmarks is available on the Expyriment website. This information is applicable to OpenSesame experiments using the [xpyriment] backend.\n\n- <http://docs.expyriment.org/Timing.html>\n\nExpyriment includes a very useful test suite. You can launch this test suite by running the `test_suite.opensesame` example experiment, or by adding a simple INLINE_SCRIPT to your experiment with the following lines of code (%LstExpyrimentTestSuite):\n\n%--\ncode:\n id: LstExpyrimentTestSuite\n syntax: python\n source: expyriment-test-suite.py\n caption: A script to start the Expyriment test suite.\n--%\n\nFor more information, please visit:\n\n- <http://docs.expyriment.org/Testsuite.html>\n\n## PsychoPy benchmarks and timing-related information\n\nSome information about timing is available on the PsychoPy documentation site. This information is applicable to OpenSesame experiments using the [psycho] backend.\n\n- <http://www.psychopy.org/general/timing/timing.html>\n\n[psycho]: /backends/xpyriment/\n[xpyriment]: /backends/xpyriment/\n[legacy]: /backends/legacy/\n[miscellaneous/clock-drift]: /miscellaneous/clock-drift\n[usage/prepare-run]: /usage/prepare-run\n[backends]: /backends\n[forms]: /forms",
    "title": "Timing",
    "url": "https://osdoc.cogsci.nl/4.1/manual/timing",
    "path": "content/pages/manual/timing.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Backends\n\ntitle: Backends\n\nThe *backend* is the software layer that deals with input (keyboard input, mouse input, etc.) and output (display presentation, sound playback, etc.). There are many libraries that offer this type of functionality and OpenSesame could, in principle, use any one of them. For this reason, OpenSesame is backend-independent, in the sense that you can choose which backend should be used. Currently there are four backends: *legacy*, *psycho*, *xpyriment*, and *osweb*.\n\n[TOC]\n\n## Differences and some tips\n\nUsually, you won't notice which backend is used. The differences between backends are largely technical, and, as long as you use the graphical user interface, all backends work more ore less the same way. However, there are a few reasons to prefer one backend over another:\n\n- If you want to run the experiment in a browser, you need to select the *osweb* backend.\n- Backend differs in [temporal precision](%link:timing%).\n\t- Tip: If you care about millisecond temporal precision, use *xpyriment* or *psycho*.\n- Backends differ in how long stimulus preparation takes.\n\t- Tip: If [forms](%link:manual/forms/about%) are slow, use *legacy*.\n\t- Tip: If the intertrial interval is long (due to stimulus preparation), use *legacy*.\n- You can use backend-specific functionality when writing Python code.\n\t- Tip: If you want to use PsychoPy functionality, use *psycho*.\n\t- Tip: If you want to use Expyriment functionality, use *xpyriment*.\n\t- Tip: If you want to use PyGame functionality, use *legacy*.\n- Some backends are not available on all platforms.\n\n## Selecting a backend\n\nYou can select a backend in the general properties of the experiment (%FigSelect).\n\n%--\nfigure:\n id: FigSelect\n source: fig-select.png\n caption: \"Selecting a backend\"\n--%\n\nIf you view the general script (select \"Show script editor\"), you will see that there are actually six distinct backends: canvas, keyboard, mouse, sampler, color, and clock. The combobox-method automatically selects an appropriate, predefined combination of backends, but you could, in theory, mix and match.\n\nFor example, if you select the *xpyriment* backend, the following code will be generated:\n\n\tset sampler_backend legacy\n\tset mouse_backend xpyriment\n\tset keyboard_backend legacy\n\tset color_backend legacy\n\tset clock_backend legacy\n\tset canvas_backend xpyriment\n\n## xpyriment\n\nThe *xpyriment* backend is built on top of [Expyriment][], a library designed for creating psychology experiments. It is a light-weight hardware-accelerated backend with excellent timing properties. If you care about temporal precision, but do not plan on generating complex stimuli (i.e. Gabor patches, random-dot gratings, etc.) *xpyriment* is a good choice.\n\n### Using Expyriment directly\n\nYou can find extensive documentation on Expyriment at <http://www.expyriment.org/doc>. The following code snippet shows a line of text:\n\n~~~ .python\nfrom expyriment import stimuli\ntext = stimuli.TextLine('This is expyriment!')\ntext.present()\n~~~\n\n### Citation\n\nAlthough Expyriment is bundled with the binary distributions of OpenSesame, it is a separate project. When appropriate, please provide the following citation in addition to citing OpenSesame:\n\nKrause, F., & Lindemann, O. (in press). Expyriment: A Python library for cognitive and neuroscientific experiments. *Behavior Research Methods*.\n{: .reference}\n\n## psycho\n\nThe psycho backend is built on top of [PsychoPy][], a library designed for creating psychology experiments. It is hardware accelerated and provides high-level routines for creating complex visual stimuli (drifting gratings, etc.). If you care about timing and plan on creating complex stimuli, Psycho is a good choice.\n\n### Using PsychoPy directly\n\nYou can find extensive documentation on PsychoPy at <http://www.psychopy.org/>. When using PsychoPy in OpenSesame, it is important to know that the main window can be accessed as `self.experiment.window` or simply `win`. So the following code snippet draws a Gabor patch:\n\n~~~ .python\nfrom psychopy import visual\ngabor = visual.PatchStim(win, tex=\"sin\", size=256, mask=\"gauss\", sf=0.05, ori=45)\ngabor.draw()\nwin.flip()\n~~~\n\n### Tutorials\n\nA tutorial specifically for using PsychoPy from within OpenSesame:\n\n- <http://www.cogsci.nl/blog/tutorials/211-a-bit-about-patches-textures-and-masks-in-psychopy>\n\nAnd a more general PsychoPy tutorial:\n\n- <http://gestaltrevision.be/wiki/coding>\n\n### Citation\n\nAlthough PsychoPy is bundled with the binary distributions of OpenSesame, it is a separate project. When appropriate, please cite the following papers in addition to citing OpenSesame:\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n{: .reference}\n\nPeirce, J. W. (2009). Generating stimuli for neuroscience using PsychoPy. *Frontiers in Neuroinformatics*, *2*(10). doi:10.3389/neuro.11.010.2008\n{: .reference}\n\n## legacy\n\nThe legacy backend is built on top of [PyGame][] in non-OpenGL mode. The downside of this is that there is no hardware acceleration, and the timing properties are not as good as that of the psycho or xpyriment backends. The upside is that PyGame is very easy to use, very reliable, and well supported on a wide range of platforms.\n\n### Mouse-cursor visibility\n\nOn some systems, the mouse cursor is not visible when using the *legacy* backend in fullscreen mode. You can work around this is the following ways:\n\n1. Open the *legacy* backend settings and set \"Double buffering\" to \"no\".\n\t- *Note:* This may disable v-sync, which can be important for time critical experiments, as discussed [here](%link:timing%).\n2. Open the *legacy* backend settings and set \"Custom cursor\" to \"yes\".\n3. Switch to another backend.\n\n### Using PyGame directly\n\nPyGame is well documented and you can find everything you need to know about using PyGame on <http://www.pygame.org/docs/>. Specific to OpenSesame is the fact that the display surface is stored as `self.experiment.window` or simply `win`. So the following code snippet, which you could paste into an INLINE_SCRIPT item, draws a red rectangle to the display:\n\n~~~ .python\nimport pygame # Import the PyGame module\npygame.draw.rect(self.experiment.window, pygame.Color(\"red\"),\n\t[20, 20, 100, 100]) # Draw a red rectangle. Not shown yet...\npygame.display.flip() # Update the display to show the red rectangle.\n~~~\n\n\n## osweb\n\nThe *osweb* backend is built on top of OSWeb and allows you run experiments in a browser. For more information, see:\n\n- %link:manual/osweb/workflow%",
    "title": "Backends",
    "url": "https://osdoc.cogsci.nl/4.1/manual/backends",
    "path": "content/pages/manual/backends.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# The prepare-run strategy\n\ntitle: The prepare-run strategy\n\n[TOC]\n\n## About\n\nExperiments typically consist of short intervals ('trials') during which participants perceive stimuli and perform a task. Timing should be controlled during a trial, but some unpredictable variation in the duration of the interval between trials is acceptable. Therefore, a good strategy is to perform time-consuming tasks before a trial, and to keep the operations that are performed during a trial to a minimum.\n\nOpenSesame does this by calling each element from a SEQUENCE item twice. This is the *prepare-run strategy*:\n\n- During the Prepare phase, items are given the opportunity to prepare. For example, a SYNTH generates a sound (but doesn't play it); and a SKETCHPAD draws a canvas (but doesn't show it).\n- During the Run phase, items do as a little as possible. For example, a SYNTH plays back a previously prepared sound; and a SKETCHPAD shows a previously prepared canvas.\n\nThis reduces the risk of timing glitches. The prepare-run strategy is implemented at the level of SEQUENCE items, which typically contains the time-critical parts of an experiment. This means that before a SEQUENCE is started, there is some unpredictable temporal jitter.\n\n## Item-specific notes\n\n### loop items\n\nA LOOP item is not prepared in advance. It is important to take this into account when using a LOOP to implement time-critical parts. For example, you may be tempted to implement an RSVP stream using a LOOP item as follows:\n\n~~~text\nrsvp_loop item (4 cycles)\n- stimulus_item\n~~~\n\nIn this construction, *stimulus_item* will be prepared and run four times in alternation, like so:\n\n~~~text\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\n~~~\n\nTherefore, you need to verify that the preparation of *stimulus_item* does not cause any timing glitches.\n\n### sequence items\n\nAll items that are part of a SEQUENCE are prepared in advance. Therefore, the following construction ...\n\n~~~text\ntrial_sequence\n- fixation_sketchpad\n- target_sketchpad\n- keyboard_response\n- logger\n~~~\n\n... will be executed as follows ...\n\n~~~text\nprepare fixation_sketchpad\nprepare target_sketchpad\nprepare keyboard_response\nprepare logger\nrun fixation_sketchpad\nrun target_sketchpad\nrun keyboard_response\nrun logger\n~~~\n\n### sketchpad and feedback items\n\nSKETCHPAD and FEEDBACK items differ in when they are prepared. For SKETCHPADs preparation occurs during the Prepare phase; for FEEDBACK items, preparation occurs only during the Run phase.\n\nFor more information, see:\n\n- %link:manual/stimuli/visual%\n\n### synth and sampler items\n\nFor SYNTH and SAMPLER items, the sound is generated and preloaded during the Prepare phase.\n\n### inline_script items\n\nIn an INLINE_SCRIPT item, you can choose how you want to implement the run and prepare strategy. In general, it is good practice to adhere to the following guidelines:\n\n- Time-consuming, preparatory functionality goes in the Prepare phase. For example, creating canvas objects, and generating sounds.\n- A minimum amount of code is put in the run phase. For example, only showing a previously prepared canvas.\n\n### Other items and plugins\n\nIn general, items should follow the principle of performing as much as possible time-consuming preparation during the Prepare phase, and minimizing the Run phase. However, every plugin is implemented differently. If you are unsure about a specific case, please post a query on the forum.\n\n## Conditional expressions (run if, show if, break if, etc)\n\nIn SEQUENCE items, the 'Run if' condition is evaluated at the last moment, during the run phase. Therefore, you can use a condition like `correct == 0` which depends on the results of a KEYBOARD_RESPONSE item which has been called just before. It is important to take into account that the 'Run if' expression applies *only* to the run phase of an item\u2014The prepare phase is *always* executed.\n\nIn COROUTINES items, the 'Run if' condition is evaluated during the Prepare phase. Therefore, the conditions cannot depend on events that occur during the execution of the COROUTINES.\n\nIn SKETCHPAD items, the 'Show if' condition is evaluated during the Prepare phase, when the canvas is constructed. In FEEDBACK items, the 'Show if' condition is evaluated during the Run phase (because the canvas is only constructed in the Run phase).",
    "title": "The prepare-run strategy",
    "url": "https://osdoc.cogsci.nl/4.1/manual/prepare-run",
    "path": "content/pages/manual/prepare-run.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Oculus rift (virtual reality)\n\n---\nlayout: osdoc\ntitle: Oculus rift (virtual reality)\ngroup: Devices\npermalink: /oculus-rift/\n---\n\n<iframe src=\"http://wl.figshare.com/articles/1394986/embed?show_title=1\" width=\"640\" height=\"861\" frameborder=\"0\"></iframe>\n\nHern\u00e1ndez-Sande, A., Lorca, J. A. (2015): OpenSesame: An example of stimulus presentation in Virtual Reality headsets (Oculus Rift DK1). *Figshare*. doi:10.6084/m9.figshare.1394986",
    "title": "Oculus rift (virtual reality)",
    "url": "https://osdoc.cogsci.nl/4.1/manual/devices/oculusrift",
    "path": "content/pages/manual/devices/oculusrift.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Ambulatory Monitoring System (VU-AMS)\n\ntitle: Ambulatory Monitoring System (VU-AMS)\n\nVU-AMS is a third-party plugin, and is not maintained by the OpenSesame team.\n{: .alert .alert-info}\n\n\nThe VU University Ambulatory Monitoring System (VU-AMS) is a device that can be used to measure a variety of factors related to heart rate, respiration, and body movement. The developers offer an OpenSesame template on their website.\n\nFor more information, see:\n\n- <http://www.vu-ams.nl> (product website)\n- <http://www.vu-ams.nl/support/downloads/extras/> (OpenSesame template)",
    "title": "Ambulatory Monitoring System (VU-AMS)",
    "url": "https://osdoc.cogsci.nl/4.1/manual/devices/vuams",
    "path": "content/pages/manual/devices/vuams.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# StimSync\n\ntitle: StimSync\n\nStimSync is an open-source open-hardware device for handling input (e.g., button presses) and output (e.g., triggers) in psychological and neuroscientific experiments. StimSync offers examples for use with OpenSesame.\n\nFor more information, see:\n\n- <http://www.mccauslandcenter.sc.edu/crnl/stimsync-0>",
    "title": "StimSync",
    "url": "https://osdoc.cogsci.nl/4.1/manual/devices/stimsync",
    "path": "content/pages/manual/devices/stimsync.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Serial port\n\ntitle: Serial port\n\nPySerial is an easy to use Python library for serial port communications, which is bundled with all OpenSesame packages. For more information, see:\n\n- <http://pyserial.sourceforge.net/>",
    "title": "Serial port",
    "url": "https://osdoc.cogsci.nl/4.1/manual/devices/serial",
    "path": "content/pages/manual/devices/serial.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Parallel port (EEG triggers)\n\ntitle: Parallel port (EEG triggers)\nreviewed: false\n\nIn EEG/ ERP studies it is common to send triggers to mark the timestamp for significant events (e.g., the onset of a trial, presentation of a particular stimulus, etc.). Triggers are typically bytes that are sent via the parallel port to the EEG apparatus.\n\n[TOC]\n\n\n## Using the `parallel_port_trigger` plugin\n\nParallel_port_trigger is a third-party plugin and not maintained by the OpenSesame team.\n{: .page-notification}\n\nAn OpenSesame plug-in for sending stimulus synchronization triggers through the parallel port to data acquisition systems.\n\n- <https://github.com/dev-jam/opensesame-plugin-parallel_port_trigger/>\n\nYou can install the `parallel_port_trigger` plugin from PyPi:\n\n```\npip install pip install opensesame-plugin-parallel-port-trigger\n```\n\n\n## Using `dportio.dll` in a Python inline Script (Windows only)\n\nInstead of using the `parallel_port_trigger` plugin, it is also possible to send triggers with `dlportio.dll` through a Python inline script. This approach is Windows only. To do so, first add an INLINE_SCRIPT to the start of the experiment with the following code in the prepare phase:\n\n~~~ .python\ntry:\n\tfrom ctypes import windll\n\tglobal io\n\tio = windll.dlportio # requires dlportio.dll !!!\nexcept:\n\tprint('The parallel port couldn\\'t be opened')\n~~~\n\nThis will load `dlportio.dll` as a global object called `io`. Please note that failure will not crash the experiment, so make sure to check the debug window for error messages!\n\nNow use the following code in an INLINE_SCRIPT anywhere in the experiment to send a trigger:\n\n~~~ .python\nglobal io\ntrigger = 1\nport = 0x378\ntry:\n\tio.DlPortWritePortUchar(port, trigger)\nexcept:\n\tprint('Failed to send trigger!')\n~~~\n\nNote that this sends trigger 1 to port 0x378 (=888). Change these values according to your set-up.\n\n## Getting access to the parallel port\n\n### Linux\n\nIn Linux we use the `parport_pc` module (tested in Debian Wheezy) and we need to provide ourselves with permissions to do so. We can accomplish this by executing the following commands:\n\n\tsudo rmmod lp\n\tsudo rmmod parport_pc\n\tsudo modprobe parport_pc\n\tsudo adduser [user] lp\n\nHere, `[user]` should be replaced by your username. Next, logout and login, and you are ready to go!\n\n### Windows XP and Windows Vista (32 bit)\n\n1. Download the 32-bit DLPortIO driver from [here][win32-dll] and uncompress the zip archive.\n2. Go to `DriverLINX/drivers` folder and copy `dlportio.dll` and `dlportio.sys` to the `install` folder. This is the folder  where `install.exe` is located. Then run `install.exe`\n3. You need to copy `dlportio.dll` to the OpenSesame folder (that is, the same folder that contains `opensesame.exe`).\n\n### Windows 7 (32 and 64 bit)\n\n1. Download the 32-bit or 64bit DLPortIO driver [here][win7-dll] and uncompress the zip archive.\n2. As Windows 7 has a strengthened security system (at least compared to XP) one cannot simply install the DLPortIO driver. This won't work as Windows 7 will block all attempts of installing a not-officially-signed (by Microsoft) driver. Good for the security of an average user -- bad for us. To bypass this restriction one has to use a little helper program called \"Digital Signature Enforcement Overrider\" (DSEO) which can be downloaded [here][dseo] (of course there are other possible ways to do this but this program is mentioned in the DLPortIO `readme.txt` and one does not have to dive deeper into MS Windows 7 architecture specialities).\n3. Start DSEO with administrator privileges (right click on `dseo13b.exe`, select \"run as administrator\"). Now the DSEO window pops up. It just presents a list of options which operation to run next.\n4. Choose the option \"sign driver/sys-file\" and press ok. Now another window appears where you have to type in the absolute path to the `DLPortIO.sys` file (only this one, not the dll!). Remember to escape spaces in the path if you have any (don't ask how long that took me) otherwise your files will not be found. Pressing ok will sign the sys-file.\n5. Back in the DSEO list choose \"enable test mode\" and press ok. Then choose \"exit\" and restart your PC. Windows 7 wrongly complains that DSEO might not be installed correctly -- just click on \"yes, the software is installed correctly\".\n6. After boot-up is completed you'll see that something like \"Windows 7 test mode built #number#\" is written on the desktop just above the clock in the starter-bar. That's necessary. You have to be in test mode to run this unofficially signed driver.\n7. Now run `DLPortIO_install.bat` with administrator privileges (in Windows Explorer, right click the file, ...). Answer \"yes\" if Windows warns you about registry changes.\n8. Reboot.\n9. Copy `DLPortIO.dll` to the Opensesame folder, that is, the same folder that contains `opensesame.exe`.\n\nSource: [Forum post by Absurd][post-3]\n\n## Recommendations\n\n- Start your experiment with a 'zero' trigger to make sure all the pins are set to zero.\n- It's recommended to use the [psycho] or [xpyriment] backends instead of the [legacy] backend (using PyGame) for time-critical experiments. This is because [psycho] and [xpyriment] takes the refresh rate of the monitor into account when returning timestamps, whereas [legacy] does not. For more information, see [miscellaneous/timing].\n- Send the trigger code right after (instead of just before) the presentation of your stimulus (assuming that it's the stimulus onset you want to mark). By doing so you'll make sure that the time stamp is as accurately as possible and will not suffer from a small random jitter due to your monitor's refresh rate. [Source: lvanderlinden][post-2]\n\n## Troubleshooting\n\nThere are a number of relevant forum topics in which trigger-related problems are discussed (and, for the most, solved!).\n\n- A post about ghost triggers, i.e. unwanted triggers that are mysteriously registered by the EEG apparatus: [link][post-2]\n- A post with elaborate installation instructions for DLPortIO on Windows 7 ([Source: absurd][post-3]).\n\nPlease don't hesitate to post questions on the forum, or to let us know of your experiences (good or bad).\n\n[win32-dll]: http://files.cogsci.nl/misc/dlportio.zip\n[win7-dll]: http://real.kiev.ua/avreal/download/#DLPORTIO_TABLE\n[dseo]: http://www.ngohq.com/home.php?page=dseo\n[post-2]: http://forum.cogsci.nl/index.php?p=/discussion/comment/780#Comment_780\n[post-3]: http://forum.cogsci.nl/index.php?p=/discussion/comment/745#Comment_745\n[miscellaneous/timing]: /miscellaneous/timing\n[legacy]: /backends/legacy\n[xpyriment]: /backends/xpyriment\n[psycho]: /backends/psycho",
    "title": "Parallel port (EEG triggers)",
    "url": "https://osdoc.cogsci.nl/4.1/manual/devices/parallel",
    "path": "content/pages/manual/devices/parallel.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Emotiv EEG\n\n---\nlayout: osdoc\ntitle: Emotiv EEG\ngroup: Devices\npermalink: /emotiv/\n---\n\n[Emotiv](https://emotiv.com/) is a low-cost EEG headset. Dimitrios Adamos (Neuroinformatics.GRoup of the Aristotle University of Thessaloniki) has written a tutorial for using the Emotiv with OpenSesame:\n\n- <http://neuroinformatics.gr/node/37>\n\n%--\nfigure:\n source: emotiv.png\n id: FigEmotiv\n caption: Emotiv is a low-cost EEG headset.\n--%",
    "title": "Emotiv EEG",
    "url": "https://osdoc.cogsci.nl/4.1/manual/devices/emotiv",
    "path": "content/pages/manual/devices/emotiv.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Using the form plugins\n\ntitle: Using the form plugins\n\nA number of commonly used forms are available as ready-made plugins. These allow you to use common forms, without any need for scripting.\n\n- FORM_CONSENT is a simple digital consent form (disclaimer: some journals may require *written* consent)\n- FORM_MULTIPLE_CHOICE allows you to present multiple choice questions\n- FORM_TEXT_DISPLAY is a simple text display that you can use to show instructions etc.\n- FORM_TEXT_INPUT is a simple text input display that allows you to ask a question and collect a multi-character response from the participant\n\nThe FORM_BASE plugin is special. It allows you to define custom forms using OpenSesame script, as described here:\n\n- %link:manual/forms/custom%\n\n%--\nfigure:\n id: FigFormPlugins\n source: form-plugins.png\n caption: The FORM plugins in the item toolbar.\n--%",
    "title": "Using the form plugins",
    "url": "https://osdoc.cogsci.nl/4.1/manual/forms/readymade",
    "path": "content/pages/manual/forms/readymade.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Form variables\n\ntitle: Form variables\n\n[TOC]\n\n## About form variables\n\nWhen you present a form with multiple `checkbox`es, you generally want to know which `checkbox` the user has checked. Similarly, when you present a form with two `button`s, you want to know which `button` the user has clicked. This information is available through variables that are automatically set when the user interacts with a form. You can specify yourself which response variables should be used. How this is done depends on how you have created your form.\n\n### In ready-made form plugins\n\nWhen you use one of the ready-made form plugins, such as FORM_TEXT_INPUT, you can specify the name of the response variable directly in the plugin controls.\n\n### In custom forms\n\nYou can use the `var` keyword to indicate which variable should be used. For example, the following OpenSesame script, which you can enter into a FORM_BASE plugin, indicates that the response from a `text_input` widget should be stored in a variable called `my_response_var`:\n\n```python\nwidget 0 0 1 1 text_input var=my_response_var\n```\n\nThe equivalent Python code is:\n\n~~~ .python\nmy_widget = TextInput(var='my_response_var')\n~~~\n\nSee also:\n\n- %link:manual/forms/widgets%\n\n## Widget-specific information\n\nEach widget uses its response variable in a slightly different way.\n\n### button\n\nThe `button` widget sets the response variable to 'yes' if it has been clicked and to 'no' if it has not.\n\n### checkbox\n\nThe `checkbox` widget sets the response variable to a semicolon-separated list of the text on all checkboxes that have been checked (for that variable), or 'no' if no `checkbox` has been checked (for that variable). This sounds a bit complicated, so let's see a few examples.\n\n```python\nwidget 0 0 1 1 checkbox group=\"1\" text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox group=\"1\" text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Next\"\n```\n\nHere there are two `checkbox`es with the text 'A' and 'B'. Both part of the same group, called '1'. Both have the same response variable, called `my_response_var`. If 'A' is checked, `my_response_var` will be 'A'. If 'B' is checked, `my_response_var` will be 'B'. If neither is checked, `my_response_var` will be 'no'. Note that only one `checkbox` in the same group can be checked, so `my_response_var` will *never* be 'A;B' in this example.\n\nNow let's consider the same script, with the sole difference that the two `checkbox`es are not part of a group:\n\n```python\nwidget 0 0 1 1 checkbox text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Next\"\n```\n\nIn this case, the situation is much like described above, with the exception that both `checkbox`es can be checked at the same time, in which case `my_response_var` will be set to 'A;B'.\n\nYou cannot use the same response variable for `checkbox`es in different groups.\n\n### image\n\nVariables are not applicable to the `image` widget.\n\n### image_button\n\nThe `image_button` widget sets the response variable to 'yes' if it has been clicked and to 'no' if it has not.\n\n### label\n\nVariables are not applicable to the `label` widget.\n\n### rating_scale\n\nThe `rating_scale` widget sets the response variable to the number of the option that has been clicked, where '0' is the first option (zero-based indexing). If no option has been selected, the response variable is set to 'None'.\n\n### text_input\n\nThe `text_input` widget sets the response variable to the entered text.",
    "title": "Form variables",
    "url": "https://osdoc.cogsci.nl/4.1/manual/forms/variables",
    "path": "content/pages/manual/forms/variables.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# About forms\n\ntitle: About forms\n\nForms are simple interactive displays that can be used to implement questionnaires, instructions, text input displays, etc. You can use forms in four ways.\n\n- Use the form plugins, such as FORM_TEXT_INPUT, which offer ready-made forms. This is the easiest, but least flexible way of using forms. This works both on the desktop and in a browser.\n\t- %link:manual/forms/readymade%\n- Define custom forms using OpenSesame script and the form_base plugin. This offers considerable flexibility, and does not require any real programming skills. This only works on the desktop.\n\t- %link:manual/forms/custom%\n- Create custom forms using Python inline script. This offers the most flexibility, but requires some knowledge of Python programming. This only works on the desktop.\n\t- %link:manual/forms/custom%\n- Create custom forms using HTML code. This only works when running experiments in a browser with OSWeb.\n\t- %link:manual/forms/html%\n\n%--\nfigure:\n id: FigAbout\n source: about.png\n caption: An example form.\n--%",
    "title": "About forms",
    "url": "https://osdoc.cogsci.nl/4.1/manual/forms/about",
    "path": "content/pages/manual/forms/about.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Custom HTML forms\n\ntitle: Custom HTML forms\n\n\nThe INLINE_HTML item allows you to implement forms using custom HTML.\n\n- The `name` attribute of `input` tags corresponds to an experimental variable. Therefore, the text that is entered into the text input of Example 1 will be stored as the experimental variable `text_response`.\n- For `checkbox` and `radio` elements, you can use the `id` attribute to assign a specific value to the associated experimental variable.\n- You can use the `required` attribute to indicate that a form cannot be submitted before a field has been filled out.\n- The form is closed when the participant clicks on an input of type submit.\n- To include images from the file pool in a custom HTML form, first retrieve the URL to the file, assign it to an experimental variable, and then use this variable as the source for the `<img>` tag (see Example 3).\n\n\nExample 1:\n\nA very basic text input form:\n\n```html\n<input type='text' name='text_response'>\n<input type='submit' value='click here to continue'>\n```\n\nExample 2:\n\nA form with multiple radio buttons:\n\n```html\n<p>Please select your age:</p>\n<input type=\"radio\" id=\"age1\" name=\"age\" value=\"30\" required>\n<label for=\"age1\">0 - 30</label><br>\n<input type=\"radio\" id=\"age2\" name=\"age\" value=\"60\">\n<label for=\"age2\">31 - 60</label><br>  \n<input type=\"radio\" id=\"age3\" name=\"age\" value=\"100\">\n<label for=\"age3\">61 - 100</label><br><br>\n<input type=\"submit\" value=\"Submit\">\n```\n\nExample 3:\n\nYou can include variable references (except within `<script>` tags, where curly braces are simply interpreted as part of JavaScript code):\n\n```html\n<p>You age group is {age}</p>\n<input type='submit' value='ok'>\n```\n\nExample 4:\n\nYou can JavaScript through `<script>` tags. For example, you can get an image from the file pool and assign to an initially empty `<img>` tag like this:\n\n```html\n<img id='capybara'>\n<input type='submit' value='ok'>\n\n<script>\ndocument.getElementById('capybara').src = pool['capybara.png'].data.src\n</script>\n```",
    "title": "Custom HTML forms",
    "url": "https://osdoc.cogsci.nl/4.1/manual/forms/html",
    "path": "content/pages/manual/forms/html.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Form widgets and keywords\n\ntitle: Form widgets and keywords\n\n\n[TOC]\n\n\n## Screenshot\n\n%--\nfigure:\n id: FigWidgets\n source: widgets.png\n caption: A list of available FORM widgets.\n--%\n\n\n## Widgets and keywords\n\nAll keywords are optional, instead otherwise indicated.\n\n### Form\n\nThe `cols` and `rows` keywords can either be single `int` values, in which case they specify the number of equally sized columns and rows, or lists of `int`, in which case they specify the relative sizes of each column and row. For more information about form geometry, see:\n\n- %link:manual/forms/custom%\n\nThe `validator` keyword can be used to validate form input. For more information, see:\n\n- %link:manual/forms/validation%\n\n(In OpenSesame script, you do not need to explicitly create a form.)\n\nPython script:\n\n~~~ .python\nform = Form(\n    cols=2, rows=2, spacing=10, margins=(100, 100, 100, 100), theme='gray',\n    timeout=None, clicks=False, validator=None\n)\nbutton = Button(text='Ok!')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### button / Button\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 button text=\"Click me!\" center=yes frame=yes var=response\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nbutton = Button(text='Click me!', frame=True, center=True, var='response')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### checkbox / Checkbox\n\nIf a group is specified, checking one checkbox from that group will uncheck all other checkboxes from that group. Checkboxes that are part of a group cannot be unchecked, except by clicking on another checkbox in that group.\n\nThe `group` keyword also affects how variables are stored, as described here:\n\n- %link:manual/forms/variables%\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 checkbox group=group text=\"Option 1\"\nwidget 0 1 1 1 checkbox group=group text=\"Option 2\"\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\ncheckbox1 = Checkbox(text='Option 1', group='group')\ncheckbox2 = Checkbox(text='Option 2', group='group')\nform.set_widget(checkbox1, (0, 0))\nform.set_widget(checkbox2, (0, 1))\nform._exec()\n~~~\n\n\n### image / ImageWidget\n\nThe Python object is called `ImageWidget` to distinguish it from the `Image` canvas element.\n\nOpenSesame script:\n\n~~~python\n# Only path is a required keyword\nwidget 0 0 1 1 image path=\"my_image.png\" adjust=yes frame=no\n~~~\n\nPython script:\n\n~~~ .python\n# Only path is a required keyword\nform = Form()\nimage = ImageWidget(path=pool['my_image.png'], adjust=True, frame=False)\nform.set_widget(image, (0, 0))\nform._exec()\n~~~\n\n\n### image_button / ImageButton\n\nThe `image_id` keyword is used to identify the image button when it is clicked. If no `image_id` is provided, the path to the image is used as id.\n\nOpenSesame script:\n\n~~~python\n# Only path is a required keyword\nwidget 0 0 1 1 image_button path=\"my_image.png\" adjust=yes frame=no image_id=my_image var=response\n~~~\n\nPython script:\n\n~~~ .python\n# Only path is a required keyword\nform = Form()\nimage_button = ImageButton(\n    path=pool['my_image.png'], adjust=True, frame=False,\n    image_id='my_image', var='response'\n)\nform.set_widget(image_button, (0, 0))\nform._exec()\n~~~\n\n\n### label / Label\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 label text=\"My text\" frame=no center=yes\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nlabel = Label(text='My text', frame=False, center=True)\nform.set_widget(label, (0,0))\nform._exec()\n~~~\n\n\n### rating_scale / RatingScale\n\nThe `nodes` keyword can be an `int` or a semicolon-separated list of labels. If `nodes` is an `int`, it specified the number of (unlabeled) nodes.\n\nThe `default` keyword indicates which node number is selected by default, where the first node is 0.\n\nOpenSesame script:\n\n~~~python\nwidget 0 1 1 1 rating_scale var=response nodes=\"Agree;Don't know;Disagree\" click_accepts=no orientation=horizontal var=response default=0\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nrating_scale = RatingScale(\n    nodes=['Agree', u\"Don't know\", 'Disagree'], click_accepts=False,\n    orientation='horizontal', var='response', default=0\n)\nform.set_widget(rating_scale, (0, 0))\nform._exec()\n~~~\n\n\n### text_input / TextInput\n\nThe `stub` keyword indicates placeholder text that is shown when no text has been entered. The `key_filter` keyword, available only in Python, specifies a function to filter key presses. This is described in more detail under:\n\n- %link:manual/forms/validation%\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 text_input text=\"Initial text\" frame=yes center=no stub=\"Type here \u2026\" return_accepts=yes var=response\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\ntext_input = TextInput(\n    text='Initial text', frame=True, center=False, stub='Type here \u2026',\n    return_accepts=True, var='response', key_filter=my_filter_function\n)\nform.set_widget(text_input, (0, 0))\nform._exec()\n~~~",
    "title": "Form widgets and keywords",
    "url": "https://osdoc.cogsci.nl/4.1/manual/forms/widgets",
    "path": "content/pages/manual/forms/widgets.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Creating custom forms\n\ntitle: Creating custom forms\n\n\n[TOC]\n\n\n## About forms, geometries, and widgets\n\nA form is a set of widgets (buttons, labels, text-input fields, etc.) arranged into a grid with a particular geometry. In the image below you see an example of a 2 (columns) \u00d7 3 (rows) form. A form geometry is simple, and consists of the following properties:\n\n- *margins* ensure that the widgets do not touch the edge of the display. You can have different margins for the top, right, bottom, and left.\n- *spacing* ensure that the widgets do not touch each other. The horizontal and vertical spacing is the same.\n- There are one or more *rows*, possibly of different sizes.\n- There are one or more *columns*, possibly of different sizes.\n\n%--\nfigure:\n id: FigGeometry\n source: geometry.png\n caption: A schematic of FORM geometries.\n--%\n\nOf course, an empty form is no fun. So let's add the following widgets to create a simple question form:\n\n- A `label` that spans the two columns of the top row. We use this label to give a title to the form.\n- Another `label` that spans the two columns of the middle row. This label contains the actual question.\n- A `button` in the bottom right widget area. This button allows the user to give the $0.05 response.\n- Another `button` in the bottom left widget area. This button allows the user to give the $0.10 response.\n\n%--\nfigure:\n id: FigSchematicExample1\n source: schematic-example1.png\n caption: A schematic example FORM.\n--%\n\nThe images above are schematic examples. How this form actually looks in OpenSesame depends on your settings (notably your font and colors), but it may look something like this:\n\n%--\nfigure:\n id: FigExample1\n source: example1.png\n caption: A example FORM.\n--%\n\n## Creating custom forms\n\nThere are two ways to create custom forms. You can:\n\n- Use the FORM_BASE item, and specify your form using OpenSesame script.\n- Using Python in an INLINE_SCRIPT item. The Python way is slightly more flexible, but for most purposes both ways can be used.\n\n### Creating forms using OpenSesame script\n\nWe will create the form described above using OpenSesame script. First, drag the FORM_BASE plugin into your experiment. Click on the newly created item to open its tab. Next, click on the 'Edit script' button (with the terminal icon), in the top-right of the tab area. This will open the script editor. Enter the following script to generate the form described above (see the comments for explanations).\n\n~~~\n# Margins are defined as \"top;right;bottom;left\". Each value corresponds to a\n# margin in pixels.\nset margins \"50;100;50;100\"\n# The spacing is simply a value in pixels.\nset spacing \"25\"\n# The sizes of the rows are relative. \"1;2;1\" means that there are three rows,\n# where the middle one is twice as large as the bottom and top ones. So \"1;2;1\"\n# means exactly the same thing as \"3;6;3\". Please note that \"3\" does not mean\n# that there are three equally-sized rows (but \"1;1;1\" does).\nset rows \"1;2;1\"\n# Columns are defined in the same way. \"1;1\" simply means that there\n# are two columns of the same size.\nset cols \"1;1\"\n# Widgets are defined as follows:\n# widget [column] [row] [column span] [row span] [widget type] [keywords]\n#\n# The columns and rows start counting at 0. If you do not want to have your widget\n# span multiple columns and rows, you simply set the column and row span to 1.\nwidget 0 0 2 1 label text=\"Question\"\nwidget 0 1 2 1 label center=\"no\" text=\"A bat and a baseball together cost $1.10. The bat costs one dollar more than the ball. How much does the ball cost?\"\nwidget 0 2 1 1 button text=\"$0.10\"\nwidget 1 2 1 1 button text=\"$0.05\"\n~~~\n\nIf you want a specific widget to receive the focus when the form is executed, you can apply the `focus=yes` keyword to one of the widgets:\n\n```\nwidget 0 0 1 1 text_input text=\"Initial text\" frame=yes center=no stub=\"Type here \u2026\" return_accepts=yes var=response focus=yes\n```\n\n\n### Creating forms using Python inline script\n\nThe exact same form can be created using an INLINE_SCRIPT and a bit of Python code. You will notice that the Python code somewhat resembles the OpenSesame script shown above. This is no wonder: The FORM_BASE plugin essentially translates the OpenSesame script into Python code.\n\nFirst, drag an INLINE_SCRIPT into your experiment. Select the newly created item to open its tab, and add the following script into the Run phase of the INLINE_SCRIPT item (see the comments for explanations).\n\n~~~ .python\n# Create a form\nform = Form(\n    cols=[1,1], rows=[1,2,1],\n    margins=(50,100,50,100), spacing=25\n)\n# Create four widgets\nlabelTitle = Label(text='Question')\nlabelQuestion = Label(\n    text='A bat and a baseball together cost $1.10. The bat costs one dollar more than the ball. How much does the ball cost?',\n    center=False\n)\nbutton5cts = Button(text='$0.05')\nbutton10cts = Button(text='$0.10')\n# Add the widgets to the form. The position in the form is indicated as a\n# (column, row) tuple.\nform.set_widget(labelTitle, (0,0), colspan=2)\nform.set_widget(labelQuestion, (0,1), colspan=2)\nform.set_widget(button5cts, (0,2))\nform.set_widget(button10cts, (1,2))\n# Execute the form! In this case, the form will return the text of the button that\n# was clicked. This is one way to get a return value out of the form. Another way\n# is to use the 'var' keyword, supported some of the widgets.\nbutton_clicked = form._exec()\n~~~\n\nIf you want a specific widget to receive the focus when the form is executed, you can use the `focus_wiget` keyword:\n\n~~~ .python\nbutton_clicked = form._exec(focus_widget=button5cts)\n~~~\n\n### Non-interactive forms\n\nUsually, a form will have an input field, a button, or some other interactive element. However, you can also use forms without having any interactive element. To do this in OpenSesame script, you set `only_render` to \"yes\":\n\n```python\nset only_render yes\n```\n\nTo this in a Python INLINE_SCRIPT, you call `form.render()`, instead of `form._exec()`.\n\n### Themes\n\nForms support theming. Currently, two themes are available: 'gray' and 'plain'. The 'gray' theme is the default. Although the 'gray' theme is already quite plain, the 'plain' theme is even more basic. You can choose a theme like this in OpenSesame script:\n\n```python\nset theme plain\n```\n\nAnd by using the `theme` keyword in Python inline script:\n\n~~~ .python\nform = Form(theme='plain')\n~~~\n\n### Available widgets and keywords\n\nFor a list of available widgets and keywords, see:\n\n- %link:manual/forms/widgets%\n\n### Validating input\n\nTo see how you can validate form input, see:\n\n- %link:manual/forms/validation%\n\n## Another example\n\nThe following OpenSesame script (in a FORM_BASE plugin) will produce a questionnaire of three rating scales plus a next button:\n\n```python\nset rows \"1;1;1;1;1\"\nset cols \"1;1\"\nwidget 0 0 2 1 label text=\"Indicate how much you agree with the following statements\"\nwidget 0 1 1 1 label center=\"no\" text=\"Forms are easy\"\nwidget 1 1 1 1 rating_scale var=\"question1\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 2 1 1 label center=\"no\" text=\"I like data\"\nwidget 1 2 1 1 rating_scale var=\"question2\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 3 1 1 label center=\"no\" text=\"I like questionnaires\"\nwidget 1 3 1 1 rating_scale var=\"question3\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 4 2 1 button text=\"Next\"\n```\n\nThe following Python inline_script will produce the same questionnaire.\n\n~~~ .python\nform = Form(cols=[1,1], rows=[1,1,1,1,1])\ntitle = Label(\n    text='Indicate how much you agree with the following statement'\n)\nquestion1 = Label(text='Forms are easy', center=False)\nquestion2 = Label(text='I like data', center=False)\nquestion3 = Label(text='I like questionnaires', center=False)\nratingScale1 = RatingScale(\n    var='question1',\n    nodes=['Agree', u\"Don't know\", 'Disagree']\n)\nratingScale2 = RatingScale(\n    var='question2',\n    nodes=['Agree', u\"Don't know\", 'Disagree']\n)\nratingScale3 = RatingScale(var='question3',\n    nodes=['Agree', u\"Don't know\", 'Disagree'])\nnextButton = Button(text='Next')\nform.set_widget(title, (0, 0), colspan=2)\nform.set_widget(question1, (0, 1))\nform.set_widget(question2, (0, 2))\nform.set_widget(question3, (0, 3))\nform.set_widget(ratingScale1, (1, 1))\nform.set_widget(ratingScale2, (1, 2))\nform.set_widget(ratingScale3, (1, 3))\nform.set_widget(nextButton, (0, 4), colspan=2)\nform._exec()\n~~~\n\nThe resulting form looks something like this. (The exact appearance depends on your font, colors, etc.)\n\n%--\nfigure:\n id: FigExample2\n source: example2.png\n caption: Another example FORM.\n--%",
    "title": "Creating custom forms",
    "url": "https://osdoc.cogsci.nl/4.1/manual/forms/custom",
    "path": "content/pages/manual/forms/custom.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Validating form input\n\ntitle: Validating form input\n\n\nTo validate a form, pass a function with the `validator` keyword to `Form()`. In the example below, `my_form_validator()` is used in this way. A validator function should not expect any arguments, and should return a `bool` to indicate whether or not the form validates. If the form does not validate, no error message is shown, but the form simply stays open.\n\nIn addition, you can validate (or filter) input to a `TextInput` widget to exclude certain characters as input. To do so, pass a function with the `key_filter` keyword to `TextInput()`. In the example below, `filter_digits()` is used in this way. A key-filter function should accept a single argument, which corresponds to a single key press, and should return a `bool` to indicate whether or not the key is accepted as input.\n\n~~~ .python\ndef my_form_validator():\n    \"\"\"Checks whether both the gender and age fields have been filled out\"\"\"\n    return gender != 'no' and age != ''\n\n\ndef filter_digits(ch):\n    \"\"\"Allows only digit characters as input\"\"\"\n    return ch in '0123456789'\n\n\n# Define all widgets\nbutton_ok = Button(text='Ok')\nlabel_gender= Label('Your gender')\ncheckbox_male = Checkbox(text='Male', group='gender', var='gender')\ncheckbox_female = Checkbox(text='Female', group='gender', var='gender')\nlabel_age = Label('Your age')\n# Specify a key filter so that only digits are accepted as text input\ninput_age = TextInput(stub='Age here \u2026', var='age', key_filter=filter_digits)\n# Build the form. Specify a validator function to make sure that the form is\n# completed.\nmy_form = Form(validator=my_form_validator, rows=[1,1,1], cols=[1,1,1])\nmy_form.set_widget(label_gender, (0, 0))\nmy_form.set_widget(checkbox_male, (1, 0))\nmy_form.set_widget(checkbox_female, (2, 0))\nmy_form.set_widget(label_age, (0, 1))\nmy_form.set_widget(input_age, (1, 1), colspan=2)\nmy_form.set_widget(button_ok, (1, 2))\nmy_form._exec()\n~~~",
    "title": "Validating form input",
    "url": "https://osdoc.cogsci.nl/4.1/manual/forms/validation",
    "path": "content/pages/manual/forms/validation.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# CSV functions (csv-parse)\n\ntitle: CSV functions (csv-parse)\n\nThe synchronous `parse()` function from the `csv-parse` library is available. This allows you to parse CSV-formatted text, for example from a CSV file in the file pool, into an Object.\n\n__Example:__\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nFor an overview, see:\n\n- <https://csv.js.org/parse/api/sync/#sync-api>",
    "title": "CSV functions (csv-parse)",
    "url": "https://osdoc.cogsci.nl/4.1/manual/javascript/csv",
    "path": "content/pages/manual/javascript/csv.md",
    "topics": [
      "opensesame",
      "inline_javascript"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Python-like iterators (pythonic)\n\ntitle: Python-like iterators (pythonic)\n\nThe `pythonic` library provides Python-like functions for iterating over arrays. Available functions are: `range()`, `enumerate()`, `items()`, `zip()`, and `zipLongest()`.\n\n__Example:__\n\nDraw a five by five grid of incrementing numbers:\n\n```js\nlet positions = xy_grid(5, 50)\nconst cnv = Canvas()\nfor (const [i, [x, y]] of enumerate(positions)) {\n    cnv.text({text: i, x: x, y: y})\n}\ncnv.show()\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/pythonic>",
    "title": "Python-like iterators (pythonic)",
    "url": "https://osdoc.cogsci.nl/4.1/manual/javascript/pythonic",
    "path": "content/pages/manual/javascript/pythonic.md",
    "topics": [
      "opensesame",
      "inline_javascript"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# About JavaScript\n\ntitle: About JavaScript\n\nIn OpenSesame you can create complex experiments using only the graphical user interface (GUI). But you will sometimes encounter situations in which the functionality provided by the GUI is insufficient. In these cases you can add JavaScript code to your experiment.\n\nJavaScript is for experiments that run in a browser with OSWeb. If you need to run your experiment on the desktop, you need to use [Python](%url:manual/python/about%) instead of JavaScript.\n\n__Version note:__ Desktop support for JavaScript was removed in OpeSesame 4.0. This is because JavaScript support on the desktop was incomplete and was perceived by users as confusing without adding much benefit.\n{: .page-notification}\n\n[TOC]\n\n\n## Learning JavaScript\n\nThere are many JavaScript tutorials available online. One good resource is Code Academy:\n\n- <https://www.codecademy.com/learn/introduction-to-javascript>\n\n\n## JavaScript in the OpenSesame GUI\n\n\n### Inline_javascript items\n\nIn order to use JavaScript code you need to add an INLINE_JAVASCRIPT item to your experiment. After you have done this you will see something like %FigInlineJavaScript.\n\n%--\nfigure:\n id: FigInlineJavaScript\n source: inline-javascript.png\n caption: The INLINE_JAVASCRIPT item.\n--%\n\nAs you can see, the INLINE_JAVASCRIPT item consists of two tabs: one for the Prepare phase and one for the Run phase. The Prepare phase is executed first, to allow items to prepare for the time-critical run phase. It is good practice to construct `Canvas` objects during the Prepare phase, so that they can be presented without delay during the Run phase. But this is only convention; you can execute arbitrary JavaScript code during both phases.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Printing output to the console\n\nYou can print to the console with the `console.log()` command:\n\n```js\nconsole.log('This will appear in the console!')\n```\n\nWhen running on the desktop, the output will appear in the OpenSesame console (or: debug window). When running in a browser, the output will appear in the browser console.\n\n\n## Things to know\n\n### Common functions\n\nMany common functions are directly available in an INLINE_JAVASCRIPT item. For example:\n\n```js\n// `Canvas()` is a factory function that returns a `Canvas` object\nlet fixdotCanvas = Canvas()\nif (sometimes()) {  // Sometimes the fixdot is green\n    fixdotCanvas.fixdot({color: 'green'})\n} else {  // Sometimes it is red\n    fixdotCanvas.fixdot({color: 'red'})\n}\nfixdotCanvas.show()\n```\n\nFor a list of common functions, see:\n\n- %link:manual/javascript/common%\n\n\n### Declaring variables (let and var)\n\nINLINE_JAVASCRIPT items are executed in non-strict (or: sloppy) mode. This means that you can assign a value to a variable that was not explicitly declared. When you do this, the variable is implicitly declared using `var` if it wasn't already declared.\n\n```js\nmy_variable = 'my value'  // implicitly declared using var\n```\n\nVariables that are declared implicitly or explicitly using `var` are global, which primarily means that they may be logged by a LOGGER. Variables that are declared using `let` are not global, which primarily means that they are not logged by a LOGGER.\n\n```js\nthis_is_a_global_variable = 'my value'\nvar this_is_also_a_global_variable = 'my value'\nlet this_is_not_a_global_variable = 'my value'\n```\n\n\n### The `persistent` object: preserving objects across scripts\n\n__Version note__ As of OSWeb 2.0, all JavaScript code is executed in the same workspace and objects are therefore preserved across scripts. This means that you no longer need the `persistent` object.\n{:.page-notification}\n\nEach INLINE_JAVASCRIPT item is executed in its own workspace. This means\u2014and this is different from Python INLINE_SCRIPT items!\u2014that you cannot use variables or functions that you've declared in one script in another script. As a workaround, you can attach variables or functions as properties to the `persistent` object, which serves as a container of things that you want to preserve across scripts.\n\nThis way you can construct a `Canvas` in one INLINE_JAVASCRIPT ...\n\n```js\npersistent.myCanvas = Canvas()\npersistent.myCanvas.fixdot()\n```\n\n.. and show it in another INLINE_JAVASCRIPT:\n\n```js\npersistent.myCanvas.show()\n```\n\n\n### The `vars` object: Access to experimental variables\n\n__Version note__ As of OSWeb 2.0, all experimental variables are available as globals. This means that you no longer need the `vars` object.\n{:.page-notification}\n\nYou can access experimental variables through the `vars` object:\n\n```js\n// OSWeb <= 1.4 (with vars object)\n// Get an experimental variable\nconsole.log('my_variable is: ' + vars.my_variable)\n// Set an experimental variable\nvars.my_variable = 'my_value'\n\n// OSWeb >= 2.0 (without vars object)\n// Get an experimental variable\nconsole.log('my_variable is: ' + my_variable)\n// Set an experimental variable\nmy_variable = 'my_value'\n```\n\n\n### The `pool` object: Access to the file pool\n\nYou access 'files' from the file pool through the `pool` object. The most obvious use of this is to parse CSV files, for example with experimental conditions, from the file pool using the `csv-parse` library (described in more detail below).\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nYou can also play sound files from the file pool directly. Assuming that there is a file called `bark.ogg` in the file pool, you can play it like so:\n\n```js\naudioContext = new (window.AudioContext || window.webkitAudioContext)()\nsource = audioContext.createBufferSource()\nsource.buffer = pool['bark.ogg'].data\nsource.connect(audioContext.destination)\nsource.start(0)\n```\n\nNote that in older versions of OSWeb you could simply use `pool['bark.ogg'].data.play()`. However, this doesn't work anymore since OSWeb has migrated to Web Audio API, which is a more modern and widely supported way to play audio.\n\n\n### The `Canvas` class: Presenting visual stimuli\n\nThe `Canvas` class is used to present visual stimuli. For example, you can show a fixation dot as follows:\n\n```js\nlet myCanvas = Canvas()\nmyCanvas.fixdot()\nmyCanvas.show()\n```\n\nA full overview of the `Canvas` class can be found here:\n\n- %link:manual/javascript/canvas%\n\n## Available JavaScript libraries\n\nThe following JavaScript libraries are included by default:\n\n- [random functions (`random-ext`)](%url:manual/javascript/random%)\n- [Color-conversion functions (`color-convert`)](%url:manual/javascript/color-convert%)\n- [CSV functions (`csv-parse`)](%url:manual/javascript/csv%)\n- [Python-like iterators (`pythonic`)](%url:manual/javascript/pythonic%)\n\nYou can include additional JavaScript libraries by URLs to the libraries in the 'External JavaScript' libraries field of the OSWeb control panel.\n\n\n## Debugging\n\nSee:\n\n- %link:debugging%",
    "title": "About JavaScript",
    "url": "https://osdoc.cogsci.nl/4.1/manual/javascript/about",
    "path": "content/pages/manual/javascript/about.md",
    "topics": [
      "opensesame",
      "inline_javascript"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Common functions\n\ntitle: Common functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a JavaScript API for OpenSesame, software for implementing psychology experiments\n- Explain that these functions are commonly used in combination with `Canvas` functions\n- Provide a bulleted list of all available functions and their parameters. Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n[TOC]\n\n\nThe following functions are available in INLINE_JAVASCRIPT items:\n\n<div class=\"cogsci-jsdoc\" markdown=\"1\">\n\n\n\n## reset\\_feedback()\nResets all feedback variables to their initial state.\n\n\n**Example**  \n```js\nreset_feedback()\n```\n<a name=\"set_subject_nr\"></a>\n\n## set\\_subject\\_nr(nr)\nSets the subject number and parity (even/ odd). This function is called\nautomatically when an experiment is started, so you only need to call it\nyourself if you overwrite the subject number that was specified when the\nexperiment was launched.\n\n\n\n| Param | Type | Description |\n| --- | --- | --- |\n| nr | <code>Number</code> | The subject number |\n\n**Example**  \n```js\nset_subject_nr(1)\nconsole.log('Subject nr = ' + vars.subject_nr)\nconsole.log('Subject parity = ' + vars.subject_parity)\n```\n<a name=\"sometimes\"></a>\n\n## sometimes([p])\nReturns true with a certain probability. (For more advanced randomization,\nuse the `random-ext` package, which is available as `random`.)\n\n\n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| [p] | <code>Number</code> | <code>.5</code> | The probability of returning true |\n\n**Example**  \n```js\nif (sometimes()) {\n  console.log('Sometimes you win')\n} else {\n  console.log('Sometimes you lose')\n}\n```\n<a name=\"xy_from_polar\"></a>\n\n## xy\\_from\\_polar(rho, phi, [pole]) \u21d2 <code>Array.&lt;Number&gt;</code>\nConverts polar coordinates (distance, angle) to Cartesian coordinates\n(x, y).\n\n\n**Returns**: <code>Array.&lt;Number&gt;</code> - An [x, y] array.  \n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| rho | <code>Number</code> |  | The radial coordinate, also distance or eccentricity. |\n| phi | <code>Number</code> |  | The angular coordinate. This reflects a clockwise     rotation in degrees (i.e. not radians), where 0 is straight right. |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | The reference point. |\n\n**Example**  \n```js\n// ECMA 5.1\nvar xy1 = xy_from_polar(100, 45)\nvar xy2 = xy_from_polar(100, -45)\nvar c = Canvas()\nc.line({sx: xy1[0], sy: xy1[1], ex: -xy1[0], ey: -xy1[1]})\nc.line({sx: xy2[0], sy: xy2[1], ex: -xy2[0], ey: -xy2[1]})\nc.show()\n// ECMA 6\nlet [x1, y1] = xy_from_polar(100, 45)\nlet [x2, y2] = xy_from_polar(100, -45)\nlet c = Canvas()\nc.line({sx: x1, sy: y1, ex: -x1, ey: -y1})\nc.line({sx: x2, sy: y2, ex: -x2, ey: -y2})\nc.show()\n```\n<a name=\"xy_to_polar\"></a>\n\n## xy\\_to\\_polar(x, y, [pole]) \u21d2 <code>Array.&lt;Number&gt;</code>\nConverts Cartesian coordinates (x, y) to polar coordinates (distance,\nangle).\n\n\n**Returns**: <code>Array.&lt;Number&gt;</code> - An [rho, phi] array. Here, `rho` is the radial\n    coordinate, also distance or eccentricity. `phi` is the angular\n    coordinate in degrees (i.e. not radians), and reflects a\n    counterclockwise rotation, where 0 is straight right.  \n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| x | <code>Number</code> |  | The X coordinate. |\n| y | <code>Number</code> |  | The Y coordinate |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | The reference point. |\n\n**Example**  \n```js\n// ECMA 5.1 (browser + desktop)\nvar rho_phi = xy_to_polar(100, 100)\nvar rho = rho_phi[0]\nvar phi = rho_phi[1]\n// ECMA 6 (browser only)\nlet [rho, phi] = xy_to_polar(100, 100)\n```\n<a name=\"xy_distance\"></a>\n\n## xy\\_distance(x1, y1, x2, y2) \u21d2 <code>Number</code>\nGives the distance between two points.\n\n\n**Returns**: <code>Number</code> - The distance between the two points.  \n\n| Param | Type | Description |\n| --- | --- | --- |\n| x1 | <code>Number</code> | The x coordinate of the first point. |\n| y1 | <code>Number</code> | The y coordinate of the first point. |\n| x2 | <code>Number</code> | The x coordinate of the second point. |\n| y2 | <code>Number</code> | The y coordinate of the second point. |\n\n<a name=\"xy_circle\"></a>\n\n## xy\\_circle(n, rho, [phi0], [pole]) \u21d2 <code>Array.&lt;Array.&lt;Number&gt;&gt;</code>\nGenerates a list of points (x,y coordinates) in a circle. This can be\nused to draw stimuli in a circular arrangement.\n\n\n**Returns**: <code>Array.&lt;Array.&lt;Number&gt;&gt;</code> - An array of [x,y] coordinate arrays.  \n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| n | <code>Number</code> |  | The number of x,y coordinates to generate. |\n| rho | <code>Number</code> |  | The radial coordinate, also distance or eccentricity,     of the first point. |\n| [phi0] | <code>Number</code> | <code>0</code> | The angular coordinate for the first coordinate.     This is a counterclockwise rotation in degrees (i.e. not radians),     where 0 is straight right. |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | The reference point. |\n\n**Example**  \n```js\n// Draw 8 rectangles around a central fixation dot\n// ECMA 5.1 (browser + desktop)\nvar c = Canvas()\nc.fixdot()\nvar points = xy_circle(8, 100)\nfor (var i in points) {\n  var x = points[i][0]\n  var y = points[i][1]\n  c.rect({x: x - 10, y: y - 10, w: 20, h: 20})\n}\nc.show()\n// ECMA 6 (browser only)\nlet c = Canvas()\nc.fixdot()\nfor (let [x, y] of xy_circle(8, 100)) {\n  c.rect({x: x - 10, y: y - 10, w: 20, h: 20})\n}\nc.show()\n```\n<a name=\"xy_grid\"></a>\n\n## xy\\_grid(n, spacing, [pole]) \u21d2 <code>Array.&lt;Array.&lt;Number&gt;&gt;</code>\nGenerates a list of points (x,y coordinates) in a grid. This can be used\nto draw stimuli in a grid arrangement.\n\n\n**Returns**: <code>Array.&lt;Array.&lt;Number&gt;&gt;</code> - An array of [x,y] coordinate arrays.  \n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| n | <code>Number</code> \\| <code>Array.&lt;Number&gt;</code> |  | A number that indicates the number of     columns and rows, so that `n=2` indicates a 2x2 grid, or a [n_col,     n_row] array, so that `n=[2,3]` indicates a 2x3 grid. |\n| spacing | <code>Number</code> \\| <code>Array.&lt;Number&gt;</code> |  | A numeric value that indicates the     spacing between cells, or a [col_spacing, row_spacing] array. |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | The reference point. |\n\n**Example**  \n```js\n// Draw a 4x4 grid of rectangles\n// ECMA 5 (desktop + browser)\nvar c = Canvas()\nc.fixdot()\nvar points = xy_grid(4, 100)\nfor (var i in points) {\n  var x = points[i][0]\n  var y = points[i][1]\n  c.rect({x: x - 10, y: y - 10, w: 20, h: 20})\n}\nc.show()\n// ECMA 6 (browser only)\nlet c = Canvas()\nc.fixdot()\nfor (let [x, y] of xy_grid(4, 100)) {\n  c.rect({x: x-10, y: y-10, w: 20, h: 20})\n}\nc.show()\n```\n<a name=\"xy_random\"></a>\n\n## xy\\_random(n, width, height, [min_dist], [pole]) \u21d2 <code>Array.&lt;Array.&lt;Number&gt;&gt;</code>\nGenerates a list of random points (x,y coordinates) with a minimum\nspacing between each pair of points. This function will throw an error\nwhen the coordinate list cannot be generated, typically because there are\ntoo many points, the min_dist is set too high, or the width or height are\nset too low.\n\n\n**Returns**: <code>Array.&lt;Array.&lt;Number&gt;&gt;</code> - An array of [x,y] coordinate arrays.  \n\n| Param | Type | Default | Description |\n| --- | --- | --- | --- |\n| n | <code>Number</code> |  | The number of points to generate. |\n| width | <code>Number</code> |  | The width of the field with random points. |\n| height | <code>Number</code> |  | The height of the field with random points. |\n| [min_dist] | <code>Number</code> | <code>0</code> | The minimum distance between each point. |\n| [pole] | <code>Array.&lt;Number&gt;</code> | <code>[0, 0]</code> | The reference point. |\n\n**Example**  \n```js\n// Draw a 50 rectangles in a random grid\n// ECMA 5 (desktop + browser)\nvar c = Canvas()\nc.fixdot()\nvar points = xy_random(50, 500, 500, 40)\nfor (var i in points) {\n  var x = points[i][0]\n  var y = points[i][1]\n  c.rect({x: x - 10, y: y - 10, w: 20, h: 20})\n}\nc.show()   \n// ECMA 6 (browser only)\nlet c = Canvas()\nc.fixdot()\nfor (let [x, y] of xy_random(50, 500, 500, 40)) {\n  c.rect({x: x-10, y: y-10, w: 20, h: 20})\n}\nc.show()\n```\n\n\n</div>",
    "title": "Common functions",
    "url": "https://osdoc.cogsci.nl/4.1/manual/javascript/common",
    "path": "content/pages/manual/javascript/common.md",
    "topics": [
      "opensesame",
      "inline_javascript"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# random functions (random-ext)\n\ntitle: random functions (random-ext)\n\n\nThe `random-ext` library is available as `random`. This library provides many convenient, higher-level functions for randomization.\n\n__Example:__\n\nDraw eight circle with a random color and a location that is randomly sampled from a five by five grid:\n\n```js\nlet positions = xy_grid(5, 50)\npositions = random.subArray(positions, 8)\nconst cnv = Canvas()\ncnv.fixdot()\nfor (const [x, y] of positions) {\n    cnv.circle({x: x, y: y, r: 20, fill: true, color: random.color()})\n}\ncnv.show()\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/random-ext>",
    "title": "random functions (random-ext)",
    "url": "https://osdoc.cogsci.nl/4.1/manual/javascript/random",
    "path": "content/pages/manual/javascript/random.md",
    "topics": [
      "opensesame",
      "inline_javascript"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Canvas functions\n\ntitle: Canvas functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a JavaScript API for OpenSesame, software for implementing psychology experiments\n- Explain the process to initialize a `Canvas`\n- Define the usage of `styleArgs`\n- Explain coordinates: x=0, y=0 is the display center\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"cogsci-jsdoc\" markdown=\"1\">\n\nThe `Canvas` class is used to present visual stimuli. You generally\ncreate a `Canvas` object with the `Canvas()` factory function. Because\n`Canvas()` is a function, you do *not* need to use `new` when calling it.\nThe JavaScript `Canvas` class mimicks the corresponding Python `Canvas`\nclass.\n\n__Style keywords__ can be passed to all functions that accept `styleArgs`.\nStyle keywords can also be set as properties of the `Canvas` object. For an\noverview of style keywords, see the\n[Python `Canvas` documentation](%url:manual/python/canvas%).\n\n__Important:__ JavaScript doesn't support named parameters (or: keywords).\nTherefore, parameters are passed an `Object` with named properties and\ndefault values. Like so:\n\n```js\nvar myCanvas = Canvas()\n// (correct) pass parameters as an Object ...\nmyCanvas.fixdot({color: 'red'})\n// (incorrect) ... and *not* as named parameters\n// myCanvas.fixdot(color='red')\nmyCanvas.show()\n```\n\n[TOC]\n\n<a name=\"Canvas.arrow\"></a>\n\n### Canvas.arrow(obj)\nDraws an arrow. An arrow is a polygon consisting of 7 vertices, with an\narrowhead pointing at (ex, ey).\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.sx | <code>Number</code> | <code>0</code> | \n| obj.sy | <code>Number</code> | <code>0</code> | \n| obj.ex | <code>Number</code> | <code>50</code> | \n| obj.ey | <code>Number</code> | <code>0</code> | \n| obj.body_length | <code>Number</code> | <code>0.8</code> | \n| obj.body_width | <code>Number</code> | <code>0.5</code> | \n| obj.head_width | <code>Number</code> | <code>30</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nvar w = vars.width / 2\nvar h = vars.height / 2\n// Important: parameters are passed as an Object\nmyCanvas.arrow({sx: 0, sy: 0, w: w, h: h, head_width:100, body_length:0.5})\n```\n<a name=\"Canvas.clear\"></a>\n\n### Canvas.clear([styleArgs])\nClears the canvas with the current background color. Note that it is\n\t generally faster to use a different canvas for each experimental\n\t display than to use a single canvas and repeatedly clear and redraw\n\t it.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| [styleArgs] | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.fixdot({color: 'green'})\nmyCanvas.show()\n// do something\nmyCanvas.clear()\nmyCanvas.fixdot({color: 'red'})\nmyCanvas.show()\n```\n<a name=\"Canvas.circle\"></a>\n\n### Canvas.circle(obj)\nDraws a circle.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.r | <code>Number</code> | <code>50</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.circle({x: 100, y: 100, r: 50, fill: true, color:'red'})\n```\n<a name=\"Canvas.ellipse\"></a>\n\n### Canvas.ellipse(obj)\nDraws an ellipse.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>-50</code> | \n| obj.y | <code>Number</code> | <code>-25</code> | \n| obj.w | <code>Number</code> | <code>100</code> | \n| obj.h | <code>Number</code> | <code>50</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.ellipse({x: -10, y: -10, w: 20, h: 20, fill:true})\n```\n<a name=\"Canvas.fixdot\"></a>\n\n### Canvas.fixdot(obj)\nDraws a fixation dot. The default style is medium-open.\n\n- 'large-filled' is a filled circle with a 16px radius.\n- 'medium-filled' is a filled circle with an 8px radius.\n- 'small-filled' is a filled circle with a 4px radius.\n- 'large-open' is a filled circle with a 16px radius and a 2px hole.\n- 'medium-open' is a filled circle with an 8px radius and a 2px hole.\n- 'small-open' is a filled circle with a 4px radius and a 2px hole.\n- 'large-cross' is 16px cross.\n- 'medium-cross' is an 8px cross.\n- 'small-cross' is a 4px cross.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.style | <code>String</code> | <code>&#x27;default&#x27;</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.fixdot()\n```\n<a name=\"Canvas.gabor\"></a>\n\n### Canvas.gabor(obj)\nDraws a gabor patch.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.orient | <code>Number</code> | <code>0</code> | \n| obj.freq | <code>Number</code> | <code>.1</code> | \n| obj.env | <code>String</code> | <code>&#x27;gaussian&#x27;</code> | \n| obj.size | <code>Number</code> | <code>96</code> | \n| obj.stdev | <code>Number</code> | <code>12</code> | \n| obj.phase | <code>Number</code> | <code>0</code> | \n| obj.col1 | <code>String</code> | <code>&#x27;white&#x27;</code> | \n| obj.col2 | <code>String</code> | <code>&#x27;black&#x27;</code> | \n| obj.bgmode | <code>String</code> | <code>&#x27;avg&#x27;</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.gabor({x: 100, y: 100, orient: 45, freq: .05})\n```\n<a name=\"Canvas.image\"></a>\n\n### Canvas.image(obj)\nDraws an image from a file in the file pool.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.fname | <code>String</code> |  | \n| obj.center | <code>Boolean</code> | <code>true</code> | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.scale | <code>Number</code> | <code>1</code> | \n| obj.rotation | <code>Number</code> | <code>0</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.image({fname: 'image_in_pool.png'})\n```\n<a name=\"Canvas.line\"></a>\n\n### Canvas.line(obj)\nDraws a line.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.sx | <code>Number</code> | <code>0</code> | \n| obj.sy | <code>Number</code> | <code>0</code> | \n| obj.ex | <code>Number</code> | <code>50</code> | \n| obj.ey | <code>Number</code> | <code>0</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nvar ex = vars.width / 2\nvar ey = vars.height / 2\nmyCanvas.line({sx: 0, sy: 0, ex: ex, ey: ey})\n```\n<a name=\"Canvas.noise_patch\"></a>\n\n### Canvas.noise\\_patch(obj)\nDraws a patch of noise, with an envelope.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| obj.env | <code>String</code> | <code>&#x27;gaussian&#x27;</code> | \n| obj.size | <code>Number</code> | <code>96</code> | \n| obj.stdev | <code>Number</code> | <code>12</code> | \n| obj.col1 | <code>String</code> | <code>&#x27;white&#x27;</code> | \n| obj.col2 | <code>String</code> | <code>&#x27;black&#x27;</code> | \n| obj.bgmode | <code>String</code> | <code>&#x27;avg&#x27;</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.noise_patch({x: 100, y: 100, env: 'circular'})\n```\n<a name=\"Canvas.polygon\"></a>\n\n### Canvas.polygon(obj)\nDraws a polygon that defined by a list of vertices. I.e. a shape of\npoints connected by lines.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.vertices | <code>Array.&lt;Array.&lt;Number&gt;&gt;</code> |  | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nvar n1 = [0,0]\nvar n2 = [100, 100]\nvar n3 = [0, 100]\nmyCanvas.polygon({vertices: [n1, n2, n3]})\n```\n<a name=\"Canvas.rect\"></a>\n\n### Canvas.rect(obj)\nDraws a rectangle.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.x | <code>Number</code> | <code>-50</code> | \n| obj.y | <code>Number</code> | <code>-25</code> | \n| obj.w | <code>Number</code> | <code>100</code> | \n| obj.h | <code>Number</code> | <code>50</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.rect({x: -10, y: -10, w: 20, h: 20, fill:true})\n```\n<a name=\"Canvas.show\"></a>\n\n### Canvas.show() \u21d2 <code>Number</code>\nShows, or 'flips', the canvas on the screen.\n\n\n**Returns**: <code>Number</code> - A timestamp of the time at which the canvas appeared on\n    the screen.  \n<a name=\"Canvas.text\"></a>\n\n### Canvas.text(obj)\nDraws text.\n\n\n\n| Param | Type | Default |\n| --- | --- | --- |\n| obj | <code>Object</code> |  | \n| obj.text | <code>String</code> |  | \n| obj.center | <code>Boolean</code> | <code>true</code> | \n| obj.x | <code>Number</code> | <code>0</code> | \n| obj.y | <code>Number</code> | <code>0</code> | \n| ..obj.styleArgs | <code>Object</code> | <code>{}</code> | \n\n**Example**  \n```js\nvar myCanvas = Canvas()\nmyCanvas.text({text: 'Some text'})\n```\n\n\n</div>",
    "title": "Canvas functions",
    "url": "https://osdoc.cogsci.nl/4.1/manual/javascript/canvas",
    "path": "content/pages/manual/javascript/canvas.md",
    "topics": [
      "opensesame",
      "inline_javascript"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Color conversion functions (color-convert)\n\ntitle: Color conversion functions (color-convert)\n\n\nThe `color-convert` library is available as `convert`. It provides convenient high level functions for converting from one color specification to another.\n\n__Example:__\n\n```js\nconsole.log('The RGB values for blue are ' + convert.keyword.rgb('blue'))\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/color-convert>",
    "title": "Color conversion functions (color-convert)",
    "url": "https://osdoc.cogsci.nl/4.1/manual/javascript/color-convert",
    "path": "content/pages/manual/javascript/color-convert.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Downloading and converting data\n\ntitle: Downloading and converting data\n\nAfter collecting data with OSWeb through JATOS, you can download and process this data for analysis. To download, navigate to your study within JATOS, click on 'Results', select all Result entries, and then choose 'Export Results \u2192 JATOS Results Archive' (see %FigJatosExportResults).\n\n%--\nfigure:\n id: FigJatosExportResults\n source: jatos-export-results.png\n caption: Procedure for exporting results collected with OSWeb through JATOS.\n--%\n\nThe downloaded file, typically named in the format `jatos_results_<timestamp>.jzip`, contains various folders and files corresponding to metadata and participant data. This format can be difficult to work with directly for data analysis.\n\nTo simplify data analysis, you can convert this file to a more accessible format like `.csv` or `.xlsx`. This conversion can be easily achieved by using the 'Convert OSWeb results to csv/xlsx' option found in the OSWeb extension.",
    "title": "Downloading and converting data",
    "url": "https://osdoc.cogsci.nl/4.1/manual/osweb/data",
    "path": "content/pages/manual/osweb/data.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Running experiments online with OSWeb\n\ntitle: Running experiments online with OSWeb\n\n\n[TOC]\n\n\n## The workflow\n\nFor an introduction to the workflow, see also:\n\nMath\u00f4t, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n<br /><small>[Related preprint (not identical to published manuscript)](https://doi.org/10.31234/osf.io/wnryc)</small>\n\n\n### Developing your experiment\n\nFirst, you develop your experiment as you ordinarily would, using the OpenSesame desktop application. Not all functionality is available in online experiments. Notably, you cannot use Python INLINE_SCRIPT items, but have to use JavaScript INLINE_JAVASCRIPT items instead. During the development of your experiment, it is therefore important to check that your experiment is compatible with OSWeb.\n\n- %link:manual/osweb/osweb%\n- %link:manual/javascript/about%\n\n\n### Uploading your experiment to JATOS\n\nOnce you have developed your experiment, you publish it to JATOS. JATOS is a web server that manages experiments: it allows you to generate links that you can distribute participants, and it stores data that has been collected.\n\nThere is not a single JATOS server. Rather, many institutions maintain their own JATOS server. In addition, <https://mindprobe.eu> is a free JATOS server, sponsored by ESCoP and OpenSesame.\n\n- %link:jatos%\n\n\n### Collecting data\n\nOne you have published your experiment to JATOS, you can start collecting data. You can do this by manually sending links to participants, for example through email. Or you can use a platform for participant recruitment, such as Prolific, Mechanical Turk, or Sona Systems.\n\n- %link:prolific%\n- %link:mturk%\n- %link:sonasystems%\n\n\n### Analyzing data\n\nOnce data collection is finished, you can download the data from JATOS and convert it to `.xlsx` or `.csv` format for further analysis:\n\n- %link:manual/osweb/data%\n\n\n## Tutorials\n\n- %link:tutorials/intermediate-javascript%\n- %link:wcst%",
    "title": "Running experiments online with OSWeb",
    "url": "https://osdoc.cogsci.nl/4.1/manual/osweb/workflow",
    "path": "content/pages/manual/osweb/workflow.md",
    "topics": [
      "opensesame",
      "inline_javascript"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# JATOS\n\ntitle: JATOS\n\n\n[TOC]\n\n\n## Introduction to JATOS\n\n[JATOS](https://www.jatos.org/) is a system for managing online experiments. It allows you to create accounts for experimenters, upload experiments, and generate links that you can distribute to participants. OpenSesame integrates closely with JATOS.\n\nTo access a JATOS server, you have three main options:\n\n- Request a free account on [MindProbe](https://mindprobe.eu/), a public JATOS server sponsored by ESCoP and OpenSesame.\n- se a JATOS server provided by your institution.\n- Download JATOS and install it on your own server.\n\n## Linking OpenSesame with JATOS/MindProbe\n\nOpenSesame requires an API token to access your account on a JATOS server such as MindProbe. Follow these steps to generate an API token:\n\n1. **Log into JATOS.**\n2. **Open your user profile** by clicking on your name located in the top right corner of the page.\n3. **Create an API token** by clicking on 'API tokens' to view all your current tokens, and then click 'New Token'.\n4. **Assign a name to your token**. This name serves as a descriptor indicating its intended use, such as 'OpenSesame integration'.\n5. **Set an expiration for your token**. Tokens default to expire after 30 days, requiring you to generate a new token each month. You can select 'No Expiration' for convenience, but be aware that it is less secure. If someone gains access to a non-expiring token, they can use it indefinitely, or until you revoke the token.\n\n%--\nfigure:\n id: FigAPIToken\n source: api-token.png\n caption: API tokens can be generated within your JATOS user profile.\n--%\n\nNote: An API token always begins with `jap_`, followed by a series of characters and numbers. Keep your token secure!\n\nOnce you have your API token, open the OSWeb and JATOS control panel in OpenSesame. Enter your API token into the corresponding field and also adjust the JATOS server URL, if necessary.\n\n%--\nfigure:\n id: FigJATOSControlPanel\n source: jatos-control-panel.png\n caption: Specify the JATOS server and your API token in the OSWeb and JATOS control panel.\n--%\n\n\n## Publishing experiments to, and downloading from, JATOS/MindProbe\n\nAfter successfully connecting OpenSesame to JATOS, as explained above, you can publish your experiment to JATOS. To do this, select the 'Publish to JATOS/MindProbe' option from the File menu. Upon initial publication, your experiment will be assigned a unique identifier (UUID) that links it to a study on JATOS.\n\nYou can then visit your JATOS server and observe that the newly published experiment has been added to your list of studies.\n\nFrom that point forward, each time you publish the experiment, the existing JATOS study will be updated with the new version. If you wish to publish the experiment as a completely new study on JATOS, you will need to reset the JATOS UUID via the OSWeb and JATOS control panel.\n\nTo download an experiment from JATOS, select the 'Open from JATOS/MindProbe' option from the File menu. Please note, this function is only applicable if the corresponding JATOS study is compatible with OSWeb 2.",
    "title": "JATOS",
    "url": "https://osdoc.cogsci.nl/4.1/manual/osweb/jatos",
    "path": "content/pages/manual/osweb/jatos.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Inline JavaScript\n\ntitle: Inline JavaScript\n\nThis page has moved to:\n\n- %link:manual/javascript/about%",
    "title": "Inline JavaScript",
    "url": "https://osdoc.cogsci.nl/4.1/manual/osweb/javascript",
    "path": "content/pages/manual/osweb/javascript.md",
    "topics": [
      "opensesame",
      "inline_javascript"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Sona Systems\n\ntitle: Sona Systems\n\n\n[TOC]\n\n\n## About Sona Systems\n\nSona Systems is an online tool that many universities use for recruiting participants, granting course credit to student participants, etc.\n\nSee also:\n\n- <https://www.sona-systems.com/help/integration_test.aspx>\n\n\n## Create a study on JATOS\n\nFirst, import your experiment into JATOS, as described above. Next, go the Worker & Batch Manager, activate the General Multiple Worker, get a URL by clicking on Get Link, and copy it.\n\n\n## Create a study on Sona Systems\n\nNext, create a study on Sona Systems. Insert the JATOS study URL in the field labeled \"Study URL\". This will tell Sona Systems how to start the experiment. Importantly, add the following to the end of the URL (this will pass the participant's Sona ID to your experiment):\n\n```bash\n?SONA_ID=%SURVEY_CODE%  \n```\n\nSona Systems does not use a Redirect URL. This means that Sona Systems will not automatically know whether or not the participant finished the study.\n\n\n## Register the Sona ID in your experiment\n\nEvery participant from Sona is identified by a unique ID. It's important to log this ID in your experiment, because this allows you to tell which participant from Sona corresponds to which entry in the JATOS results. You can do this by adding the script below in the Prepare phase of an `inline_javascript` item at the very start of your experiment.\n\nWhen running the experiment through Sona, this will make the Sona ID available as the experimental variable `sona_participant_id`. When the running the experiment in any other way (e.g. during testing), the variable `sona_participant_id` will be set to -1. \n\n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.SONA_ID) {\n    console.log('Sona information is available')\n    var sona_participant_id = jatos.urlQueryParameters.SONA_ID\n} else {\n    console.log('Sona information is not available (setting value to -1)')\n    var sona_participant_id = -1\n}\nconsole.log('sona_participant_id = ' + sona_participant_id)\n```\n\n\n## Automatically grant credits on study completion\n\nSona Systems provides a completion URL (client-side), which should be called when a study is succesfully completed, so that Sona Systems can grant credit to the participant (see %FigCompletionURL).\n\n%--\nfigure:\n id: FigCompletionURL\n source: completion-url.png\n caption: The completion URL in the Sona Systems study information.\n--%\n\nThe completion URL (client side) has three arguments in it:\n\n- `experiment_id` which identifies the study and is the same for all participants\n- `credit_token` which (apparently) changes when you change the study information, but is otherwise the same for all participants\n- `survey_code` which corresponds to the Sona Participant ID, and is therefore different for each participant\n\nCopy the completion URL, and replace the `XXX` by `[SONA_ID]`. Go to Study Properties on JATOS, and insert the resulting URL into the End Redirect URL field.\n\n%--\nfigure:\n id: FigEndRedirectURL\n source: end-redirect-url.png\n caption: The end-redirect URL in the JATOS study properties.\n--%",
    "title": "Sona Systems",
    "url": "https://osdoc.cogsci.nl/4.1/manual/osweb/sonasystems",
    "path": "content/pages/manual/osweb/sonasystems.md",
    "topics": [
      "opensesame",
      "inline_javascript"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# OSWeb\n\ntitle: OSWeb\n\n\n[TOC]\n\n\n## About OSWeb\n\nOSWeb is an online runtime for OpenSesame experiments. It is a JavaScript library that executes OpenSesame experiments in a browser. To use OSWeb, you need the `opensesame-extension-osweb` package, which comes pre-installed with the Windows and macOS distributions of OpenSesame.\n\n\n## Executing an experiment in a web browser\n\nTo run an experiment in a web browser using OSWeb, follow these steps:\n\n1. Open the Experiment Properties and select 'In a browser with OSWeb (osweb)' in the 'Run experiment' section.\n2. Click any of the 'Run' buttons to start the experiment.\n3. If the experiment is not compatible with OSWeb, an error message will appear that details the compatibility issues. (Refer to the 'supported functionality' section for more details.)\n4. If there are no compatibility issues, the experiment will open in a new browser window. Note that even though the experiment is running in a web browser, it is still executing locally on your own computer. To host the experiment online, you need to publish it to [JATOS](%url:jatos%).\n5. When the experiment is finished, the data will be downloaded in `.json` format. This data file can then be [converted to `.xlsx` or `.csv` format](%url:manual/osweb/data%) for further analysis.\n\n\n%--\nfigure:\n id: FigTestRun\n source: testrun.png\n caption: Open the Experiment Properties and select 'In a browser with OSWeb (osweb)' under 'Run experiment'.\n--%\n\n\n## OSWeb control panel\n\nFor more control over OSWeb experiments, you can access the OSWeb and JATOS control panel from the Tools menu. This panel offers a range of configuration options:\n\n- **Possible subject numbers:** When running an experiment from within JATOS, a subject number is randomly selected from this list. You can specify individual numbers using commas (e.g., '1,2,3') or number ranges (e.g., '1-10'). When running an experiment from within OpenSesame, this option does not apply, as the subject number is specified when the experiment starts.\n- **Make browser fullscreen:** This option determines whether the browser should switch to fullscreen mode when an experiment starts within JATOS. If you're running an experiment directly from OpenSesame, this option is ignored; instead, you can run the experiment fullscreen by using the regular Run button, while the Quick Run button does not enable fullscreen.\n- **Show OSWeb Welcome Screen:** This toggle controls whether participants will see a welcome screen before the experiment starts. The welcome screen can convey crucial information to participants. Additionally, it serves a technical purpose\u2014due to browser-security policies, media playback and certain functionality is only available if the experiment is initiated by a user action. Therefore, it is generally recommended to leave this option enabled.\n- **Bypass Compatibility Check:** Enabling this option allows you to run the experiment even when the OSWeb compatibility check fails. Note that doing so will not automagically resolve compatibility issues!\n- **Welcome Text:** This field allows you to customize the welcome message displayed to participants on the welcome screen.\n- **External Libraries:** This field lets you specify any external libraries that should be loaded with your experiment. The use of external libraries is explained in more detail in the section below.\n\n\n%--\nfigure:\n id: FigOSWebControlPanel\n source: osweb-control-panel.png\n caption: The OSWeb and JATOS control panel offers a range of configuration options for your OSWeb experiments.\n--%\n\n\n## Supported functionality\n\nWhen you run the experiment from within OpenSesame, a compatibility check is automatically performed. However, this check is fairly superficial. A more complete overview of supported functionality can be found below.\n\n\n- `advanced_delay`\n- `feedback`\n    - See `sketchpad`\n- `form_consent` (supported >= v1.4)\n- `form_text_display` (supported >= 1.4)\n- `form_text_input` (supported >= 1.4)\n    - Unsupported: fullscreen mode\n- `form_multiple_choice` (supported >= 1.4)\n- `inline_html` (supported >= 1.4)\n- `inline_javascript`\n- `keyboard`\n    - Unsupported: key release\n    - Unsupported: HSV, HSL, and CIELab color spaces\n- `logger`\n- `loop`\n    - Unsupported: resume after break\n    - Unsupported: Disabling of evaluate on first cycle\n    - Unsupported: constraints (pseudorandomization)\n    - Supported >= 1.4: file source\n- `mouse`\n    - Unsupported: mouse release\n    - Unsupported: linked sketchpad\n- `notepad`\n- `repeat_cycle`\n- `reset_feedback`\n- `sampler`\n    - Supported >= 1.4.12: panning, pitch, and fade in\n    - Supported >= 1.4.12: Sound playback on Safari on Mac OS or any browser on iOS\n    - Unsupported: stop after\n- `sequence`\n- `sketchpad`\n    - Unsupported: named elements\n    - Supported >= 1.4: image rotation\n    - Unsupported: HSV, HSL, and CIELab color spaces\n- `touch_response`\n\n\nThe compatibility check may also indicate errors of the following type:\n\n> The prepare phase for item new_logger is called multiple times in a row\n\nThis error results from how the experiment is structured, and specifically the use of linked copies. It's not always easy to understand where this error comes from, but you can read more about the prepare-run strategy in [this article](%url:prepare-run%). As a workaround, you can put the problematic items in a dummy LOOP, that is, a LOOP that simply calls the item once.\n\n\n## Including external JavaScript packages\n\nYou can include external JavaScript packages by entering URLs to these packages (one URL per line) in the input field labeled 'External JavaScript libraries'. These packages are then included with `<script>` tags in the head of the HTML.\n\nFor example, you can include [WebGazer](%url:webgazer%) for in-browser by entering the following link:\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```\n\n\n## Debugging\n\nSee:\n\n- %link:debugging%",
    "title": "OSWeb",
    "url": "https://osdoc.cogsci.nl/4.1/manual/osweb/osweb",
    "path": "content/pages/manual/osweb/osweb.md",
    "topics": [
      "opensesame",
      "inline_javascript"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Questionnaires in OSWeb\n\ntitle: Questionnaires in OSWeb\n\n\n## Forms and custom HTML\n\nForms and custom HTML are supported as of OSWeb 1.4\n{:.page-notification}\n\nYou can use the form plugins as described here:\n\n- %link:manual/forms/about%\n\nThe FORM_BASE plugin is *not* supported in OSWeb. Instead, you can use the INLINE_HTML item to implement custom HTML forms, as described here:\n\n- %link:manual/forms/html%\n\n\n## Linking to a different platform\n\nAs an alternative, you can implement a questionnaire using another platform, such as [LimeSurvey](https://www.limesurvey.org/), and then link to this questionnaire from your OSWeb experiment. The video below shows how to do this in such a way that you can tell afterwards which questionnaire data belongs to which OSWeb data.\n\n%--\nvideo:\n source: youtube\n id: BeginnerTutorial\n videoid: 1WvTUQr0JL0\n width: 640\n height: 360\n caption: |\n  Combining OSWeb and LimeSurvey.\n--%",
    "title": "Questionnaires in OSWeb",
    "url": "https://osdoc.cogsci.nl/4.1/manual/osweb/questionnaires",
    "path": "content/pages/manual/osweb/questionnaires.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Mechanical Turk\n\ntitle: Mechanical Turk\n\n\nThere is currently no information that is specific to running OSWeb experiments on Mechanical Turk. For general information about connecting JATOS to Mechanical Turk, see:\n\n- <http://www.jatos.org/Connect-to-Mechanical-Turk.html>",
    "title": "Mechanical Turk",
    "url": "https://osdoc.cogsci.nl/4.1/manual/osweb/mturk",
    "path": "content/pages/manual/osweb/mturk.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Prolific\n\ntitle: Prolific\n\n\n[TOC]\n\n\n## About Prolific\n\n[Prolific](https://prolific.co/) is a commercial tool for recruiting participants for research. To run OSWeb experiments on Prolific, you need to follow the steps explained below.\n\nSee also:\n\n- <http://www.jatos.org/Use-Prolific.html>\n\n\n## Create a study on JATOS\n\nFirst, import your experiment into JATOS, as described above. Next, go the Worker & Batch Manager, activate the General Multiple Worker, get a URL by clicking on Get Link, and copy it (%FigJatosURL).\n\n\n%--\nfigure:\n id: FigJatosURL\n source: jatos-url.png\n caption: Get a study URL from JATOS.\n--%\n\n\n\n## Create a study on Prolific\n\nNext, create a study on Prolific. Under Study Details (%FigProlific), insert the JATOS study URL in the field labeled \"What is the URL of your study?\". This will tell Prolific how to start the experiment. Importantly, add the following to the end of the URL (this will pass important information from Prolific to your experiment):\n\n{% raw %}\n```bash\n&PROLIFIC_PID={{%PROLIFIC_PID%}}&STUDY_ID={{%STUDY_ID%}}&SESSION_ID={{%SESSION_ID%}}\n```\n{% endraw %}\n\nWhen the experiment is finished, Prolific needs to know about it. For this purpose, Prolific uses an End Redirect URL, which is listed in the field labeled \"To prove that participants have completed your study \u2026\". Copy this End Redirect URL. Also check the box labeled \"I've set up my study to redirect to this url at the end\".\n\n%--\nfigure:\n id: FigProlific\n source: prolific.png\n caption: Study details on Prolific.\n--%\n\n\n\n## Set an End Redirect URL in JATOS\n\nNow go back to JATOS, and open the Properties of your study (%FigJatosProperties). There, paste the End Redirect URL that you have copied from Prolific in the field labeled \"End Redirect URL\". This will tell JATOS that the participant should be redirected back to Prolific when the experiment is finished, so that Prolific knows that the participant completed the experiment.\n\n\n%--\nfigure:\n id: FigJatosProperties\n source: jatos-properties.png\n caption: Set the End Redirect URL in JATOS.\n--%\n\n\n## Register Prolific information in your experiment\n\nEvery participant from Prolific is identified by a unique ID. It's important to log this ID in your experiment, because this allows you to tell which participant from Prolific corresponds to which entry in the JATOS results. You can do this by adding the script below in the Prepare phase of an `inline_javascript` item at the very start of your experiment.\n\nWhen running the experiment through Prolific, this will make the Prolific ID available as the experimental variable `prolific_participant_id`. When the running the experiment in any other way (e.g. during testing), the variable `prolific_participant_id` will be set to -1. The same logic applied to the Prolific Study ID (`prolific_study_id`) and the Prolific Session ID (`prolific_session_id`).\n\n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.PROLIFIC_PID) {\n    console.log('Prolific information is available')\n    var prolific_participant_id = jatos.urlQueryParameters.PROLIFIC_PID\n    var prolific_study_id = jatos.urlQueryParameters.STUDY_ID\n    var prolific_session_id = jatos.urlQueryParameters.SESSION_ID\n} else {\n    console.log('Prolific information is not available (setting values to -1)')\n    var prolific_participant_id = -1\n    var prolific_study_id = -1\n    var prolific_session_id = -1\n}\nconsole.log('prolific_participant_id = ' + prolific_participant_id)\nconsole.log('prolific_study_id = ' + prolific_study_id)\nconsole.log('prolific_session_id = ' + prolific_session_id)\n```\n\n\n## Test the study\n\nGo back to the Study Details page on Prolific. At the bottom of the page, there is a Preview button. This allows you to test the experiment by acting as a participant yourself. Don't forget to check the JATOS results to make sure that the experiment has successfully finished, and that all the necessary information (including the Prolific information) has been logged!",
    "title": "Prolific",
    "url": "https://osdoc.cogsci.nl/4.1/manual/osweb/prolific",
    "path": "content/pages/manual/osweb/prolific.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Looping and independent variables\n\ntitle: Looping and independent variables\n\nThe LOOP item has two important functions:\n\n- It runs another item multiple times.\n- It is where you usually define your independent variables; that is, the variables that you manipulate in your experiment.\n\n[TOC]\n\n## The item to run\n\nA LOOP is always connected to a single other item: the item to run. You select the item to run in the box labeled \"Run\". In most cases, the item to run is a SEQUENCE, which runs multiple items sequentially.\n\nTwo common SEQUENCE-LOOP structures are:\n\n- If a SEQUENCE corresponds to a single trial (by convention called *trial_sequence*), then a LOOP that is connected to this sequence corresponds to multiple trials, or a block (by convention called *block_loop*).\n- If a SEQUENCE corresponds to a block of trials followed by a feedback display (by convention called *block_sequence*), then a loop that is connected to this sequence corresponds to multiple blocks, or a complete experimental session (by convention called *experimental_loop*).\n\n## Defining independent variables\n\nThe loop table is a powerful-yet-simple way to define independent variables. Every column in the table corresponds to a variable; every row corresponds to a cycle, that is, a level of the variable. For example, a simple loop with one variable (`animal`) that has two cycles (\"cat\" and \"dog\") looks like this:\n\nanimal |\n------ |\ncat    |\ndog    |\n\nThe loop has a few important options:\n\n*Repeat* indicates how often each cycle should be executed. In the example above, repeat is set to 2, which means that *trial_sequence* is called twice while the variable `animal` has the value \"cat\", and twice while `animal` has the value \"dog\" (so four times in total).\n\n*Order* indicates whether cycles should be executed sequentially or in random order. Randomization is complete, in the sense that the complete list of number-of-cycles \u00d7 repeat trials is randomized.\n\n## Reading independent variables from file\n\nIf you want to read independent variables from file, rather than entering them into the loop table, you can do so as follows:\n\n- Set *Source* to *file*.\n- Select an Excel (`.xlsx`) or CSV (`.csv`) file in the *File* entry.\n\nThe source file follows the same conventions as the loop table; that is, each column corresponds to a variable, and each row corresponds to a cycle.\n\nCSV files are expected to be in the following format:\n\n- plain-text\n- comma-separated\n- double-quoted (literal double-quotes are escaped with backward slashes)\n- UTF-8 encoded\n\n## Breaking the loop\n\nIf you want to break the loop before all cycles have been executed, you can specify a break-if expression. This break-if expression follows the same syntax as other conditional expressions, as described on:\n\n- %link:manual/variables%\n\nFor example, the following break-if statement would break the loop as soon as a correct response is given:\n\n```python\ncorrect == 1\n```\n\nThe *Evaluate on first cycle* option indicates whether the break-if statement should be evaluated before the first cycle, in which case no cycles may be executed at all, or only before the second cycle, in which case at least one cycle is always executed. In some cases, the break-if statement will refer to a variable that is only defined after the first cycle, in which case you should disable the 'Evaluate on first cycle' option to avoid a 'Variable does not exist' error.\n\n## Generating a full-factorial design\n\nBy clicking on the *Full-factorial design* you open a wizard that allows you to easily generate a full-factorial design, that is, a design in which each combination of factors occurs.\n\n## Pseudorandomization\n\nYou can add constraints for pseudorandomization to the script of the loop item. This shuffles the rows, even if Order is set to sequential. (Currently, this is not possible through the GUI.)\n\nExample: Make sure that repetitions of the same word (given by the `word` variable) are separated by at least 4 cycles:\n\n```python\nconstrain word mindist=4\n```\n\nExample: Make sure that the same word is not repeated:\n\n```python\nconstrain word maxrep=1\n```\n\n`constrain` commands must come *after* `setcycle` commands.\n\n## Advanced loop operations\n\nCommands for advanced loop operations must come *after* `constrain` and `setcycle` commands.\n\n### fullfactorial\n\nThe `fullfactorial` instruction treats the loop table as the input for a full-factorial design. For example, the following loop table:\n\ncue   | duration\n----- | --------\nleft  | 0\nright | 100\n      | 200\n\nWould result in:\n\ncue   | duration\n----- | --------\nleft  | 0\nleft  | 100\nleft  | 200\nright | 0\nright | 100\nright | 200\n\n### shuffle\n\n`shuffle` without argument randomizes the entire table. When a column name is specified (`shuffle cue`), only that column is randomized.\n\n### shuffle_horiz\n\n`shuffle_horiz` shuffles all columns horizontally. When multiple columns are specified, only those columns are shuffled horizontally.\n\nFor example, when `shuffle_horiz word1 word2` is applied to the following table:\n\nword1 | word2 | word3\n----- | ----- | -----\ncat   | dog   | bunny\ncat   | dog   | bunny\ncat   | dog   | bunny\n\nThe result could be (i.e. values are randomly swapped between `word1` and `word2`, but not `word3`):\n\nword1 | word2 | word3\n----- | ----- | -----\ndog   | cat   | bunny\ndog   | cat   | bunny\ncat   | dog   | bunny\n\n### slice\n\n`slice [from] [to]` selects a slice from the loop. It requires a start and an end index, where 0 is the first row, and negative values are counted from the end backwards. (Just like list slicing in Python, in other words.)\n\nFor example, when `slice 1 -1` is applied to the following table:\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nThe result would be:\n\nword  |\n----- |\ndog   |\nbunny |\n\n### sort\n\n`sort [column]` sorts a single column, without changing any of the other columns.\n\n### sortby\n\n`sortby [column]` sorts the entire table by a single column.\n\n### reverse\n\n`reverse` reverses the order of the entire table. If a column name is specified (e.g. `reverse word`), only that column is reversed, without changing any of the other columns.\n\n### roll\n\n`roll [value]` rolls the entire table forward (for positive values) or backward (for negative values). If a column name is specified (e.g. `roll 1 word`), only that column is rolled, without changing any of the other columns.\n\nFor example, if `roll 1` is applied to the following table:\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nThe result would be:\n\nword  |\n----- |\nhorse |\ncat   |\ndog   |\nbunny |\n\n### weight\n\n`weight [column]` repeats each row by a weighting value specified in a column.\n\nFor example, if `weight w` is applied to the following table:\n\nword  | w\n----- | -\ncat   | 0\ndog   | 0\nbunny | 2\nhorse | 1\n\nThe result would be:\n\nword  | w\n----- | -\nbunny | 2\nbunny | 2\nhorse | 1\n\n## Previewing the loop\n\nIf you have specified constraints, or have used advanced loop operations, then it is a good idea to check that the result is as expected. To do so, you can generate a preview of the loop table as it will be (or could be, in case of randomization) when you run the experiment.\n\nTo generate a preview, click on the *Preview* button.\n\n\n## Accessing the loop table in Python inline script\n\nThe original LOOP table, as you see it in the OpenSesame user interface, is a [`DataMatrix`](http://datamatrix.cogsci.nl/) object called `dm`, and is a property of the LOOP item.\n\nThis original LOOP table is usually transformed in various ways; for example, the order of the rows can be randomized, and rows can be repeated multiple times. The transformed LOOP is also a `DataMatrix` object, and is called `live_dm`. `live_dm` is created just before the loop is executed and is set to `None` when the loop is finished; that is, `live_dm` is only available during the *run* phase of the LOOP.\n\nFinally, the index of the current row is stored as the experimental variable `live_row`. That is, `live_row` indicates the currently active row of `live_dm`.\n\nSo let's say that we have a LOOP called *block_loop*. We could then access the LOOP table in a Python inline script as follows:\n\n~~~ .python\nprint('The original loop table:')\nprint(items['block_loop'].dm)\n\nprint('The transformed loop table:')\nprint(items['block_loop'].live_dm)\n\nprint('The current row:')\nprint(items['block_loop'].live_dm[var.live_row])\n~~~\n\nYou can even programatically define the LOOP table. You have to do this in the Prepare phase of an INLINE_SCRIPT that precedes the LOOP.\n\n```python\nfrom datamatrix import DataMatrix\n\nitems['block_loop'].dm = DataMatrix(length=4)\nitems['block_loop'].dm.cue_side = 'left', 'right', 'left', 'right'\nitems['block_loop'].dm.cue_validity = 'valid', 'valid', 'invalid', 'invalid'\n```\n\n`DataMatrix` objects are powerful structures for working with tabular data. For more information, see:\n\n- <https://pydatamatrix.eu/>",
    "title": "Looping and independent variables",
    "url": "https://osdoc.cogsci.nl/4.1/manual/structure/loop",
    "path": "content/pages/manual/structure/loop.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Doing things in parallel\n\ntitle: Doing things in parallel\n\n\nCoroutines run multiple items in parallel\u2014or, to be more exact, they run items in rapid alternation in a way that looks parallel. Not all items support coroutines.\n\n\n[TOC]\n\n\n## Using coroutines\n\nYou can use coroutines through the COROUTINES plugin (see %FigCoroutinesInterface).\n\n\n%--\nfigure:\n source: FigCoroutinesInterface.png\n caption: The interface of the coroutines plugin.\n id: FigCoroutinesInterface\n--%\n\n\nAs you can see, the COROUTINES plugin looks similar to the SEQUENCE item, but has a few extra options:\n\n- *Duration* indicates the total duration of the coroutines.\n- *End after item (optional)* indicates that the coroutines should end when a specific item has ended. This allows you, for example, to indicate that the coroutines should end when a key press has been collected, by selecting a KEYBOARD_RESPONSE item here.\n- Each item has a *Start time*. Most items also have an *End time*. The end time does not apply to one-shot items; for example, SKETCHPADs show a display and terminate immediately, so they have no end time.\n\nSpecifically, the example from %FigCoroutinesInterface (from the stop-signal-task example) does the following:\n\n- It shows a target display immediately.\n- If the `stop_after` variable is not empty, it shows the stop_signal display after an interval specified by the `stop_after` variable.\n- During the entire (2000 ms) interval, a keyboard response is collected.\n\nThe temporal flow is controlled by the COROUTINES plugin. Therefore, the timeout and duration values specified in the items are not used. For example, in %FigCoroutinesInterface, the KEYBOARD_RESPONSE will run for 2000 ms, regardless of the timeout that is specified in the item.\n\n\n## Supported items\n\nCurrently, the following items are supported (this list may not be exhaustive):\n\n- FEEDBACK\n- INLINE_SCRIPT\n- KEYBOARD_RESPONSE\n- LOGGER\n- MOUSE_RESPONSE\n- SAMPLER\n- SYNTH\n- SKETCHPAD\n\n\n## Using inline_script items in coroutines\n\nWhen you use an INLINE_SCRIPT item in a COROUTINES, the Run phase works a little differently from what you might be used to. Specifically, the Run phase is executed on every iteration of the COROUTINES. In addition, the Run phase should only contain code that takes very little time to execute; this is because time-consuming operations will block the COROUTINES, thus interfering with the timing of other items in the COROUTINES as well. To end the COROUTINES, you can raise an `AbortCoroutines()` exception.\n\nFor example, say that you have a COROUTINES with two KEYBOARD_RESPONSE items, *kb1* and *kb2*, and you want to run the COROUTINES until two key presses have been collected, with a timeout of 5000 ms. You could then create the following COROUTINES structure:\n\n\n%--\nfigure:\n source: FigCoroutinesTwoResponses.png\n caption: A coroutines that collects two keypress responses\n id: FigCoroutinesTwoResponses\n--%\n\nThe *check_responses* INLINE_SCRIPT would then first set both responses variables to an empty string in the Prepare phase:\n\n```python\n# This is executed at the start of the coroutines\nresponse_kb1 = ''\nresponse_kb2 = ''\n```\n\nAnd then, in the Run phase, check if both variables have been set, and abort the coroutines if this is the case:\n\n```python\n# Values that are not an empty string are True for Python\n# This code will be executed many times!\nif response_kb1 and response_kb2:\n    raise AbortCoroutines()\n```\n\n## Run-if expressions\n\nThe behavior of run-if expressions in COROUTINES is a bit different from that in SEQUENCE items. Specifically, run-if expressions in COROUTINES are evaluated during the prepare phase. See also:\n\n- %link:prepare-run%",
    "title": "Doing things in parallel",
    "url": "https://osdoc.cogsci.nl/4.1/manual/structure/coroutines",
    "path": "content/pages/manual/structure/coroutines.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Doing things in sequence\n\ntitle: Doing things in sequence\n\nThe SEQUENCE item has two important functions:\n\n- It runs multiple other items one after another.\n- It determines which items should, and which shouldn't, be run.\n\nSEQUENCEs are run from top to bottom; that is, the item at the top is run first. The order of a SEQUENCE is always sequential.\n\n## Run-if expressions\n\nYou can use run-if expressions to determine whether or not a particular item should be run. For example, if you want a display to be presented only if a participant has made an incorrect response, you can set the run-if expressions for that item to:\n\n```python\ncorrect == 0\n```\n\nIf you leave the run-if expressions empty or enter `True`, the item will always be run. Run-if expressions use the same syntax as other conditional expressions. For more information, see:\n\n- %link:manual/variables%\n\nRun-if expressions only affect which items are run, not which items are prepared. Phrased differently, the Prepare phase of all items in a SEQUENCE is always executed, regardless of the run-if expressions. See also:\n\n- %link:prepare-run%\n\n\n## Disabling items\n\nTo completely disable an item in a SEQUENCE, right-click on it and select 'Disable'. This is mostly useful during development of your experiment, for example to temporarily bypass the instructions.",
    "title": "Doing things in sequence",
    "url": "https://osdoc.cogsci.nl/4.1/manual/structure/sequence",
    "path": "content/pages/manual/structure/sequence.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# GazePoint / OpenGaze\n\ntitle: GazePoint / OpenGaze\n\nPyGaze offers *experimental* support for GazePoint eye trackers through the OpenGaze API as of OpenSesame 3.3.11. For more information, see:\n\n- %link:pygaze%\n- <https://www.gazept.com/>",
    "title": "GazePoint / OpenGaze",
    "url": "https://osdoc.cogsci.nl/4.1/manual/eyetracking/gazepoint",
    "path": "content/pages/manual/eyetracking/gazepoint.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# WebGazer.js\n\ntitle: WebGazer.js\n\nRequires OSWeb v1.4.6.1\n{:.page-notification}\n\n[TOC]\n\n\n## About WebGazer\n\nWebGazer.js is an eye-tracking library written in JavaScript. You can include it with OSWeb to perform eye tracking in online experiments.\n\n- <https://webgazer.cs.brown.edu/>\n\n\n## Including WebGazer.js in the experiment\n\nWebGazer.js is not bundled with OSWeb by default. However, you can include it as an external library by entering a link to `webgazer.js` under External JavaScript libraries. Currently, a functional link is:\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```\n\nSee also:\n\n- %link:manual/osweb/osweb%\n\n\n## Example experiment\n\nBelow you can download an example experiment that uses WebGazer.js. Participants are first asked to click on and look at a set of dots; this will cause WebGazer.js to automatically perform something akin to a calibration procedure. Next, the experiment shows a simple screen to test the accuracy of gaze-position recording. In general, fine-grained eye tracking is not feasible, but you can tell which quadrant of the screen a participant is looking at. To run this experiment, you need include WebGazer.js in the experiment, as described above. \n\n- %static:attachments/webgazer.osexp%\n\nYou can also launch the experiment directly in the browser:\n\n- <https://jatos.mindprobe.eu/publix/BowSAFY2VWl>",
    "title": "WebGazer.js",
    "url": "https://osdoc.cogsci.nl/4.1/manual/eyetracking/webgazer",
    "path": "content/pages/manual/eyetracking/webgazer.md",
    "topics": [
      "opensesame",
      "inline_javascript"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# EyeTribe\n\ntitle: EyeTribe\n\nThe EyeTribe is supported through PyGaze. For more information, see:\n\n- %link:pygaze%",
    "title": "EyeTribe",
    "url": "https://osdoc.cogsci.nl/4.1/manual/eyetracking/eyetribe",
    "path": "content/pages/manual/eyetracking/eyetribe.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# PyGaze (eye tracking)\n\ntitle: PyGaze (eye tracking)\n\n[TOC]\n\n## About\n\nPyGaze is a Python library for eye tracking. A set of plugins allow you to use PyGaze from within OpenSesame. For more information on PyGaze, visit:\n\n- <http://www.pygaze.org/>\n\nPlease cite PyGaze as:\n\nDalmaijer, E., Math\u00f4t, S., & Van der Stigchel, S. (2014). PyGaze: An open-source, cross-platform toolbox for minimal-effort programming of eyetracking experiments. *Behavior Research Methods*. doi:10.3758/s13428-013-0422-2\n{: .reference}\n\n## Supported eye trackers\n\nPyGaze supports the following eye trackers:\n\n- [EyeLink](%link:eyelink%)\n- [EyeTribe](%link:eyetribe%)\n\nFor the following eye trackers, there is experimental support:\n\n- [EyeLogic](%link:eyelogic%)\n- [GazePoint / OpenGaze](%link:gazepoint%)\n- [SMI](%link:smi%)\n- [Tobii](%link:tobii%)\n\nYou can also perform basic eye tracking in online experiments with WebGazer.js:\n\n- [WebGazer.js](%link:webgazer%)\n\nPyGaze also includes two dummy eye trackers for testing purposes:\n\n- __Simple dummy__ \u2014 Does nothing.\n- __Advanced dummy__ \u2014 Mouse simulation of eye movements.\n\n## Installing PyGaze\n\n### Windows\n\nIf you use the official Windows package of OpenSesame, PyGaze is already installed.\n\n### Ubuntu\n\nIf you use Ubuntu, you can get PyGaze from the Cogsci.nl PPA:\n\n```\nsudo add-apt-repository ppa:smathot/cogscinl\nsudo apt-get update\nsudo apt-get install python-pygaze\n```\n\nOr, if you are using Python 3, change the last comment to:\n\n```\nsudo apt-get install python3-pygaze\n```\n\n## pip install (all platforms)\n\nYou can install PyGaze with `pip`:\n\n```\npip install python-pygaze\n```\n\n### Anaconda (all platforms)\n\n```\nconda install python-pygaze -c cogsci\n```\n\n## PyGaze OpenSesame plugins\n\nThe following PyGaze plugins are available:\n\n- PYGAZE_INIT \u2014 Initializes PyGaze. This plugin is generally inserted at the start of the experiment.\n- PYGAZE_DRIFT_CORRECT \u2014 Implements a drift correction procedure.\n- PYGAZE_START_RECORDING \u2014 Puts PyGaze in recording mode.\n- PYGAZE_STOP_RECORDING \u2014 Puts PyGaze out of recording mode.\n- PYGAZE_WAIT \u2014 Pauses until an event occurs, such as a saccade start.\n- PYGAZE_LOG \u2014 Logs experimental variables and arbitrary text.\n\n## Example\n\nFor an example of how to use the PyGaze plugins, see the PyGaze template that is included with OpenSesame.\n\nBelow is an example of how to use PyGaze in a Python INLINE_SCRIPT:\n\n~~~ .python\n# Create a keyboard and a canvas object\nmy_keyboard = Keyboard(timeout=0)\nmy_canvas = Canvas()\nmy_canvas['dot'] = Circle(x=0, y=0, r=10, fill=True)\n# Loop ...\nwhile True:\n\t# ... until space is pressed\n\tkey, timestamp = my_keyboard.get_key()\n\tif key == 'space':\n\t\tbreak\n\t# Get gaze position from pygaze ...\n\tx, y = eyetracker.sample()\n\t# ... and draw a gaze-contingent fixation dot!\n\tmy_canvas['dot'].x = x + my_canvas.left\n\tmy_canvas['dot'].y = y + my_canvas.top\n\tmy_canvas.show()\n~~~\n\n## Function overview\n\nTo initialize PyGaze in OpenSesame, insert the PYGAZE_INIT plugin into your experiment. Once you have done this, an `eyetracker` object will be available, which offers the following functions:\n\n<div class=\"ClassDoc YAMLDoc\" id=\"eyetracker\" markdown=\"1\">\n\n# class __eyetracker__\n\nA generic Python library for eye tracking.\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-calibrate\" markdown=\"1\">\n\n## function __eyetracker\\.calibrate__\\(\\)\n\nCalibrates the eye tracking system. The actual behavior of this\nfunction depends on the type of eye tracker and is described below.\n\n__EyeLink:__\n\nThis function will activate the camera-setup screen, which allows\nyou to adjust the camera, and peform a calibration/ validation\nprocedure. Pressing 'q' will exit the setup routine. Pressing\n'escape' will first trigger a confirmation dialog and then, upon\nconfirmation, raises an Exception.\n\n__EyeTribe:__\n\nActivates a simple calibration routine.\n\n__Returns:__\n\nReturns True if calibration succeeded, or False if not; in\naddition a calibration log is added to the log file and some\nproperties are updated (i.e. the thresholds for detection\nalgorithms).\n\n- Type: bool\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-close\" markdown=\"1\">\n\n## function __eyetracker\\.close__\\(\\)\n\nNeatly closes connection to tracker. Saves data and sets\n`self.connected` to False.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-connected\" markdown=\"1\">\n\n## function __eyetracker\\.connected__\\(\\)\n\nChecks if the tracker is connected.\n\n__Returns:__\n\nTrue if connection is established, False if not; sets\n`self.connected` to the same value.\n\n- Type: bool\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-draw_calibration_target\" markdown=\"1\">\n\n## function __eyetracker\\.draw\\_calibration\\_target__\\(x, y\\)\n\nDraws a calibration target.\n\n__Arguments:__\n\n- `x` -- The X coordinate\n\t- Type: int\n- `y` -- The Y coordinate\n\t- Type: int\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-draw_drift_correction_target\" markdown=\"1\">\n\n## function __eyetracker\\.draw\\_drift\\_correction\\_target__\\(x, y\\)\n\nDraws a drift-correction target.\n\n__Arguments:__\n\n- `x` -- The X coordinate\n\t- Type: int\n- `y` -- The Y coordinate\n\t- Type: int\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-drift_correction\" markdown=\"1\">\n\n## function __eyetracker\\.drift\\_correction__\\(pos=None, fix\\_triggered=False\\)\n\nPerforms a drift-correction procedure. The exact behavior of this\nfunction on the type of eye tracker and is described below. Because\ndrift correction may fail, you will generally call this function in\na loop.\n\n__EyeLink:__\n\nPressing 'q' during drift-correction will activate the camera-setup\nscreen. From there, pressing 'q' again will cause drift correction\nto fail immediately. Pressing 'escape' will give the option to abort\nthe experiment, in which case an Exception is raised.\n\n__Keywords:__\n\n- `pos` -- (x, y) position of the fixation dot or None for a central fixation.\n\t- Type: tuple, NoneType\n\t- Default: None\n- `fix_triggered` -- Boolean indicating if drift check should be performed based on gaze position (True) or on spacepress (False).\n\t- Type: bool\n\t- Default: False\n\n__Returns:__\n\nA boolean indicating if drift check is ok (True) or not (False).\n\n- Type: bool\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-fix_triggered_drift_correction\" markdown=\"1\">\n\n## function __eyetracker\\.fix\\_triggered\\_drift\\_correction__\\(pos=None, min\\_samples=30, max\\_dev=60, reset\\_threshold=10\\)\n\nPerforms a fixation triggered drift correction by collecting\na number of samples and calculating the average distance from the\nfixation position\n\n__Keywords:__\n\n- `pos` -- (x, y) position of the fixation dot or None for a central fixation.\n\t- Type: tuple, NoneType\n\t- Default: None\n- `min_samples` -- The minimal amount of samples after which an average deviation is calculated.\n\t- Type: int\n\t- Default: 30\n- `max_dev` -- The maximal deviation from fixation in pixels.\n\t- Type: int\n\t- Default: 60\n- `reset_threshold` -- If the horizontal or vertical distance in pixels between two consecutive samples is larger than this threshold, the sample collection is reset.\n\t- Type: int\n\t- Default: 10\n\n__Returns:__\n\nA boolean indicating if drift check is ok (True) or not (False).\n\n- Type: bool\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-get_eyetracker_clock_async\" markdown=\"1\">\n\n## function __eyetracker\\.get\\_eyetracker\\_clock\\_async__\\(\\)\n\nReturns the difference between tracker time and PyGaze time, which can be used to synchronize timing\n\n__Returns:__\n\nThe difference between eyetracker time and PyGaze time.\n\n- Type: int, float\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-log\" markdown=\"1\">\n\n## function __eyetracker\\.log__\\(msg\\)\n\nWrites a message to the log file.\n\n__Arguments:__\n\n- `msg` -- A message.\n\t- Type: str, unicode\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-log_var\" markdown=\"1\">\n\n## function __eyetracker\\.log\\_var__\\(var, val\\)\n\nWrites a variable's name and value to the log file\n\n__Arguments:__\n\n- `var` -- A variable name.\n\t- Type: str, unicode\n- `val` -- A variable value\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-pupil_size\" markdown=\"1\">\n\n## function __eyetracker\\.pupil\\_size__\\(\\)\n\nReturns the newest pupil size sample; size may be measured as the diameter or the area of the pupil, depending on your setup (note that pupil size mostly is given in an arbitrary units).\n\n__Returns:__\n\nReturns pupil size for the eye that is currently being tracked (as specified by self.eye_used) or -1 when no data is obtainable.\n\n- Type: int, float\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-sample\" markdown=\"1\">\n\n## function __eyetracker\\.sample__\\(\\)\n\nReturns newest available gaze position.\n\n__Returns:__\n\nAn (x,y) tuple or a (-1,-1) on an error.\n\n- Type: tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-send_command\" markdown=\"1\">\n\n## function __eyetracker\\.send\\_command__\\(cmd\\)\n\nDirectly sends a command to the eye tracker (not supported for all brands; might produce a warning message if your setup does not support direct commands).\n\n__Arguments:__\n\n- `cmd` -- The command to be sent to the eye tracker.\n\t- Type: str, unicode\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-set_detection_type\" markdown=\"1\">\n\n## function __eyetracker\\.set\\_detection\\_type__\\(eventdetection\\)\n\nSet the event detection type to either PyGaze algorithms, or\nnative algorithms as provided by the manufacturer (only if\navailable: detection type will default to PyGaze if no native\nfunctions are available)\n\n__Arguments:__\n\n- `eventdetection` -- A string indicating which detection type\nshould be employed: either 'pygaze' for\nPyGaze event detection algorithms or\n'native' for manufacturers algorithms (only\nif available; will default to 'pygaze' if no\nnative event detection is available)\n\t- Type: str, unicode\n\n__Returns:__\n\nDetection type for saccades, fixations and blinks in a tuple, e.g. ('pygaze','native','native') when 'native' was passed, but native detection was not available for saccade detection.\n\n- Type: tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-set_draw_calibration_target_func\" markdown=\"1\">\n\n## function __eyetracker\\.set\\_draw\\_calibration\\_target\\_func__\\(func\\)\n\nSpecifies a custom function to draw the calibration target. This will function will override the default [draw_calibration_target].\n\n__Arguments:__\n\n- `func` -- The function to draw a calibration target. This function should accept two parameters, for the x and y coordinate of the target.\n\t- Type: function\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-set_draw_drift_correction_target_func\" markdown=\"1\">\n\n## function __eyetracker\\.set\\_draw\\_drift\\_correction\\_target\\_func__\\(func\\)\n\nSpecifies a custom function to draw the drift-correction target. This function will override the default [draw_drift_correction_target].\n\n__Arguments:__\n\n- `func` -- The function to draw a drift-correction target. This function should accept two parameters, for the x and y coordinate of the target.\n\t- Type: function\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-set_eye_used\" markdown=\"1\">\n\n## function __eyetracker\\.set\\_eye\\_used__\\(\\)\n\nLogs the `eye_used` variable, based on which eye was specified (if both eyes are being tracked, the left eye is used). Does not return anything.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-start_recording\" markdown=\"1\">\n\n## function __eyetracker\\.start\\_recording__\\(\\)\n\nStarts recording. Sets `self.recording` to `True` when recording is successfully started.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-status_msg\" markdown=\"1\">\n\n## function __eyetracker\\.status\\_msg__\\(msg\\)\n\nSends a status message to the eye tracker, which is displayed in the tracker's GUI (only available for EyeLink setups).\n\n__Arguments:__\n\n- `msg` -- A string that is to be displayed on the experimenter PC,\ne.g.: \"current trial: %d\" % trialnr.\n\t- Type: str, unicode\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-stop_recording\" markdown=\"1\">\n\n## function __eyetracker\\.stop\\_recording__\\(\\)\n\nStops recording. Sets `self.recording` to `False` when recording is successfully stopped.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_blink_end\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_blink\\_end__\\(\\)\n\nWaits for a blink end and returns the blink ending time.\nDetection based on Dalmaijer et al. (2013) if EVENTDETECTION is set\nto 'pygaze', or using native detection functions if EVENTDETECTION\nis set to 'native' (NOTE: not every system has native functionality;\nwill fall back to ;pygaze' if 'native' is not available!)\n\n__Returns:__\n\nBlink ending time in milliseconds, as measured from experiment begin time.\n\n- Type: int, float\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_blink_start\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_blink\\_start__\\(\\)\n\nWaits for a blink start and returns the blink starting time.\nDetection based on Dalmaijer et al. (2013) if EVENTDETECTION is set\nto 'pygaze', or using native detection functions if EVENTDETECTION\nis set to 'native' (NOTE: not every system has native functionality;\nwill fall back to ;pygaze' if 'native' is not available!)\n\n__Returns:__\n\nBlink starting time in milliseconds, as measured from experiment begin time\n\n- Type: int, float\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_event\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_event__\\(event\\)\n\nWaits for an event.\n\n__Arguments:__\n\n- `event` -- An integer event code, one of the following:\n\n- 3 = STARTBLINK\n- 4 = ENDBLINK\n- 5 = STARTSACC\n- 6 = ENDSACC\n- 7 = STARTFIX\n- 8 = ENDFIX\n\t- Type: int\n\n__Returns:__\n\nA `self.wait_for_*` method is called, depending on the specified event; the return value of corresponding method is returned.\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_fixation_end\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_fixation\\_end__\\(\\)\n\nReturns time and gaze position when a fixation has ended;\nfunction assumes that a 'fixation' has ended when a deviation of\nmore than self.pxfixtresh from the initial fixation position has\nbeen detected (self.pxfixtresh is created in self.calibration,\nbased on self.fixtresh, a property defined in self.__init__).\nDetection based on Dalmaijer et al. (2013) if EVENTDETECTION is set\nto 'pygaze', or using native detection functions if EVENTDETECTION\nis set to 'native' (NOTE: not every system has native functionality;\nwill fall back to ;pygaze' if 'native' is not available!)\n\n__Returns:__\n\nA `time, gazepos` tuple. Time is the end time in milliseconds (from expstart), gazepos is a (x,y) gaze position tuple of the position from which the fixation was initiated.\n\n- Type: tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_fixation_start\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_fixation\\_start__\\(\\)\n\nReturns starting time and position when a fixation is started;\nfunction assumes a 'fixation' has started when gaze position\nremains reasonably stable (i.e. when most deviant samples are\nwithin self.pxfixtresh) for five samples in a row (self.pxfixtresh\nis created in self.calibration, based on self.fixtresh, a property\ndefined in self.__init__).\nDetection based on Dalmaijer et al. (2013) if EVENTDETECTION is set\nto 'pygaze', or using native detection functions if EVENTDETECTION\nis set to 'native' (NOTE: not every system has native functionality;\nwill fall back to ;pygaze' if 'native' is not available!)\n\n__Returns:__\n\nA `time, gazepos` tuple. Time is the starting time in milliseconds (from expstart), gazepos is a (x,y) gaze position tuple of the position from which the fixation was initiated.\n\n- Type: tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_saccade_end\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_saccade\\_end__\\(\\)\n\nReturns ending time, starting and end position when a saccade is\nended; based on Dalmaijer et al. (2013) online saccade detection\nalgorithm if EVENTDETECTION is set to 'pygaze', or using native\ndetection functions if EVENTDETECTION is set to 'native' (NOTE: not\nevery system has native functionality; will fall back to ;pygaze'\nif 'native' is not available!)\n\n__Returns:__\n\nAn `endtime, startpos, endpos` tuple. Endtime in milliseconds (from expbegintime); startpos and endpos are (x,y) gaze position tuples.\n\n- Type: tuple\n\n</div>\n\n<div class=\"FunctionDoc YAMLDoc\" id=\"eyetracker-wait_for_saccade_start\" markdown=\"1\">\n\n## function __eyetracker\\.wait\\_for\\_saccade\\_start__\\(\\)\n\nReturns starting time and starting position when a saccade is\nstarted; based on Dalmaijer et al. (2013) online saccade detection\nalgorithm if EVENTDETECTION is set to 'pygaze', or using native\ndetection functions if EVENTDETECTION is set to 'native' (NOTE: not\nevery system has native functionality; will fall back to ;pygaze'\nif 'native' is not available!)\n\n__Returns:__\n\nAn `endtime, startpos` tuple. Endtime in milliseconds (from expbegintime); startpos is an (x,y) gaze position tuple.\n\n- Type: tuple\n\n</div>\n\n</div>\n\n",
    "title": "PyGaze (eye tracking)",
    "url": "https://osdoc.cogsci.nl/4.1/manual/eyetracking/pygaze",
    "path": "content/pages/manual/eyetracking/pygaze.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# SMI\n\ntitle: SMI\n\nPyGaze offers *experimental* support for SMI eye trackers. (SMI no longer exists as a company, but its eye trackers are still used in some labs.) For more information, see:\n\n- %link:pygaze%",
    "title": "SMI",
    "url": "https://osdoc.cogsci.nl/4.1/manual/eyetracking/smi",
    "path": "content/pages/manual/eyetracking/smi.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# EyeLogic\n\ntitle: EyeLogic\n\nPyGaze offers *experimental support* for EyeLogic eye trackers as of OpenSesame 3.3.11. For more information, see:\n\n- %link:pygaze%\n- <https://www.eyelogicsolutions.com/>",
    "title": "EyeLogic",
    "url": "https://osdoc.cogsci.nl/4.1/manual/eyetracking/eyelogic",
    "path": "content/pages/manual/eyetracking/eyelogic.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Button box\n\ntitle: Button box\n\nThere are many different types of button boxes, and they all work in different ways. Therefore, there is no single OpenSesame item that works with all button boxes. (This is different from keyboards, which are standard devices that all work with the KEYBOARD_RESPONSE item.)\n\nCommon types of button boxes:\n\n- Some button boxes *emulate keypresses*. This is easy, because you can use the normal KEYBOARD_RESPONSE item.\n\t- %link:manual/response/keyboard%\n- Some button boxes *emulate a joystick*. This is also easy, because you can use the JOYSTICK plugin.\n\t- %link:joystick%\n- Some button boxes are compatible with the *Serial Response Box* that is developed by Psychology Software Tools. These button boxes are supported by the SRBOX plugin.\n\t- %link:srbox%\n- Some button boxes have their own Python libaries. In this case, you should be able to find example scripts of how to use the button box in Python, that is, in an OpenSesame INLINE_SCRIPT item.",
    "title": "Button box",
    "url": "https://osdoc.cogsci.nl/4.1/manual/response/buttonbox",
    "path": "content/pages/manual/response/buttonbox.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Mouse responses\n\ntitle: Mouse responses\n\nMouse responses are collected with the MOUSE_RESPONSE item. The MOUSE_RESPONSE is primarily intended to collect individual mouse clicks. If you want to collect mouse-cursor trajectories, take a look at the MOUSETRAP plugins:\n\n- %link:mousetracking%\n\n[TOC]\n\n\n## Response variables\n\nThe MOUSE_RESPONSE sets the standard response variables as described here:\n\n- %link:manual/variables%\n\n\n## Mouse-button names\n\nMouse buttons have a number (`1`, etc.) as well as a name (`left_button`, etc.). Both can be used to specify correct and allowed responses, but the `response` variable will be set to a number.\n\n- `left_button` corresponds to `1`\n- `middle_button` corresponds to `2`\n- `right_button` corresponds to `3`\n- `scroll_up` corresponds to `4`\n- `scroll_down` corresponds to `5`\n\n\n## Correct response\n\nThe *Correct response* field indicates which response is considered correct. After a correct response, the `correct` variable is automatically set to 1; after an incorrect response or a timeout (i.e. everything else), `correct` is set to 0; if no correct response is specified, `correct` is set to 'undefined'.\n\nYou can indicate the correct response in three main ways:\n\n- *Leave the field empty.* If you leave the *Correct response* field empty, OpenSesame will automatically check if a variable called `correct_response` has been defined, and, if so, use this variable for the correct response.\n- *Enter a literal value.* You can explicitly enter a response, such as 1. This is only useful if the correct response is fixed.\n- *Enter a variable name.* You can enter a variable, such as '{cr}'. In this case, this variable will be used for the correct response.\n\nNote that the correct response refers to which mouse button was clicked, not to which region of interest was clicked (ROI); see the section below for more information about ROIs.\n\n## Allowed responses\n\nThe *Allowed responses* field indicates a list of allowed responses. All other responses will be ignored, except for 'Escape', which will pause the experiment. The allowed responses should be a semicolon-separated list of responses, such as '1;3' to allow the left and right mouse buttons. To accept all responses, leave the *Allowed responses* field empty.\n\nNote that the allowed responses refer to which mouse button can be clicked, not to which region of interest can be clicked (ROI); see the section below for more information about ROIs.\n\n\n## Timeout\n\nThe *Timeout* field indicates a timeout value in milliseconds, or 'infinite' for no timeout. When a timeout occurs, the following happens:\n\n- `response_time` is set to the timeout value, or rather to the time it takes for a timeout to be registered, which may deviate slightly from the timeout value.\n- `response` is set to 'None'. This means that you can specify 'None' for the correct response a timeout should occur; this can be useful, for example, in a go/no-go task, when the participant should withold a response on no-go trials.\n\n\n## Coordinates and regions of interest (ROIs)\n\nThe `cursor_x` and `cursor_y` variables hold the location of the mouse click.\n\nIf you indicate a linked SKETCHPAD, the variable `cursor_roi` will hold a comma-separated list of names of elements that contain the clicked coordinate. In other words, elements on the SKETCHPAD automatically serve as regions of interest for the mouse click.\n\nIf the correctness of a response depends on which ROI was clicked, you cannot use the `correct_response` variable for this, because this currently refers only to which mouse button was clicked. Instead you need to use a simple script.\n\nIn a Python INLINE_SCRIPT you can do this as follows:\n\n```python\nclicked_rois = cursor_roi.split(';')\ncorrect_roi = 'my_roi'\nif correct_roi in clicked_rois:\n    print('correct!')\n    correct = 1\nelse:\n    print('incorrect!')\n    correct = 0\n```\n\nWith OSWeb using a INLINE_JAVASCRIPT you can do this as follows:\n\n```js\nclicked_rois = cursor_roi.split(';')\ncorrect_roi = 'my_roi'\nif (clicked_rois.includes(correct_roi)) {\n    console.log('correct!')\n    correct = 1\n} else {\n    console.log('incorrect!')\n    correct = 0\n}\n```\n\n\n%--\nvideo:\n source: youtube\n id: VidMouseROI\n videoid: 21cgX_zHDiA\n width: 640\n height: 360\n caption: |\n  Collecting mouse clicks and using regions of interest.\n--%\n\n## Collecting mouse responses in Python\n\nYou can use the `mouse` object to collect mouse responses in Python:\n\n- %link:manual/python/mouse%",
    "title": "Mouse responses",
    "url": "https://osdoc.cogsci.nl/4.1/manual/response/mouse",
    "path": "content/pages/manual/response/mouse.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Keyboard responses\n\ntitle: Keyboard responses\n\nKeyboard responses are collected with the KEYBOARD_RESPONSE item.\n\n[TOC]\n\n\n## Response variables\n\nThe KEYBOARD_RESPONSE sets the standard response variables as described here:\n\n- %link:manual/variables%\n\n## Key names\n\nKeys are generally identified by their character and/ or their description (depending on which is applicable). For example:\n\n- The `/` key is named 'slash' and '/'. You can use either of the two names.\n- The `a` is named 'a'.\n- The left-arrow key is named 'left'.\n\nIf you don't know what a particular key is named, you can:\n\n- Click on the 'List available keys' button; or\n- Create a simple experiment in which a KEYBOARD_RESPONSE is immediately followed by a FEEDBACK item with the text '{response}' on it. This will show the name of the previously collected response.\n\n\n## Correct response\n\nThe *Correct response* field indicates which response is considered correct. After a correct response, the `correct` variable is automatically set to 1; after an incorrect response (i.e. everything else), `correct` is set to 0; if no correct response is specified, `correct` is set to 'undefined'.\n\nYou can indicate the correct response in three main ways:\n\n- *Leave the field empty.* If you leave the *Correct response* field empty, OpenSesame will automatically check if a variable called `correct_response` has been defined, and, if so, use this variable for the correct response.\n- *Enter a literal value.* You can explicitly enter a response, such as 'left' in the case of a KEYBOARD_RESPONSE item. This is only useful if the correct response is fixed.\n- *Enter a variable name.* You can enter a variable, such as '{cr}'. In this case, this variable will be used for the correct response.\n\n\n## Allowed responses\n\nThe *Allowed responses* field indicates a list of allowed responses. All other responses will be ignored, except for 'Escape', which will pause the experiment. The allowed responses should be a semicolon-separated list of responses, such as 'a;left;/' for a KEYBOARD_RESPONSE. To accept all responses, leave the *Allowed responses* field empty.\n\n\n## Timeout\n\nThe *Timeout* field indicates a timeout value in milliseconds, or 'infinite' for no timeout. When a timeout occurs, the following happens:\n\n- `response_time` is set to the timeout value, or rather to the time it takes for a timeout to be registered, which may deviate slightly from the timeout value.\n- `response` is set to 'None'. This means that you can specify 'None' for the correct response a timeout should occur; this can be useful, for example, in a go/no-go task, when the participant should withold a response on no-go trials.\n\n\n## Collecting keyboard responses in Python\n\nYou can use the `keyboard` object to collect keyboard responses in Python:\n\n- %link:manual/python/keyboard%",
    "title": "Keyboard responses",
    "url": "https://osdoc.cogsci.nl/4.1/manual/response/keyboard",
    "path": "content/pages/manual/response/keyboard.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Sound recording\n\ntitle: Sound recording\n\n[TOC]\n\n\n## Audio Low Latency plugins\n\nThe Audio Low Latency plugins, developed by Bob Rosbag, are the recommended way to record sound input. The main goal of this set of plugins is to play and record audio with minimal and predictable latencies to achieve a high accuracy and precision. The `PyAlsaAudio` package which uses the Linux ALSA audio system provided the best results within Python. `PortAudio` and `sounddevice` are cross-platform and work on both Windows as Linux.\n\nThe plugins are not installed by default, but can be installed through pip:\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nSee also:\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>\n\n\n## Sound recorder plugins\n\nThe sound recorder plugins, developed by Daniel Schreij, are no longer under active development and are therefore no longer recommended. More information about this set of plugins can be found on previous version of this page:\n\n- <https://osdoc.cogsci.nl/3.2/manual/response/soundrecording/>",
    "title": "Sound recording",
    "url": "https://osdoc.cogsci.nl/4.1/manual/response/soundrecording",
    "path": "content/pages/manual/response/soundrecording.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Joystick and gamepad\n\ntitle: Joystick and gamepad\n\nJoysticks and gamepads are supported through the JOYSTICK plugin.\n\n[TOC]\n\n<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __joystick__\n\nIf you insert the JOYSTICK plugin at the start of your experiment, a\nJOYSTICK object automatically becomes part of the experiment object\nand can be used within an INLINE_SCRIPT item as `joystick`.\n\n{% set arg_joybuttonlist = \"A list of buttons that are accepted or \" +\n\"`None` to accept all buttons.\" %}\n{% set arg_timeout = \"A timeout value in milliseconds or `None` for no \" +\n\"timeout.\" %}\n\n[TOC]\n\n## flush()\n\nClears all pending input, not limited to the joystick.\n\n\n\n__Returns__\n\n- True if joyinput was pending (i.e., if there was something to\nflush) and False otherwise.\n\n\n## get_joyaxes(timeout=None)\n\nWaits for joystick axes movement.\n\n\n__Parameters__\n\n- **timeout**: A timeout value in milliseconds or `None` to use default timeout.\n\n__Returns__\n\n- A `(position, timestamp)` tuple. `position` is `None` if a timeout\noccurs. Otherwise, `position` is an `(x, y, z)` tuple.\n\n\n## get_joyballs(timeout=None)\n\nWaits for joystick trackball movement.\n\n\n__Parameters__\n\n- **timeout**: A timeout value in milliseconds or `None` to use default timeout.\n\n__Returns__\n\n- A `(position, timestamp)` tuple. The position is `None` if a\ntimeout occurs.\n\n\n## get_joybutton(joybuttonlist=None, timeout=None)\n\nCollects joystick button input.\n\n\n__Parameters__\n\n- **joybuttonlist**: A list of buttons that are accepted or `None` to default\njoybuttonlist.\n- **timeout**: A timeout value in milliseconds or `None` to use default timeout.\n\n__Returns__\n\n- A (joybutton, timestamp) tuple. The joybutton is `None` if a\ntimeout occurs.\n\n\n## get_joyhats(timeout=None)\n\nWaits for joystick hat movement.\n\n\n__Parameters__\n\n- **timeout**: A timeout value in milliseconds or `None` to use default timeout.\n\n__Returns__\n\n- A `(position, timestamp)` tuple. `position` is `None` if a timeout\noccurs. Otherwise, `position` is an `(x, y)` tuple.\n\n\n## get_joyinput(joybuttonlist=None, timeout=None)\n\nWaits for any joystick input (buttons, axes, hats or balls).\n\n\n__Parameters__\n\n- **joybuttonlist**: A list of buttons that are accepted or `None` to default\njoybuttonlist.\n- **timeout**: A timeout value in milliseconds or `None` to use default timeout.\n\n__Returns__\n\n- A (event, value, timestamp) tuple. The value is `None` if a timeout\noccurs. `event` is one of `None`, 'joybuttonpress',\n'joyballmotion', 'joyaxismotion', or 'joyhatmotion'\n\n\n## input_options()\n\nGenerates a list with the number of available buttons, axes, balls\nand hats.\n\n\n\n__Returns__\n\n- A list with number of inputs as: [buttons, axes, balls,\nhats].\n\n\n## set_joybuttonlist(joybuttonlist=None)\n\nSets a list of accepted buttons.\n\n\n__Parameters__\n\n- **joybuttonlist**: {{arg_joybuttonlist}}\n\n\n## set_timeout(timeout=None)\n\nSets a timeout.\n\n\n__Parameters__\n\n- **timeout**: {{arg_timeout}}\n\n\n</div>\n\n",
    "title": "Joystick and gamepad",
    "url": "https://osdoc.cogsci.nl/4.1/manual/response/joystick",
    "path": "content/pages/manual/response/joystick.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# SR Box\n\ntitle: SR Box\n\n[TOC]\n\n## About the srbox plugin\n\nThe serial response (SR) box is a button box, specifically designed for response collection in psychological experiments. The original version, developed by Psychology Software Tools, has 5 buttons, 5 lights, and is connected to the PC trough the serial port. There are also SR Box compatible devices by other manufacturers, which may differ in the number of buttons and lights and often use a USB connection, which emulates a serial port.\n\nThe SRBOX plugin for OpenSesame allows you to use the SR Box or compatible device in your OpenSesame experiments.\n\n## Screenshot\n\n%--\nfigure:\n  source: srbox.png\n  id: FigSrbox\n  caption: The srbox plugin in OpenSesame.\n--%\n\n## Setting the device name\n\nBy default, the plugin tries to autodetect your SR Box. If this works, you don't have to change it. If your experiment freezes, OpenSesame has chosen the wrong serial port and you must enter the device name manually. Under Windows, the device is probably called something like\n\n```text\nCOM4\n```\n\nUnder Linux the device is probably called something like\n\n```text\n/dev/tty0\n```\n\n## Requirements\n\nAn SR Box or compatible button box. Not all button boxes are compatible, see:\n\n- %link:buttonbox%\n\n## Using the SR Box from Python inline code\n\nThe `srbox` object does *not* exist when the plug-in is in dummy mode.\n\n<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __srbox__\n\nIf you insert the srbox plugin at the start of your experiment, an\ninstance of SRBOX automatically becomes part of the experiment\nobject and\ncan be accessed within an inline_script item as SRBOX.\n\n__Important note1:__\n\nIf you do not specify a device, the plug-in will try to autodetect\nthe\nSR Box port. However, on some systems this freezes the experiment, so\nit is better to explicitly specify a device.\n\n__Important note 2:__\n\nYou\nneed to call [srbox.start] to put the SR Box in sending mode,\nbefore\ncalling [srbox.get_button_press] to collect a button press.\n\n__Example:__\n~~~ .python\nt0 = clock.time()\nsrbox.start()\nbutton, t1 = srbox.get_button_press(allowed_buttons=[1, 2],\n                                    require_state_change=True)\nif button == 1:\n    response_time = t1 - t0\nprint(f'Button 1 was pressed in {response_time} ms!')\nsrbox.stop()\n~~~\n[TOC]\n\n## get_button_press(allowed_buttons=None, timeout=None, require_state_change=False)\n\nCollects a button press from the SR box.\n\n\n__Parameters__\n\n- **allowed_buttons**: A list of buttons that are accepted or `None` to accept all\nbuttons. Valid buttons are integers 1 through 8.\n- **timeout**: A timeout value in milliseconds or `None` for no timeout.\n- **require_state_change    Indicates whether already pressed button should be accepted**: (False), or whether only a state change from unpressed to pressed\nis accepted (True).\n\n__Returns__\n\n- A `(button_list, timestamp)` tuple. `button_list` is `None` if no \nbutton was pressed (i.e. a timeout occurred).\n\n\n## send(ch)\n\nSends a single character to the SR Box. Send '`' to turn off all\nlights, 'a' for light 1 on, 'b' for light 2 on,'c' for lights\n1 and 2 on etc.\n\n\n__Parameters__\n\n- **ch**: The character to send. If a `str` is passed, it is encoded to\n`bytes` using utf-8 encoding.\n\n\n## start()\n\nTurns on sending mode, so that the SR Box starts to send output.\nThe SR Box must be in sending mode when you call\n[srbox.get_button_press].\n\n\n\n\n## stop()\n\nTurns off sending mode, so that the SR Box stops giving output.\n\n\n\n\n</div>\n\n",
    "title": "SR Box",
    "url": "https://osdoc.cogsci.nl/4.1/manual/response/srbox",
    "path": "content/pages/manual/response/srbox.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Access the file pool\n\ntitle: Access the file pool\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `pool` object does not need to be imported\n- Give examples of how to:\n    - Check whether a file is in the file pool\n    - Retrieve the path to a file in the file pool\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __pool__\n\nThe `pool` object provides dict-like access to the file pool. When\nchecking whether a file is in the file pool, several folders are\nsearched.\nFor more details, see `pool.folders()`.\n\nA `pool` object is created\nautomatically when the experiment starts.\n\nIn addition to the functions\nlisted below, the following semantics are\nsupported:\n\n__Examples__\n\nBasic use:\n\n~~~ .python\n# Get the full path to a file in the file pool\nprint(f'The full path to img.png is {pool[\"img.png\"]}')\n# Check if a file is in the file pool\nif 'img.png' in pool:\n    print('img.png is in the file pool')\n# Delete a file from the file pool\ndel pool['img.png']\n# Walk through all files in the file pool. This retrieves the full paths.\nfor path in pool:\n    print(path)\n# Check the number of files in the file pool\nprint(f'There are {len(pool)} files in the file pool')\n~~~\n\nGet an image from the file pool and use a `Canvas` to show it.\n\n~~~ .python\nimage_path = pool['img.png']\nmy_canvas = Canvas()\nmy_canvas.image(image_path)\nmy_canvas.show()\n~~~\n\n[TOC]\n\n## add(path, new_name=None)\n\nCopies a file to the file pool.\n\n\n__Parameters__\n\n- **path**: The full path to the file on disk.\n- **new_name**: A new name for the file in the pool, or None to use the file's\noriginal name.\n\n__Example__\n\n~~~ .python\npool.add('/home/username/Pictures/my_ing.png')\n~~~\n\n\n\n## clean_up()\n\nRemoves the pool folder.\n\n\n\n\n## fallback_folder()\n\nThe full path to the fallback pool folder, which is the\n`__pool__` subfolder of the current experiment folder, or\n`None` if this folder does not exist. The fallback pool\nfolder is mostly useful in combination with a versioning\nsystem, such as git, because it allows you to save the\nexperiment as a plain-text file, even when having files\nin the file pool.\n\n\n\n__Returns__\n\n- \n\n__Example__\n\n~~~ .python\nif pool.fallback_folder() is not None:\n    print('There is a fallback pool folder!')\n~~~\n\n\n\n## files()\n\nReturns all files in the file pool.\n\n\n\n__Returns__\n\n- A list of full paths.\n\n__Example__\n\n~~~ .python\nfor path in pool.files():\n    print(path)\n# Equivalent to:\nfor path in pool:\n    print(path)\n~~~\n\n\n\n## folder()\n\nGives the full path to the (main) pool folder. This is typically a\ntemporary folder that is deleted when the experiment is finished.\n\n\n\n__Returns__\n\n- The full path to the main pool folder.\n\n__Example__\n\n~~~ .python\nprint(f'The pool folder is here: {pool.folder()}')\n~~~\n\n\n\n## folders(include_fallback_folder=True, include_experiment_path=False)\n\nGives a list of all folders that are searched when retrieving the\nfull path to a file. These are (in order):\n\n1. The file pool folder\nitself, as returned by `pool.folder()`.\n2. The folder of the current\nexperiment (if it exists)\n3. The fallback pool folder, as returned by\n`pool.fallback_folder()` (if it exists)\n\n__Parameters__\n\n- **include_fallback_folder**: Indicates whether the fallback pool folder should be included if it\nexists.\n- **include_experiment_path**: Indicates whether the experiment folder should be included if it\nexists.\n\n__Returns__\n\n- A list of all folders.\n\n__Example__\n\n~~~ .python\nprint('The following folders are searched for files:')\nfor folder in pool.folders():\n    print(folder)\n~~~\n\n\n\n## in_folder(path)\n\nChecks whether path is in the pool folder. This is different from\nthe `path in pool` syntax in that it only checks the main pool folder,\nand not the fallback pool folder and experiment folder.\n\n\n__Parameters__\n\n- **path**: A file basename to check.\n\n__Returns__\n\n- \n\n__Example__\n\n~~~ .python\nprint(pool.in_folder('cue.png'))\n~~~\n\n\n\n## rename(old_path, new_path)\n\nRenames a file in the pool folder.\n\n\n__Parameters__\n\n- **old_path**: The old file name.\n- **new_path**: The new file name.\n\n__Example__\n\n~~~ .python\npool.rename('my_old_img.png', 'my_new_img.png')\n~~~\n\n\n\n## size()\n\nGets the combined size in bytes of all files in the file pool.\n\n\n\n__Returns__\n\n- \n\n__Example__\n\n~~~ .python\nprint(f'The size of the file pool is {pool.size()} bytes')\n~~~\n\n\n\n</div>\n\n",
    "title": "Access the file pool",
    "url": "https://osdoc.cogsci.nl/4.1/manual/python/pool",
    "path": "content/pages/manual/python/pool.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Sampler functions\n\ntitle: Sampler functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `Sampler` class does not need to be imported\n- Explain the process to initialize a Sampler\n- Define the usage of `**playback_args`\n- Explain supported file formats\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# class __Sampler__\n\nThe `Sampler` class provides functionality to play sound samples. You \ngenerally create a `Sampler` object with the `Sampler()` factory function, \nas described in the section [Creating a Sampler](#creating-a-sampler).\n\n__Example:__\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src, volume=.5)\nmy_sampler.play()\n~~~\n\n[TOC]\n\n## Things to know\n\n### Creating a Sampler\n\nYou generally create a `Sampler` with the `Sampler()` factory function, which\ntakes the full path to a sound file as the first argument.\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src)\n~~~\n\nOptionally, you can pass [Playback keywords](#playback-keywords) to `Sampler()`\nto set the default behavior:\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src, volume=.5)\n~~~\n\n### Sampling rate\n\nIf you find that your sample plays too slowly (low pitch) or too quickly (high\npitch), make sure that the sampling rate of your sample matches the sampling\nrate of the sampler back-end as specified under backend settings.\n\n### Supported file formats\n\nSound files in `.wav`, `.mp3`, and `.ogg` format are supported. If you need to\nconvert samples from a different format, you can use\n[Audacity](http://sourceforge.net/projects/audacity/).\n\n### Playback keywords\n\nFunctions that accept `**playback_args` take the following keyword arguments:\n\n- `volume` specifies a volume between `0.0` (silent) and `1.0` (maximum).\n- `pitch` specifies a pitch (or playback speed), where values > 1 indicate a\n  higher pitch, and values < 1 indicate a lower pitch.\n- `pan` specifies a panning, where values < 0 indicate panning to the left, and\n  values > 0 indicate panning to the right. Alternatively, you can set pan to\n  'left' or 'right' to play only a single channel.\n- `duration` specifies the duration of the sound in milliseconds, or is set to\n  `0` or `None` to play the full sound.\n- `fade_in` specifies the fade-in time (or attack) of the sound, or is set to\n  `0` or `None` to disable fade-in.\n- `block` indicates whether the experiment should block (`True`) during\n  playback or not (`False`).\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play(volume=.5, pan='left')\n~~~\n\nPlayback keywords only affect the current operation (except when passed to\n`Sampler()` when creating the object). To change the behavior for all\nsubsequent operations, set the playback properties directly:\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.volume = .5\nmy_sampler.pan = 'left'\nmy_sampler.play()\n~~~\n\nOr pass the playback keywords to `Sampler()` when creating the object:\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src, volume=.5, pan='left')\nmy_sampler.play()\n~~~\n\n## close_sound(experiment)\n\nCloses the mixer after the experiment is finished.\n\n\n__Parameters__\n\n- **experiment**: The experiment object.\n\n\n## init_sound(experiment)\n\nInitializes the pygame mixer before the experiment begins.\n\n\n__Parameters__\n\n- **experiment**: The experiment object.\n\n\n## is_playing()\n\nChecks if a sound is currently playing.\n\n\n\n__Returns__\n\n- True if a sound is playing, False if not.\n\n__Example__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play()\nsleep(100)\nif my_sampler.is_playing():\n        print('The sampler is still playing!')\n~~~\n\n\n\n## pause()\n\nPauses playback (if any).\n\n\n\n__Example__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play()\nsleep(100)\nmy_sampler.pause()\nsleep(100)\nmy_sampler.resume()\n~~~\n\n\n\n## play(\\*arglist, \\*\\*kwdict)\n\nPlays the sound.\n\n\n__Parameters__\n\n- **\\*\\*playback_args**: Optional [playback keywords](#playback-keywords) that will be used\nfor this call to `Sampler.play()`. This does not affect subsequent\noperations.\n\n__Example__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play(pitch=.5, block=True)\n~~~\n\n\n\n## resume()\n\nResumes playback (if any).\n\n\n\n__Example__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play()\nsleep(100)\nmy_sampler.pause()\nsleep(100)\nmy_sampler.resume()\n~~~\n\n\n\n## set_config(\\*\\*cfg)\n\nUpdates the configurables.\n\n\n__Parameters__\n\n- **\\*\\*cfg**: The to-be-updated configurables.\n\n\n## stop()\n\nStops the currently playing sound (if any).\n\n\n\n__Example__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play()\nsleep(100)\nmy_sampler.stop()\n~~~\n\n\n\n## wait()\n\nBlocks until the sound has finished playing or returns right away\nif no sound is playing.\n\n\n\n__Example__\n\n~~~ .python\nsrc = pool['my_sound.ogg']\nmy_sampler = Sampler(src)\nmy_sampler.play()\nmy_sampler.wait()\nprint('The sampler is finished!')\n~~~\n\n\n\n</div>\n\n",
    "title": "Sampler functions",
    "url": "https://osdoc.cogsci.nl/4.1/manual/python/sampler",
    "path": "content/pages/manual/python/sampler.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Clock functions\n\ntitle: Clock functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `clock` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __clock__\n\nThe `clock` object offers basic time functions. A `clock` object is\ncreated automatically when the experiment starts.\n\n__Example__\n\n~~~ .python\n# Get the timestamp before and after sleeping for 1000 ms\nt0 = clock.time()\nclock.sleep(1000)\nt1 = clock.time()\ntime_passed = t1 - t0\nprint(f'This should be 1000: {time_passed}')\n~~~\n\n[TOC]\n\n## loop_for(ms, throttle=None, t0=None)\n\n*New in v3.2.0*\n\nAn iterator that loops for a fixed time.\n\n__Parameters__\n\n- **ms**: The number of milliseconds to loop for.\n- **throttle**: A period to sleep for in between each iteration.\n- **t0**: A starting time. If `None`, the starting time is the moment at\nwhich the iteration starts.\n\n__Returns__\n\n- \n\n__Example__\n\n~~~ .python\nfor ms in clock.loop_for(100, throttle=10):\n    print(ms)\n~~~\n\n\n\n## once_in_a_while(ms=1000)\n\n*New in v3.2.0*\n\nPeriodically returns `True`. This is mostly useful\nfor executing\ncode (e.g. within a `for` loop) that should only be\nexecuted once\nin a while.\n\n__Parameters__\n\n- **ms**: The minimum waiting period.\n\n__Returns__\n\n- `True` after (at least) the minimum waiting period has\npassed since\nthe last call to `Clock.once_in_a_while()`, or\n`False` otherwise.\n\n__Example__\n\n~~~ .python\nfor i in range(1000000):\n    if clock.once_in_a_while(ms=50):\n        # Execute this code only once every 50 ms\n        print(clock.time())\n~~~\n\n\n\n## sleep(ms)\n\nSleeps (pauses) for a period.\n\n\n__Parameters__\n\n- **ms**: The number of milliseconds to sleep for.\n\n__Example__\n\n~~~ .python\n# Create two canvas objects ...\nmy_canvas1 = Canvas()\nmy_canvas1.text('1')\nmy_canvas2 = Canvas()\nmy_canvas2.text('2')\n# ... and show them with 1 s in between\nmy_canvas1.show()\nclock.sleep(1000)\nmy_canvas2.show()\n~~~\n\n\n\n## time()\n\nGives a current timestamp in milliseconds. The absolute meaning of\nthe timestamp (i.e. when it was 0) depends on the backend.\n\n\n\n__Returns__\n\n- A timestamp.\n\n__Example__\n\n~~~ .python\nt = clock.time()\nprint(f'The current time is {t}')\n~~~\n\n\n\n</div>\n\n",
    "title": "Clock functions",
    "url": "https://osdoc.cogsci.nl/4.1/manual/python/clock",
    "path": "content/pages/manual/python/clock.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Access response history\n\ntitle: Access response history\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `responses` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __responses__\n\nThe `responses` object contains the history of the responses that were\ncollected during the experiment.\n\nA `responses` object is created automatically when the experiment starts.\n\nIn addition to the functions listed below, the following semantics are\nsupported:\n\n__Example__\n\n~~~ .python\n# Loop through all responses, where last-given responses come first\n# Each response has correct, response, response_time, item, and feedback\n# attributes.\nfor response in responses:\n    print(response.correct)\n# Print the two last-given responses\nprint('last_two responses:')\nprint(responses[:2])\n~~~\n\n[TOC]\n\n## add(response=None, correct=None, response_time=None, item=None, feedback=True)\n\nAdds a response.\n\n\n__Parameters__\n\n- **response    The response value, for example, 'space' for the spacebar, 0 for**: joystick button 0, etc.\n- **correct**: The correctness of the response.\n- **response_time**: The response_time.\n- **item**: The item that collected the response.\n- **feedback**: Indicates whether the response should be included in feedback on\naccuracy and average response time.\n\n__Example__\n\n~~~ .python\nresponses.add(response_time=500, correct=1, response='left')\n~~~\n\n\n\n## clear()\n\nClears all responses.\n\n\n\n__Example__\n\n~~~ .python\nresponses.clear()\n~~~\n\n\n\n## reset_feedback()\n\nSets the feedback status of all responses to False, so that only\nnew responses will be included in feedback.\n\n\n\n__Example__\n\n~~~ .python\nresponses.reset_feedback()\n~~~\n\n\n\n</div>\n\n",
    "title": "Access response history",
    "url": "https://osdoc.cogsci.nl/4.1/manual/python/responses",
    "path": "content/pages/manual/python/responses.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Mouse functions\n\ntitle: Mouse functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `Mouse` class does not need to be imported\n- Explain the process to initialize a Mouse\n- Define the usage of `**resp_args`\n- Explain how to specify button names/ numbers\n- Explain coordinates: x=0, y=0 is the display center\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# class __Mouse__\n\nThe `Mouse` class is used to collect mouse input. You generally create a\n`Mouse` object with the `Mouse()` factory function, as described in the\nsection [Creating a Mouse](#creating-a-mouse).\n\n__Example__\n\n~~~ .python\n# Draw a 'fixation-dot mouse cursor' until a button is clicked\nmy_mouse = Mouse()\nmy_canvas = Canvas()\nwhile True:\n    button, position, timestamp = my_mouse.get_click(timeout=20)\n    if button is not None:\n        break\n    (x,y), time = my_mouse.get_pos()\n    my_canvas.clear()\n    my_canvas.fixdot(x, y)\n    my_canvas.show()\n~~~\n\n[TOC]\n\n## Things to know\n\n### Creating a Mouse\n\nYou generally create a `Mouse` with the `Mouse()` factory function:\n\n~~~ .python\nmy_mouse = Mouse()\n~~~\n\nOptionally, you can pass [Response keywords](#response-keywords) to `Mouse()`\nto set the default behavior:\n\n~~~ .python\nmy_mouse = Mouse(timeout=2000)\n~~~\n\n### Coordinates\n\n- When *Uniform coordinates* is set to 'yes', coordinates are relative to the\n  center of the display. That is, (0,0) is the center. This is the default as\n  of OpenSesame 3.0.0.\n- When *Uniform coordinates* is set to 'no', coordinates are relative to the\n  top-left of the display. That is, (0,0) is the top-left. This was the default\n  in OpenSesame 2.9.X and earlier.\n\n### Button numbers\n\nMouse buttons are numbered as follows:\n\n1. Left button\n2. Middle button\n3. Right button\n4. Scroll up\n5. Scroll down\n\n### Touch screens\n\nWhen working with a touch screen, a touch is registered as button 1\n(left button).\n\n### Response keywords\n\nFunctions that accept `**resp_args` take the following keyword arguments:\n\n- `timeout` specifies a timeout value in milliseconds, or is set to `None` to\n  disable the timeout.\n- `buttonlist` specifies a list of buttons that are accepted, or is set to\n  `None` accept all buttons.\n- `visible` indicates whether the mouse cursor becomes visible when a click is\n  collected (`True` or `False`). To immediately change cursor visibility, use\n  `Mouse.show_cursor()`.\n\n~~~ .python\n# Get a left or right button press with a timeout of 3000 ms\nmy_mouse = Mouse()\nbutton, time = my_mouse.get_click(buttonlist=[1,3], timeout=3000)\n~~~\n\nResponse keywords only affect the current operation (except when passed to\n`Mouse()` when creating the object). To change the behavior for all subsequent\noperations, set the response properties directly:\n\n~~~ .python\n# Get two left or right presses with a 5000 ms timeout\nmy_mouse = Mouse()\nmy_mouse.buttonlist = [1,3]\nmy_mouse.timeout = 5000\nbutton1, time1 = my_mouse.get_click()\nbutton2, time2 = my_mouse.get_click()\n~~~\n\nOr pass the response keywords to `Mouse()` when creating the object:\n\n~~~ .python\n# Get two left or right presses with a 5000 ms timeout\nmy_mouse = Mouse(buttonlist=[1,3], timeout=5000)\nbutton1, time1 = my_mouse.get_click()\nbutton2, time2 = my_mouse.get_click()\n~~~\n\n## flush()\n\nClears all pending input, not limited to the mouse.\n\n\n\n__Returns__\n\n- True if a button had been clicked (i.e., if there was something to\nflush) and False otherwise.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse()\nmy_mouse.flush()\nbutton, position, timestamp = my_mouse.get_click()\n~~~\n\n\n\n## get_click(\\*arglist, \\*\\*kwdict)\n\nCollects a mouse click.\n\n\n__Parameters__\n\n- **\\*\\*resp_args**: Optional [response keywords](#response-keywords) that will be used\nfor this call to `Mouse.get_click()`. This does not affect\nsubsequent operations.\n\n__Returns__\n\n- A (button, position, timestamp) tuple. The button and position are\n`None` if a timeout occurs. Position is an (x, y) tuple in screen\ncoordinates.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse()\nbutton, (x, y), timestamp = my_mouse.get_click(timeout=5000)\nif button is None:\n        print('A timeout occurred!')\n~~~\n\n\n\n## get_click_release(\\*arglist, \\*\\*kwdict)\n\n*New in v3.2.0*\n\nCollects a mouse-click release.\n\n*Important:* This\nfunction is currently not implemented for the\n*psycho* backend.\n\n__Parameters__\n\n- **\\*\\*resp_args**: Optional [response keywords](#response-keywords) that will be used\nfor this call to `Mouse.get_click_release()`. This does not affect\nsubsequent operations.\n\n__Returns__\n\n- A (button, position, timestamp) tuple. The button and position are\n`None` if a timeout occurs. Position is an (x, y) tuple in screen\ncoordinates.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse()\nbutton, (x, y), timestamp = my_mouse.get_click_release(timeout=5000)\nif button is None:\n        print('A timeout occurred!')\n~~~\n\n\n\n## get_pos()\n\nReturns the current position of the cursor.\n\n\n\n__Returns__\n\n- A (position, timestamp) tuple.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse()\n(x, y), timestamp = my_mouse.get_pos()\nprint('The cursor was at (%d, %d)' % (x, y))\n~~~\n\n\n\n## get_pressed()\n\nReturns the current state of the mouse buttons. A True value means\nthe button is currently being pressed.\n\n\n\n__Returns__\n\n- A (button1, button2, button3) tuple of boolean values.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse()\nbuttons = my_mouse.get_pressed()\nb1, b2, b3 = buttons\nprint('Currently pressed mouse buttons: (%d,%d,%d)' % (b1,b2,b3))\n~~~\n\n\n\n## set_pos(pos=(0, 0))\n\nSets the position of the mouse cursor.\n\n__Warning:__ `set_pos()` is\nunreliable and will silently fail on\nsome systems.\n\n__Parameters__\n\n- **pos**: An (x,y) tuple for the new mouse coordinates.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse()\nmy_mouse.set_pos(pos=(0,0))\n~~~\n\n\n\n## show_cursor(show=True)\n\nImmediately changes the visibility of the mouse cursor.\n\n__Note:__\nIn most cases, you will want to use the `visible`\nkeyword, which\nchanges the visibility during response collection,\nthat is, while\n`mouse.get_click()` is called. Calling \n`show_cursor()` will not\nimplicitly change the value of `visible`, \nwhich can lead to the\nsomewhat unintuitive behavior that the cursor\nis hidden as soon as\n`get_click()` is called.\n\n__Parameters__\n\n- **show**: Indicates whether the cursor is shown (True) or hidden (False).\n\n\n## synonyms(button)\n\nGives a list of synonyms for a mouse button. For example, 1 and\n'left_button' are synonyms.\n\n\n__Parameters__\n\n- **button**: A button value.\n\n__Returns__\n\n- A list of synonyms.\n\n\n</div>\n\n",
    "title": "Mouse functions",
    "url": "https://osdoc.cogsci.nl/4.1/manual/python/mouse",
    "path": "content/pages/manual/python/mouse.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Log functions\n\ntitle: Log functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `log` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __log__\n\nThe `log` object provides data logging. A `log` object is created\nautomatically when the experiment starts.\n\n__Example__\n\n~~~ .python\n# Write one line of text\nlog.write('My custom log message')\n# Write all variables\nlog.write_vars()\n~~~\n\n[TOC]\n\n## close()\n\nCloses the current log.\n\n\n\n__Example__\n\n~~~ .python\nlog.close()\n~~~\n\n\n\n## open(path)\n\nOpens the current log. If a log was already open, it is closed\nautomatically, and re-opened.\n\n\n__Parameters__\n\n- **path**: The path to the current logfile. In most cases (unless) a custom\nlog back-end is used, this will be a filename.\n\n__Example__\n\n~~~ .python\n# Open a new log\nlog.open('/path/to/new/logfile.csv')\n~~~\n\n\n\n## write(msg, newline=True)\n\nWrite one message to the log.\n\n\n__Parameters__\n\n- **msg**: A text message. When using Python 2, this should be either\n`unicode` or a utf-8-encoded `str`. When using Python 3, this\nshould be either `str` or a utf-8-encoded `bytes`.\n- **newline**: Indicates whether a newline should be written after the message.\n\n__Example__\n\n~~~ .python\n# Write a single string of text\nlog.write(f'time = {clock.time()}')\n~~~\n\n\n\n## write_vars(var_list=None)\n\nWrites variables to the log.\n\n\n__Parameters__\n\n- **var_list**: A list of variable names to write, or None to write all variables\nthat exist in the experiment.\n\n__Example__\n\n~~~ .python\n# Write all variables to the logfile\nlog.write_vars()\n~~~\n\n\n\n</div>\n\n",
    "title": "Log functions",
    "url": "https://osdoc.cogsci.nl/4.1/manual/python/log",
    "path": "content/pages/manual/python/log.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# About Python\n\ntitle: About Python\n\nIn OpenSesame you can create complex experiments using only the graphical user interface (GUI). But you will sometimes encounter situations in which the functionality provided by the GUI is insufficient. In these cases you can add Python code to your experiment.\n\nPython is not supported in online experiments with OSWeb. If you need to run your experiment online, you have to use [JavaScript](%url:manual/javascript/about%) instead.\n\n[TOC]\n\n## Learning Python\n\nYou can find a set of basic tutorials and exercises to get you started with Python at <https://pythontutorials.eu/>.\n\n\n## Python in the OpenSesame GUI\n\n### A single Python workspace\n\nAll Python code is executed in a single Python workspace. This means that variables that have been defined in one INLINE_SCRIPT are accessible in all other INLINE_SCRIPTs, as well as in Python statements that are embedded in run-if statements and text strings. The same principle applies to modules: once `import`ed, they are available everywhere.\n\nFor example, you can simply construct the `Canvas` in one INLINE_SCRIPT ...\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\n~~~\n\n... and show it in another INLINE_SCRIPT ...\n\n~~~ .python\nmy_canvas.show()\n~~~\n\n### Inline_script items\n\nIn order to use Python code you need to add an INLINE_SCRIPT item to your experiment. You can do this by dragging the Python icon (the blue/yellow icon) from the item toolbar into the experiment sequence. After you have done this you will see something like %FigInlineScript.\n\n%--\nfigure:\n id: FigInlineScript\n source: inline-script.png\n caption: The INLINE_SCRIPT item.\n--%\n\nAs you can see, the INLINE_SCRIPT item consists of two tabs: one for the Prepare phase and one for the Run phase. The Prepare phase is executed first, to allow items to prepare for the time-critical run phase. It is good practice to construct `Canvas` objects, `Sampler` objects, etc. during the Prepare phase, so that they can be presented without delay during the Run phase. But this is only convention; you can execute arbitrary Python code during both phases.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Conditional (\"if\") expressions\n\nYou can use single-line Python expressions in conditional expressions. For example, you can use the following Python script as a run-if expression (see also %FigRunIf):\n\n~~~ .python\ncorrect == 1 and response_time < 1000\n~~~\n\n%--\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: Using Python script in the run-if statement of a SEQUENCE item.\n--%\n\nFor more information about conditional (\"if\") expressions, see:\n\n- %link:manual/variables%\n\n\n### Python in text strings\n\nYou can embed Python statements in text strings using the `{...} syntax. This works for simple variable references, but also for single-line expressions. For example, you could the following text to a SKETCHPAD:\n\n```text\nThe resolution is {width} x {height} px, which is a total of {width * height} pixels\n```\n\nDepending on your experiment's resolution, this might evaluate to:\n\n```text\nThe resolution is 1024 x 768 px, which is a total of 786432 pixels\n```\n\nFor more information about variables and text, see:\n\n- %link:manual/variables%\n- %link:manual/stimuli/text%\n\n\n### The Jupyter console (debug window)\n\nOpenSesame reroutes the standard output to the console (or: debug window), which you can activate using Control + D or through the menu (Menu -> View -> Show debug window; see %FigDebugNormal). You can print to the console using `print()`.\n\n~~~ .python\nprint('This will appear in the debug window!')\n~~~\n\nThe console is also an interactive Python interpreter powered by [project Jupyter](https://jupyter.org).\n\n\n## Things to know\n\n### Common functions\n\nMany common functions are directly available in an INLINE_SCRIPT item, without the need to import anything. For example:\n\n~~~ .python\n# `Canvas()` is a factory function that returns a `Canvas` object\nfixdot_canvas = Canvas()\nif sometimes(): # Sometimes the fixdot is green\n    fixdot_canvas.fixdot(color='green')\nelse: # Sometimes it is red\n    fixdot_canvas.fixdot(color='red')\nfixdot_canvas.show()\n~~~\n\nFor a list of common functions, see:\n\n- %link:manual/python/common%\n\n\n### The `var` object: Access to experimental variables\n\n__Version note__ As of OpenSesame 4.0, all experimental variables are available as globals. This means that you no longer need the `var` object.\n{:.page-notification}\n\nYou can access experimental variables through the `var` object:\n\n~~~ .python\n# OpenSesame <= 3.3 (with var object)\n# Get an experimental variable\nprint('my_variable is: %s' % var.my_variable)\n# Set an experimental variable\nvar.my_variable = 'my_value'\n\n# OpenSesame >= 4.0 (without var object)\n# Get an experimental variable\nprint('my_variable is: %s' % my_variable)\n# Set an experimental variable\nmy_variable = 'my_value'\n~~~\n\nA full overview of the `var` object can be found here:\n\n- %link:manual/python/var%\n\n\n### The `clock` object: Time functions\n\nBasic time functions are available through the `clock` object:\n\n~~~ .python\n# Get the current timestamp\nt = clock.time()\n# Wait for 1 s\nclock.sleep(1000)\n~~~\n\nA full overview of the `clock` object can be found here:\n\n- %link:manual/python/clock%\n\n\n### The `log` object: Data logging\n\nData logging is available through the `log` object:\n\n~~~ .python\n# Write one line of text\nlog.write('My custom log message')\n# Write all variables\nlog.write_vars()\n~~~\n\nA full overview of the `log` object can be found here:\n\n- %link:manual/python/log%\n\n\n### The `pool` object: Access to the file pool\n\nYou get the full path to a file in the file pool through the `pool` object:\n\n~~~ .python\n# Show an image from the file pool\npath = pool['img.png']\nmy_canvas = Canvas()\nmy_canvas.image(path)\nmy_canvas.show()\n~~~\n\nA full overview of the `pool` object can be found here:\n\n- %link:manual/python/pool%\n\n\n### The `responses` object: Access to participant responses\n\nThe `responses` object keeps track of all participant responses that have been collected during the experiment. For example, to list the correctness of all responses so far:\n\n~~~ .python\nfor response in responses:\n\tprint(response.correct)\n~~~\n\nA full overview of the `responses` object can be found here:\n\n- %link:manual/python/responses%\n\n\n### The `Canvas` class: Presenting visual stimuli\n\nThe `Canvas` class is used to present visual stimuli. For example, you can show a fixation dot as follows:\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\nmy_canvas.show()\n~~~\n\nA full overview of the `Canvas` class can be found here:\n\n- %link:manual/python/canvas%\n\n\n### The `Keyboard` class: Collecting key presses\n\nThe `Keyboard` class is used to collect key presses. For example, to collect a key press with a timeout of 1000 ms:\n\n~~~ .python\nmy_keyboard = Keyboard(timeout=1000)\nkey, time = my_keyboard.get_key()\n~~~\n\nA full overview of the `Keyboard` class can be found here:\n\n- %link:manual/python/keyboard%\n\n\n### The `Mouse` class: Collecting mouse clicks and screen touches\n\nThe `Mouse` class is used to collect mouse clicks and screen touches. (OpenSesame makes no distinction between the two.) For example, to collect a mouse click with a timeout of 1000 ms:\n\n~~~ .python\nmy_mouse = Mouse(timeout=1000)\nbutton, position, time = my_mouse.get_click()\n~~~\n\nA full overview of the `Mouse` class can be found here:\n\n- %link:manual/python/mouse%\n\n\n### The `Sampler` class: Sound playback\n\nThe `Sampler` class is used to play back sound samples. For example, to play back a simple beep:\n\n~~~ .python\nmy_sampler = Sampler()\nmy_sampler.play()\n~~~\n\nA full overview of the `Sampler` class can be found here:\n\n- %link:manual/python/sampler%\n\n\n## Alternative modules for display presentation, response collection, etc.\n\n\n### `psychopy`\n\nIf you are using the *psycho* backend, you can directly use the various [PsychoPy] modules. For more information, see:\n\n- %link:backends%\n\n\n### `expyriment`\n\nIf you are using the *xpyriment* backend, you can directly use the various [Expyriment] modules. For more information, see:\n\n- %link:backends%\n\n### `pygame`\n\nIf you are using the *legacy*, *droid*, or *xpyriment* (only with \"Use OpenGL\" set to \"no\") backend, you can directly use the various [PyGame] modules. For more information, see:\n\n- %link:backends%\n\n\n[python]: http://www.python.org/\n[backends]: /backends/about-backends\n[ipython]: http://ipython.org/\n[swaroop]: http://www.swaroopch.com/notes/Python\n[swaroop-direct]: http://www.ibiblio.org/swaroopch/byteofpython/files/120/byteofpython_120.pdf\n[downey]: http://www.greenteapress.com/thinkpython/\n[downey-direct]: http://www.greenteapress.com/thinkpython/thinkpython.pdf\n[opensesamerun]: /usage/opensesamerun/\n[psychopy]: http://www.psychopy.org/\n[expyriment]: http://www.expyriment.org/\n[pygame]: http://www.pygame.org/",
    "title": "About Python",
    "url": "https://osdoc.cogsci.nl/4.1/manual/python/about",
    "path": "content/pages/manual/python/about.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Common functions\n\ntitle: Common functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that these functions are commonly used in combination with Canvas functions\n- Explain that none of the listed functions need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\nThe following functions are available in INLINE_SCRIPT items:\n\n[TOC]\n\n<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n## Canvas(auto_prepare=True, \\*\\*style_args)\n\nA factory function that creates a new `Canvas` object. For a\ndescription of possible keywords, see:\n\n- %link:manual/python/canvas%\n\n\n__Returns__\n\n- A `Canvas` object.\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas(color=u'red', penwidth=2)\nmy_canvas.line(-10, -10, 10, 10)\nmy_canvas.line(-10, 10, 10, -10)\nmy_canvas.show()\n~~~\n\n\n\n## Experiment(osexp_path=None, log_path='defaultlog.csv', fullscreen=False, subject_nr=0, \\*\\*kwargs)\n\nA factory function that creates a new `Experiment` object. This is only\nuseful when implementing an experiment entirely through a Python script,\nrather than through the user interface.\n\n\n__Parameters__\n\n- **osexp_path**: If a path to an `.osexp` file is specified, this file is opened and\ncan be run directly by calling `Experiment.run()`. If no experiment\nfile is specified, an empty experiment is initialized.\n- **log_path**: \n- **fullscreen**: \n- **subject_nr**: \n- **kwargs**: Optional keyword arguments that are interpreted as experimental\nvariables. The main use of this is to specify the backend through\nthe `canvas_backend` keyword.\n\n__Returns__\n\n- An (exp, win, clock, log) tuple corresponding to the Experiment,\nwindow handle (backend-specific), Clock, and Log objects.\n\n__Example__\n\nTo implement an experiment fully programmatically:\n\n~~~ .python\nfrom libopensesame.python_workspace_api import (\n    Experiment, Canvas, Text, Keyboard)\nexp, win, clock, log = Experiment(canvas_backend='legacy')\nc = Canvas()\nc += Text('Press any key')\nc.show()\nkb = Keyboard()\nkb.get_key()\nexp.end()\n~~~\n\nTo load an experiment file and run it:\n\n~~~ .python\nfrom libopensesame.python_workspace_api import Experiment\nexp, win, clock, log = Experiment(osexp_path='my_experiment.osexp',\n                                  subject_nr=2)\nexp.run()\n~~~\n\n\n\n## Form(\\*args, \\*\\*kwargs)\n\nA factory function that creates a new `Form` object. For a\ndescription\nof possible keywords, see:\n\n- %link:manual/forms/widgets%\n\n\n__Returns__\n\n- A `Form` object.\n\n__Example__\n\n~~~ .python\nform = Form()\nlabel = Label(text='label')\nbutton = Button(text='Ok')\nform.set_widget(label, (0,0))\nform.set_widget(button, (0,1))\nform._exec()\n~~~\n\n\n\n## Keyboard(\\*\\*resp_args)\n\nA factory function that creates a new `Keyboard` object. For a\ndescription of possible keywords, see:\n\n- %link:manual/python/keyboard%\n\n\n__Returns__\n\n- A `Keyboard` object.\n\n__Example__\n\n~~~ .python\nmy_keyboard = Keyboard(keylist=[u'a', u'b'], timeout=5000)\nkey, time = my_keyboard.get_key()\n~~~\n\n\n\n## Mouse(\\*\\*resp_args)\n\nA factory function that creates a new `Mouse` object. For a\ndescription\nof possible keywords, see:\n\n- %link:manual/python/mouse%\n\n\n__Returns__\n\n- A `mouse` object.\n\n__Example__\n\n~~~ .python\nmy_mouse = Mouse(keylist=[1,3], timeout=5000)\nbutton, time = my_mouse.get_button()\n~~~\n\n\n\n## Sampler(src, \\*\\*playback_args)\n\nA factory function that creates a new `Sampler` object. For a\ndescription of possible keywords, see:\n\n- %link:manual/python/sampler%\n\n\n__Returns__\n\n- A SAMPLER object.\n\n__Example__\n\n~~~ .python\nsrc = pool['bark.ogg']\nmy_sampler = Sampler(src, volume=.5, pan='left')\nmy_sampler.play()\n~~~\n\n\n\n## Synth(osc='sine', freq=440, length=100, attack=0, decay=5, \\*\\*playback_args)\n\nA factory function that synthesizes a sound and returns it as a\n`Sampler` object.\n\n\n__Parameters__\n\n- **osc**: Oscillator, can be \"sine\", \"saw\", \"square\" or \"white_noise\".\n- **freq**: Frequency, either an integer value (value in hertz) or a string (\"A1\",\n\"eb2\", etc.).\n- **length**: The length of the sound in milliseconds.\n- **attack**: The attack (fade-in) time in milliseconds.\n- **decay**: The decay (fade-out) time in milliseconds.\n- **\\*\\*playback_args**: Optional playback keywords, such as volume and pan, as described under\n[/python/sampler/]().\n\n__Returns__\n\n- A SAMPLER object.\n\n__Example__\n\n~~~ .python\nmy_sampler = Synth(freq='b2', length=500)\n~~~\n\n\n\n## copy_sketchpad(name)\n\nReturns a copy of a `sketchpad`'s canvas.\n\n\n__Parameters__\n\n- **name**: The name of the `sketchpad`.\n\n__Returns__\n\n- A copy of the `sketchpad`'s canvas.\n\n__Example__\n\n~~~ .python\nmy_canvas = copy_sketchpad('my_sketchpad')\nmy_canvas.show()\n~~~\n\n\n\n## pause()\n\nPauses the experiment.\n\n\n\n\n## register_cleanup_function(fnc)\n\nRegisters a clean-up function, which is executed when the experiment\nends. Clean-up functions are executed at the very end, after the display,\nsound device, and log file have been closed. Clean-up functions are also\nexecuted when the experiment crashes.\n\n\n\n__Example__\n\n~~~ .python\ndef my_cleanup_function():\n        print(u'The experiment is finished!')\nregister_cleanup_function(my_cleanup_function)\n~~~\n\n\n\n## reset_feedback()\n\nResets all feedback variables to their initial state.\n\n\n\n__Example__\n\n~~~ .python\nreset_feedback()\n~~~\n\n\n\n## set_subject_nr(nr)\n\nSets the subject number and parity (even/ odd). This function is called\nautomatically when an experiment is started, so you only need to call it\nyourself if you overwrite the subject number that was specified when the\nexperiment was launched.\n\n\n__Parameters__\n\n- **nr**: The subject nr.\n\n__Example__\n\n~~~ .python\nset_subject_nr(1)\nprint('Subject nr = %d' % var.subject_nr)\nprint('Subject parity = %s' % var.subject_parity)\n~~~\n\n\n\n## sometimes(p=0.5)\n\nReturns True with a certain probability. (For more advanced\nrandomization, use the Python `random` module.)\n\n\n__Parameters__\n\n- **p**: The probability of returning True.\n\n__Returns__\n\n- True or False\n\n__Example__\n\n~~~ .python\nif sometimes():\n        print('Sometimes you win')\nelse:\n        print('Sometimes you loose')\n~~~\n\n\n\n## xy_circle(n, rho, phi0=0, pole=(0, 0))\n\nGenerates a list of points (x,y coordinates) in a circle. This can be\nused to draw stimuli in a circular arrangement.\n\n\n__Parameters__\n\n- **n**: The number of x,y coordinates to generate.\n- **rho**: The radial coordinate, also distance or eccentricity, of the first\npoint.\n- **phi0**: The angular coordinate for the first coordinate. This is a\ncounterclockwise rotation in degrees (i.e. not radians), where 0 is\nstraight right.\n- **pole**: The reference point.\n\n__Returns__\n\n- A list of (x,y) coordinate tuples.\n\n__Example__\n\n~~~ .python\n# Draw 8 rectangles around a central fixation dot\nc = Canvas()\nc.fixdot()\nfor x, y in xy_circle(8, 100):\n        c.rect(x-10, y-10, 20, 20)\nc.show()\n~~~\n\n\n\n## xy_distance(x1, y1, x2, y2)\n\nGives the distance between two points.\n\n\n__Parameters__\n\n- **x1**: The x coordinate of the first point.\n- **y1**: The y coordinate of the first point.\n- **x2**: The x coordinate of the second point.\n- **y2**: The y coordinate of the second point.\n\n__Returns__\n\n- The distance between the two points.\n\n\n## xy_from_polar(rho, phi, pole=(0, 0))\n\nConverts polar coordinates (distance, angle) to Cartesian coordinates\n(x, y).\n\n\n__Parameters__\n\n- **rho**: The radial coordinate, also distance or eccentricity.\n- **phi**: The angular coordinate. This reflects a clockwise rotation in degrees\n(i.e. not radians), where 0 is straight right.\n- **pole**: The reference point.\n\n__Returns__\n\n- An (x, y) coordinate tuple.\n\n__Example__\n\n~~~ .python\n# Draw a cross\nx1, y1 = xy_from_polar(100, 45)\nx2, y2 = xy_from_polar(100, -45)\nc = Canvas()\nc.line(x1, y1, -x1, -y1)\nc.line(x2, y2, -x2, -y2)\nc.show()\n~~~\n\n\n\n## xy_grid(n, spacing, pole=(0, 0))\n\nGenerates a list of points (x,y coordinates) in a grid. This can be\nused to draw stimuli in a grid arrangement.\n\n\n__Parameters__\n\n- **n**: An `int` that indicates the number of columns and rows, so that `n=2`\nindicates a 2x2 grid, or a (n_col, n_row) `tuple`, so that `n=(2,3)`\nindicates a 2x3 grid.\n- **spacing**: A numeric value that indicates the spacing between cells, or a\n(col_spacing, row_spacing) tuple.\n- **pole**: The reference point.\n\n__Returns__\n\n- A list of (x,y) coordinate tuples.\n\n__Example__\n\n~~~ .python\n# Draw a 4x4 grid of rectangles\nc = Canvas()\nc.fixdot()\nfor x, y in xy_grid(4, 100):\n        c.rect(x-10, y-10, 20, 20)\nc.show()\n~~~\n\n\n\n## xy_random(n, width, height, min_dist=0, pole=(0, 0))\n\nGenerates a list of random points (x,y coordinates) with a minimum\nspacing between each pair of points. This function will raise an\nException when the coordinate list cannot be generated,  typically because\nthere are too many points, the min_dist is set too high, or the width or\nheight are set too low.\n\n\n__Parameters__\n\n- **n**: The number of points to generate.\n- **width**: The width of the field with random points.\n- **height**: The height of the field with random points.\n- **min_dist**: The minimum distance between each point.\n- **pole**: The reference point.\n\n__Returns__\n\n- A list of (x,y) coordinate tuples.\n\n__Example__\n\n~~~ .python\n# Draw a 50 rectangles in a random grid\nc = Canvas()\nc.fixdot()\nfor x, y in xy_random(50, 500, 500, min_dist=40):\n        c.rect(x-10, y-10, 20, 20)\nc.show()\n~~~\n\n\n\n## xy_to_polar(x, y, pole=(0, 0))\n\nConverts Cartesian coordinates (x, y) to polar coordinates (distance,\nangle).\n\n\n__Parameters__\n\n- **x**: The X coordinate.\n- **y**: The Y coordinate.\n- **pole**: The reference point.\n\n__Returns__\n\n- An (rho, phi) coordinate tuple. Here, `rho` is the radial coordinate,\nalso distance or eccentricity. `phi` is the angular coordinate in\ndegrees (i.e. not radians), and reflects a counterclockwise rotation,\nwhere 0 is straight right.\n\n__Example__\n\n~~~ .python\nrho, phi = xy_to_polar(100, 100)\n~~~\n\n\n\n</div>\n\n",
    "title": "Common functions",
    "url": "https://osdoc.cogsci.nl/4.1/manual/python/common",
    "path": "content/pages/manual/python/common.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Canvas functions\n\ntitle: Canvas functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that `Canvas` and Element classes do not need to be imported\n- Explain the process to initialize a `Canvas`\n- Discuss three methods of drawing elements:\n    - Naming an Element interface (`my_canvas['name'] = FixDot()`)\n    - Adding an Element interface (`my_canvas += FixDot()`)\n    - Not preferred: function interface (`my_canvas.fixdot()`)\n- Illustrate how to modify named elements with an example\n- Define the usage of `**style_args`\n- Explain how to specify colors\n- Explain coordinates: x=0, y=0 is the display center\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# class __Canvas__\n\n{% set arg_max_width = \"The maximum width of the text in pixels, \" +\n\"before wrapping to a new line, or `None` to wrap at screen edge.\" %}\n\n{% set arg_bgmode = \"Specifies whether the background is the average of \" +\n\"col1 and col2 ('avg', corresponding to a typical Gabor patch), or \" + \n\"equal to col2 ('col2'), useful for blending into the background. Note: \" +\n\"this parameter is ignored by the psycho backend, which uses increasing \" + \n\"transparency for the background.\" %}\n\n{% set arg_style = \"Optional [style keywords](#style-keywords) that \" + \n\"specify the style of the current drawing operation. This does not \" + \n\"affect subsequent drawing operations.\" %}\n\n{% set arg_center = \"A bool indicating whether the coordinates reflect \" + \n\"the center (`True`) or top-left (`False`) of the text.\" %}\n\nThe `Canvas` class is used to present visual stimuli. You generally create a\n`Canvas` object with the `Canvas()` factory function, as described in the section\n[Creating a Canvas](#creating-a-canvas).\n\n__Example__:\n\n~~~ .python\n# Create and show a canvas with a central fixation dot\nmy_canvas = Canvas()\nmy_canvas.fixdot()\nmy_canvas.show()\n~~~\n\n__Example__:\n\nYou can also add `Canvas` elements as objects. See also the section on [Naming,\naccessing, and modifying elements](#naming-accessing-and-modifying-elements).\n\n~~~ .python\n# Create a canvas with a fixation dot and a rectangle\nmy_canvas = Canvas()\nmy_canvas['my_fixdot'] = FixDot()\nmy_canvas.show()\n~~~\n\n[TOC]\n\n## Things to know\n\n### Creating a Canvas\n\nYou generally create a `Canvas` with the `Canvas()` factory function:\n\n~~~ .python\nmy_canvas = Canvas()\n~~~\n\nOptionally, you can pass [Style keywords](#style-keywords) to `Canvas()` to set\nthe default style:\n\n~~~ .python\nmy_canvas = Canvas(color='green')\nmy_canvas.fixdot() # Will be green\n~~~\n\n### Style keywords\n\nAll functions that accept `**style_args` take the following keyword arguments:\n\n- `color` specifies the foreground color. For valid color specifications, see\n  [colors](#colors).\n- `background_color` specifies the background color. For valid color\n  specifications, see [colors](#colors).\n- `fill` indicates whether rectangles, circles, polygons, and ellipses are\n  filled (`True`), or drawn as an outline (`False`).\n- `penwidth` indicates a penwidth in pixels and should be `int` or `float`.\n- `html` indicates whether HTML-tags are interpreted, and should be `True` or\n  `False`.\n- `font_family` is the name of a font family, such as 'sans'.\n- `font_size` is a font size in pixels.\n- `font_italic` indicates whether text should italics, and should be `True` or\n  `False`.\n- `font_bold` indicates whether text should bold, and should be `True` or\n  `False`.\n- `font_underline` indicates whether text should underlined, and should be\n  `True` or `False`.\n\n~~~ .python\n# Draw a green fixation dot\nmy_canvas = Canvas()\nmy_canvas.fixdot(color='green')\nmy_canvas.show()\n~~~\n\nStyle keywords only affect the current drawing operation (except when passed to\n`Canvas()` while creating the `Canvas`). To change the style for all subsequent\ndrawing operations, set style properties, such as `canvas.color`, directly:\n\n~~~ .python\n# Draw a red cross with a 2px penwidth\nmy_canvas = Canvas()\nmy_canvas.color = 'red'\nmy_canvas.penwidth = 2\nmy_canvas.line(-10, -10, 10, 10)\nmy_canvas.line(-10, 10, 10, -10)\nmy_canvas.show()\n~~~\n\nOr pass the style properties to `Canvas()`:\n\n~~~ .python\n# Draw a red cross with a 2px penwidth\nmy_canvas = Canvas(color='red', penwidth=2)\nmy_canvas.line(-10, -10, 10, 10)\nmy_canvas.line(-10, 10, 10, -10)\nmy_canvas.show()\n~~~\n\n### Colors\n\nYou can specify colors in the following ways. This includes CSS3-type color\nspecifications, but also supports some extra specifications, such as CIE l* a*\nb* color space.\n\n__Version note:__ The `hsv`, `hsl`, and `lab` color spaces are new in v3.3.0.\n\n- __Color names:__ 'red', 'black', etc. A full list of valid color names can be\n  found [here](http://www.w3.org/TR/SVG11/types.html#ColorKeywords).\n- __Seven-character hexadecimal strings:__ `#FF0000`, `#000000`, etc. Here,\n  values range from `00` to `FF`, so that `#FF0000` is bright red.\n- __Four-character hexadecimal strings:__ `#F00`, `#000`, etc. Here, values\n  range from '0' to 'F' so that `#F00` is bright red.\n- __RGB strings:__ `rgb(255,0,0)`, `rgb(0,0,0)`, etc. Here, values range from\n  0 to 255 so that `rgb(255,0,0)` is bright red.\n- __RGB percentage strings:__ `rgb(100%,0%,0%)`, `rgb(0%,0%,0%)`, etc. Here,\n  values range from 0% to 100% so that `rgb(100%,0%,0%)` is bright red.\n- __RGB tuples:__ `(255, 0, 0)`, `(0, 0 ,0)`, etc. Here, values range from `0`\n  to `255` so that `(255,0,0)' is bright red.\n- __HSV strings:__ `hsv(120, 100%, 100%)`. In the [HSV](https://en.wikipedia.org/\n  wiki/HSL_and_HSV) color space, the hue parameter is an angle from 0 to 359,\n  and the saturation and value parameters are percentages from 0% to 100%.\n- __HSL strings:__ `hsl(120, 100%, 50%)`. In the [HSL](https://en.wikipedia.org/\n  wiki/HSL_and_HSV) color space, the hue parameter is an angle from 0 to 359,\n  and the saturation and lightness parameters are percentages from 0% to 100%.\n- __LAB strings:__ `lab(53, -20, 0)`. In the [CIELAB](https://en.wikipedia.org/\n  wiki/CIELAB_color_space) color space, the parameters reflect lightness (`l*`),\n  green-red axis (`a*`, negative is green), and blue-yellow axis (`b*`, negative\n  is blue). This uses the D65 white point and the sRGB transfer function, as\n  implemented [here](https://www.psychopy.org/_modules/psychopy/tools/\n  colorspacetools.html).\n- __Luminance values:__  `255`, `0`, etc. Here, values range from `0` to `255`\n  so that `255` is white.\n\n~~~ .python\n# Various ways to specify green\nmy_canvas.fixdot(color='green')  # Dark green\nmy_canvas.fixdot(color='#00ff00')\nmy_canvas.fixdot(color='#0f0')\nmy_canvas.fixdot(color='rgb(0, 255, 0)')\nmy_canvas.fixdot(color='rgb(0%, 100%, 0%)')\nmy_canvas.fixdot(color='hsl(100, 100%, 50%)')\nmy_canvas.fixdot(color='hsv(0, 100%, 100%)')\nmy_canvas.fixdot(color='lab(53, -20, 0)')  # Dark green\nmy_canvas.fixdot(color=(0, 255, 0))  # Specify a luminance value (white)\n~~~\n\n### Naming, accessing, and modifying elements\n\nAs of OpenSesame 3.2, the `Canvas` supports an object-based interface that allows\nyou to name elements, and to access and modify elements individually, without\nhaving to redraw the entire `Canvas`.\n\nFor example, the following will first add a red `Line` element to a `Canvas`\nand show it, then change the color of the line to green and show it again,\nand then finally delete the line and show the canvas again (which is now blank).\nThe name of the element (`my_line`) is used to refer to the element for all the\noperations.\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas['my_line'] = Line(-100, -100, 100, 100, color='red')\nmy_canvas.show()\nclock.sleep(1000)\nmy_canvas['my_line'].color = 'green'\nmy_canvas.show()\nclock.sleep(1000)\ndel my_canvas['my_line']\nmy_canvas.show()\n~~~\n\nYou can also add an element without explicitly providing a name for it. In that\ncase, a name is generated automatically (e.g. `stim0`).\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas += FixDot()\nmy_canvas.show()\n~~~\n\nIf you add a list of elements, they will be automatically grouped together, and\nyou can refer to the entire group by name.\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas['my_cross'] = [    Line(-100, 0, 100, 0),    Line(0, -100, 0, 100)]\nmy_canvas.show()\n~~~\n\nTo check whether a particular `x,y` coordinate falls within the bounding\nrectangle of an element, you can use `in`:\n\n~~~ .python\nmy_mouse = Mouse(visible=True)\nmy_canvas = Canvas()\nmy_canvas['rect'] = Rect(-100, -100, 200, 200)\nmy_canvas.show()\nbutton, (x, y), time = my_mouse.get_click()\nif (x, y) in my_canvas['rect']:\n    print('Clicked in rectangle')\nelse:\n    print('Clicked outside of rectangle')\n~~~\n\nYou can also get a list of the names of all elements that contain an `x,y`\ncoordinate, using the `Canvas.elements_at()` function, documented below.\n\n## arrow(sx, sy, ex, ey, body_length=0.8, body_width=0.5, head_width=30, \\*\\*style_args)\n\nDraws an arrow. An arrow is a polygon consisting of 7 vertices,\nwith an arrowhead pointing at (ex, ey).\n\n\n__Parameters__\n\n- **sx**: The X coordinate of the arrow's base.\n- **sy**: The Y coordinate of the arrow's base.\n- **ex**: The X coordinate of the arrow's tip.\n- **ey**: The Y coordinate of the arrow's tip..\n- **body_length**: Proportional length of the arrow body relative to the full arrow\n[0-1].\n- **body_width**: Proportional width (thickness) of the arrow body relative to the\nfull arrow [0-1].\n- **head_width**: Width (thickness) of the arrow head in pixels.\n\n\n## circle(x, y, r, \\*\\*style_args)\n\nDraws a circle.\n\n\n__Parameters__\n\n- **x**: The center X coordinate of the circle.\n- **y**: The center Y coordinate of the circle.\n- **r**: The radius of the circle.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.circle(100, 100, 50, fill=True, color='red')\n# Element interface\nmy_canvas['my_circle'] = Circle(100, 100, 50, fill=True, color='red')\n~~~\n\n\n\n## clear(\\*arglist, \\*\\*kwdict)\n\nClears the canvas with the current background color. Note that it\nis generally faster to use a different canvas for each experimental\ndisplay than to use a single canvas and repeatedly clear and redraw it.\n\n\n__Parameters__\n\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot(color='green')\nmy_canvas.show()\nclock.sleep(1000)\nmy_canvas.clear()\nmy_canvas.fixdot(color='red')\nmy_canvas.show()\n~~~\n\n\n\n## copy(canvas)\n\nTurns the current `Canvas` into a copy of the passed `Canvas`.\n\n__Warning:__\n\nCopying `Canvas` objects can result in unpredictable behavior. In many\ncases, a better solution is to recreate multiple `Canvas` objects from\nscratch, and/ or to use the element interface to update `Canvas`\nelements individually.\n\n__Parameters__\n\n- **canvas**: The `Canvas` to copy.\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot(x=100, color='green')\nmy_copied_canvas = Canvas()\nmy_copied_canvas.copy(my_canvas)\nmy_copied_canvas.fixdot(x=200, color=\"blue\")\nmy_copied_canvas.show()\n~~~\n\n\n\n## elements_at(x, y)\n\n*New in v3.2.0*\n\nGets the names of elements that contain a\nparticular `x, y`\ncoordinate.\n\n__Parameters__\n\n- **x**: An X coordinate.\n- **y**: A Y coordinate.\n\n__Returns__\n\n- A `list` of element names that contain the coordinate `x, y`.\n\n__Example__\n\n~~~ .python\n# Create and show a canvas with two partly overlapping rectangles\nmy_canvas = Canvas()\nmy_canvas['right_rect'] = Rect(x=-200, y=-100, w=200, h=200, color='red')\nmy_canvas['left_rect'] = Rect(x=-100, y=-100, w=200, h=200, color='green')\nmy_canvas.show()\n# Collect a mouse click and print the names of the elements that\n# contain the clicked point\nmy_mouse = Mouse(visible=True)\nbutton, pos, time = my_mouse.get_click()\nif pos is not None:\n    x, y = pos\n    print('Clicked on elements: %s' % my_canvas.elements_at(x, y))\n~~~\n\n\n\n## ellipse(x, y, w, h, \\*\\*style_args)\n\nDraws an ellipse.\n\n\n__Parameters__\n\n- **x**: The left X coordinate.\n- **y**: The top Y coordinate.\n- **w**: The width.\n- **h**: The height.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.ellipse(-10, -10, 20, 20, fill=True)\n# Element interface\nmy_canvas['my_ellipse'] = Ellipse(-10, -10, 20, 20, fill=True)\n~~~\n\n\n\n## fixdot(x=None, y=None, style='default', \\*\\*style_args)\n\nDraws a fixation dot. The default style is medium-open.\n\n- 'large-\nfilled' is a filled circle with a 16px radius.\n- 'medium-filled' is a\nfilled circle with an 8px radius.\n- 'small-filled' is a filled circle\nwith a 4px radius.\n- 'large-open' is a filled circle with a 16px radius\nand a 2px hole.\n- 'medium-open' is a filled circle with an 8px radius\nand a 2px hole.\n- 'small-open' is a filled circle with a 4px radius and\na 2px hole.\n- 'large-cross' is 16px cross.\n- 'medium-cross' is an 8px\ncross.\n- 'small-cross' is a 4px cross.\n\n__Parameters__\n\n- **x**: The X coordinate of the dot center, or None to draw a horizontally\ncentered dot.\n- **y**: The Y coordinate of the dot center, or None to draw a vertically\ncentered dot.\n- **style**: The fixation-dot style. One of: default, large-filled,\nmedium-\nfilled, small-filled, large-open, medium-open,\nsmall-open, large-\ncross, medium-cross, or small-cross.\ndefault equals medium-open.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.fixdot()\n# Element interface\nmy_canvas['my_fixdot'] = FixDot()\n~~~\n\n\n\n## gabor(x, y, orient, freq, env='gaussian', size=96, stdev=12, phase=0, col1='white', col2='black', bgmode='avg')\n\nDraws a Gabor patch. Note: The exact rendering of the Gabor patch\ndepends on the back-end.\n\n\n__Parameters__\n\n- **x**: The center X coordinate.\n- **y**: The center Y coordinate.\n- **orient**: Orientation in degrees [0 .. 360]. This refers to a\nclockwise rotation from a vertical.\n- **freq**: Frequency in cycles/px of the sinusoid.\n- **env**: The envelope that determines the shape of the patch. Can be\n\"gaussian\", \"linear\", \"circular\", or \"rectangular\".\n- **size**: A size in pixels.\n- **stdev**: Standard deviation in pixels of the gaussian. Only applicable to\ngaussian envelopes.\n- **phase**: Phase of the sinusoid [0.0 .. 1.0].\n- **col1**: A color for the peaks.\n- **col2**: A color for the troughs. Note: The psycho back-end\nignores this\nparameter and always uses the inverse of\n`col1` for the throughs.\n- **bgmode**: {{arg_bgmode}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.gabor(100, 100, 45, .05)\n# Element interface\nmy_canvas['my_gabor'] = Gabor(100, 100, 45, .05)\n~~~\n\n\n\n## image(fname, center=True, x=None, y=None, scale=None, rotation=None)\n\nDraws an image from file. This function does not look in the file\npool, but takes an absolute path.\n\n\n__Parameters__\n\n- **fname**: The filename of the image. When using Python 2, this should be\neither `unicode` or a utf-8-encoded `str`. When using Python 3,\nthis should be either `str` or a utf-8-encoded `bytes`.\n- **center**: A bool indicating whether coordinates indicate the center (True) or\ntop-left (False).\n- **x**: The X coordinate, or `None` to draw a horizontally centered image.\n- **y**: The Y coordinate, or `None` to draw a vertically centered image.\n- **scale**: The scaling factor of the image. `None` or 1 indicate the original\nsize. 2.0 indicates a 200% zoom, etc.\n- **rotation**: The rotation of the image `None` or 0 indicate the original\nrotation. Positive values indicate a clockwise rotation in degrees.\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Determine the absolute path:\npath = exp.pool['image_in_pool.png']\n# Function interface\nmy_canvas.image(path)\n# Element interface\nmy_canvas['my_image'] = Image(path)\n~~~\n\n\n\n## line(sx, sy, ex, ey, \\*\\*style_args)\n\nDraws a line.\n\n\n__Parameters__\n\n- **sx**: The left X coordinate.\n- **sy**: The top Y coordinate.\n- **ex**: The right X coordinate.\n- **ey**: The bottom Y coordinate.\n- **\\*\\*style_args**: {{arg_style}}\n\n\n## lower_to_bottom(element)\n\nLowers an element to the bottom, so that it is drawn first; that\nis, it becomes the background.\n\n\n__Parameters__\n\n- **element**: A SKETCHPAD element, or its name.\n\n\n## noise_patch(x, y, env='gaussian', size=96, stdev=12, col1='white', col2='black', bgmode='avg')\n\nDraws a patch of noise, with an envelope. The exact rendering of\nthe noise patch depends on the back-end.\n\n\n__Parameters__\n\n- **x**: The center X coordinate.\n- **y**: The center Y coordinate.\n- **env**: The envelope that determines the shape of the patch. Can be\n\"gaussian\", \"linear\", \"circular\", or \"rectangular\".\n- **size**: A size in pixels.\n- **stdev**: Standard deviation in pixels of the gaussian. Only applicable to\ngaussian envelopes.\n- **col1**: The first color.\n- **col2**: The second color. Note: The psycho back-end ignores this\nparameter\nand always uses the inverse of `col1`.\n- **bgmode**: {{arg_bgmode}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.noise_patch(100, 100, env='circular')\n# Element interface\nmy_canvas['my_noise_patch'] = NoisePatch(100, 100, env='circular')\n~~~\n\n\n\n## polygon(vertices, \\*\\*style_args)\n\nDraws a polygon that defined by a list of vertices. I.e. a shape of\npoints connected by lines.\n\n\n__Parameters__\n\n- **vertices**: A list of tuples, where each tuple corresponds to a vertex. For\nexample, [(100,100), (200,100), (100,200)] will draw a triangle.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\nn1 = 0,0\nn2 = 100, 100\nn3 = 0, 100\n# Function interface\nmy_canvas.polygon([n1, n2, n3])\n# Element interface\nmy_canvas['my_polygon'] = Polygon([n1, n2, n3])\n~~~\n\n\n\n## prepare()\n\nFinishes pending canvas operations (if any), so that a subsequent\ncall to [canvas.show] is extra fast. It's only necessary to call this\nfunction if you have disabled `auto_prepare` when initializing the\n`Canvas`.\n\n\n\n\n## raise_to_top(element)\n\nRaises an element to the top, so that it is drawn last; that is, it\nbecomes the foreground.\n\n\n__Parameters__\n\n- **element**: A SKETCHPAD element, or its name.\n\n\n## rect(x, y, w, h, \\*\\*style_args)\n\nDraws a rectangle.\n\n\n__Parameters__\n\n- **x**: The left X coordinate.\n- **y**: The top Y coordinate.\n- **w**: The width.\n- **h**: The height.\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.rect(-10, -10, 20, 20, fill=True)\n# Element interface\nmy_canvas['my_rect'] = Rect(-10, -10, 20, 20, fill=True)\n~~~\n\n\n\n## rename_element(old_name, new_name)\n\nRenames an element.\n\n\n\n\n## show()\n\nShows, or 'flips', the canvas on the screen.\n\n\n\n__Returns__\n\n- A timestamp of the time at which the canvas actually appeared on\nthe screen, or a best guess if precise temporal information is not\navailable. For more information about timing, see </misc/timing>.\nDepending on the back-end the timestamp is an `int` or a `float`.\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\nt = my_canvas.show()\nexp.set('time_fixdot', t)\n~~~\n\n\n\n## text(text, center=True, x=None, y=None, max_width=None, \\*\\*style_args)\n\nDraws text.\n\n\n__Parameters__\n\n- **text**: A string of text. When using Python 2, this should be either\n`unicode` or a utf-8-encoded `str`. When using Python 3, this\nshould be either `str` or a utf-8-encoded `bytes`.\n- **center**: {{arg_center}}\n- **x**: The X coordinate, or None to draw horizontally centered text.\n- **y**: The Y coordinate, or None to draw vertically centered text.\n- **max_width**: {{arg_max_width}}\n- **\\*\\*style_args**: {{arg_style}}\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\n# Function interface\nmy_canvas.text('Some text with <b>boldface</b> and <i>italics</i>')\n# Element interface\nmy_canvas['my_text'] = Text('Some text with <b>boldface</b> and <i>italics</i>')\n~~~\n\n\n\n## text_size(text, center=True, max_width=None, \\*\\*style_args)\n\nDetermines the size of a text string in pixels.\n\n\n__Parameters__\n\n- **text**: A string of text.\n- **center**: {{arg_center}}\n- **max_width**: {{arg_max_width}}\n- **\\*\\*style_args**: {{arg_style}}\n\n__Returns__\n\n- A (width, height) tuple containing the dimensions of the text\nstring.\n\n__Example__\n\n~~~ .python\nmy_canvas = Canvas()\nw, h = my_canvas.text_size('Some text')\n~~~\n\n\n\n</div>\n\n",
    "title": "Canvas functions",
    "url": "https://osdoc.cogsci.nl/4.1/manual/python/canvas",
    "path": "content/pages/manual/python/canvas.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Access items\n\ntitle: Access items\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `items` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __items__\n\nThe `items` object provides dict-like access to the items. It's mainly\nuseful for programmatically executing items.\n\nAn `items` object is created automatically when the experiment starts.\n\nIn addition to the functions listed below, the following semantics are\nsupported:\n\n__Example__\n\n~~~ .python\n# Programmatically prepare and run a sketchpad item.\nitems.execute('my_sketchpad')\n# Check if an item exists\nif 'my_sketchpad' in items:\n    print('my_sketchpad exists')\n# Delete an item\ndel items['my_sketchpad']\n# Walk through all item names\nfor item_name in items:\n    print(item_name)\n~~~\n\n[TOC]\n\n## execute(name)\n\nExecutes the run and prepare phases of an item, and updates the\nitem stack.\n\n\n__Parameters__\n\n- **name**: An item name.\n\n__Example__\n\n~~~ .python\nitems.execute('target_sketchpad')\n~~~\n\n\n\n## new(_type, name=None, script=None, allow_rename=True)\n\nCreates a new item.\n\n\n__Parameters__\n\n- **_type**: The item type.\n- **name**: The item name, or None to choose a unique name based on the item\ntype.\n- **script**: A definition script, or None to start with a blank item.\n- **allow_rename**: Indicates whether OpenSesame can use a different name from the one\nthat is provided as `name` to avoid duplicate names etc.\n\n__Returns__\n\n- The newly generated item.\n\n__Example__\n\n~~~ .python\nitems.new('sketchpad', name='my_sketchpad')\nitems['my_sketchpad'].prepare()\nitems['my_sketchpad'].run()\n~~~\n\n\n\n## prepare(name)\n\nExecutes the prepare phase of an item, and updates the item stack.\n\n\n__Parameters__\n\n- **name**: An item name.\n\n__Example__\n\n~~~ .python\nitems.prepare('target_sketchpad')\nitems.run('target_sketchpad')\n~~~\n\n\n\n## run(name)\n\nExecutes the run phase of an item, and updates the item stack.\n\n\n__Parameters__\n\n- **name**: An item name.\n\n__Example__\n\n~~~ .python\nitems.prepare('target_sketchpad')\nitems.run('target_sketchpad')\n~~~\n\n\n\n## valid_name(item_type, suggestion=None)\n\nGenerates a unique name that is valid and resembles the desired\nname.\n\n\n__Parameters__\n\n- **item_type**: The type of the item to suggest a name for.\n- **suggestion**: The desired name, or None to choose a name based on the item's\ntype.\n\n__Returns__\n\n- A unique name.\n\n__Example__\n\n~~~ .python\nvalid_name = items.valid_name('sketchpad', 'an invalid name')\n~~~\n\n\n\n</div>\n\n",
    "title": "Access items",
    "url": "https://osdoc.cogsci.nl/4.1/manual/python/items",
    "path": "content/pages/manual/python/items.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Keyboard functions\n\ntitle: Keyboard functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `Keyboard` class does not need to be imported\n- Explain the process to initialize a Keyboard\n- Define the usage of `**resp_args`\n- Explain how to specify key names\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# class __Keyboard__\n\nThe `Keyboard` class is used to collect keyboard responses. You generally create\na `Keyboard` object with the `Keyboard()` factory function, as described in the\nsection [Creating a Keyboard](#creating-a-keyboard).\n\n__Example__\n\n~~~ .python\n# Wait for a 'z' or 'x' key with a timeout of 3000 ms\nmy_keyboard = Keyboard(keylist=['z', 'x'], timeout=3000)\nstart_time = clock.time()\nkey, end_time = my_keyboard.get_key()\nresponse = key\nresponse_time = end_time - start_time\n~~~\n\n[TOC]\n\n## Things to know\n\n### Creating a Keyboard\n\nYou generally create a `Keyboard` with the `Keyboard()` factory function:\n\n~~~ .python\nmy_keyboard = Keyboard()\n~~~\n\nOptionally, you can pass [Response keywords](#response-keywords) to `Keyboard()`\nto set the default behavior:\n\n~~~ .python\nmy_keyboard = Keyboard(timeout=2000)\n~~~\n\n### Key names\n\n- Key names may differ between backends.\n- Keys can be identified either by character or name, and are case-insensitive.\n  For example:\n  - The key 'a' is represented by 'a' and 'A'\n  - The up arrow is represented by 'up' and 'UP'\n  - The '/' key is represented by '/', 'slash', and 'SLASH'\n  - The spacebar is represented by 'space' and 'SPACE'\n- To find out the name of key, you can:\n  - Click on the 'list available keys' button of the KEYBOARD_RESPONSE item.\n  - Collect a key press with a KEYBOARD_RESPONSE item, and display the key name\n    through a FEEDBACK item with the text 'You pressed [response]' in it.\n\n### Response keywords\n\nFunctions that accept `**resp_args` take the following keyword arguments:\n\n- `timeout` specifies a timeout value in milliseconds, or is set to `None` to\n  disable the timeout.\n- `keylist` specifies a list of keys that are accepted, or is set to `None`\n  accept all keys.\n\n~~~ .python\n# Get a left or right arrow press with a timeout of 3000 ms\nmy_keyboard = Keyboard()\nkey, time = my_keyboard.get_key(keylist=[u'left', u'right'], timeout=3000)\n~~~\n\nResponse keywords only affect the current operation (except when passed to\n`Keyboard()`). To change the behavior for all subsequent\noperations, set the response properties directly:\n\n~~~ .python\n# Get two key A or B presses with a 5000 ms timeout\nmy_keyboard = Keyboard()\nmy_keyboard.keylist = [u'a', u'b']\nmy_keyboard.timeout = 5000\nkey1, time1 = my_keyboard.get_key()\nkey2, time2 = my_keyboard.get_key()\n~~~\n\nOr pass the response options to [keyboard.__init__][__init__]:\n\n~~~ .python\n# Get two key A or B presses with a 5000 ms timeout\nmy_keyboard = Keyboard(keylist=[u'a', u'b'], timeout=5000)\nkey1, time1 = my_keyboard.get_key()\nkey2, time2 = my_keyboard.get_key()\n~~~\n\n## flush()\n\nClears all pending keyboard input, not limited to the keyboard.\n\n\n\n__Returns__\n\n- True if a key had been pressed (i.e., if there was something to\nflush) and False otherwise.\n\n\n## get_key(\\*arglist, \\*\\*kwdict)\n\nCollects a single key press.\n\n\n__Parameters__\n\n- **\\*\\*resp_args**: Optional [response keywords](#response-keywords) (`timeout` and\n`keylist`) that will be used for this call to `Keyboard.get_key()`.\nThis does not affect subsequent operations.\n\n__Returns__\n\n- A `(key, timestamp)` tuple. `key` is None if a timeout occurs.\n\n__Example__\n\n~~~ .python\nmy_keyboard = Keyboard()\nresponse, timestamp = my_keyboard.get_key(timeout=5000)\nif response is None:\n        print(u'A timeout occurred!')\n~~~\n\n\n\n## get_key_release(\\*arglist, \\*\\*kwdict)\n\n*New in v3.2.0*\n\nCollects a single key release.\n\n*Important:* This\nfunction currently assumes a QWERTY keyboard\nlayout (unlike\n`Keyboard.get_key()`). This means that the returned\n`key` may be\nincorrect on non-QWERTY keyboard layouts. In addition,\nthis function is\nnot implemented for the *psycho* backend.\n\n__Parameters__\n\n- **\\*\\*resp_args**: Optional [response keywords](#response-keywords) (`timeout` and\n`keylist`) that will be used for this call to\n`Keyboard.get_key_release()`. This does not affect subsequent\noperations.\n\n__Returns__\n\n- A `(key, timestamp)` tuple. `key` is None if a timeout occurs.\n\n__Example__\n\n~~~ .python\nmy_keyboard = Keyboard()\nresponse, timestamp = my_keyboard.get_key_release(timeout=5000)\nif response is None:\n        print(u'A timeout occurred!')\n~~~\n\n\n\n## get_mods()\n\nReturns a list of keyboard moderators (e.g., shift, alt, etc.) that\nare currently pressed.\n\n\n\n__Returns__\n\n- A list of keyboard moderators. An empty list is returned if no\nmoderators are pressed.\n\n__Example__\n\n~~~ .python\nmy_keyboard = Keyboard()\nmoderators = my_keyboard.get_mods()\nif u'shift' in moderators:\n        print(u'The shift-key is down!')\n~~~\n\n\n\n## show_virtual_keyboard(visible=True)\n\nShows or hides a virtual keyboard if this is supported by the\nback-end. This function is only necessary if you want the virtual\nkeyboard to remain visible while collecting multicharacter\nresponses. Otherwise, `Keyboard.get_key()` will implicitly show and\nhide the keyboard for a single-character response.\n\nThis function does nothing for back-ends that do not support virtual\nkeyboards.\n\n__Parameters__\n\n- **visible**: True if the keyboard should be shown, False otherwise.\n\n__Example__\n\n~~~ .python\nmy_keyboard = Keyboard()\nmy_keyboard.show_virtual_keyboard(True)\nresponse1, timestamp2 = my_keyboard.get_key()\nresponse2, timestamp2 = my_keyboard.get_key()\nmy_keyboard.show_virtual_keyboard(False)\n~~~\n\n\n\n## synonyms(key)\n\nGives a list of synonyms for a key, either codes or names. Synonyms\ninclude all variables as types and as Unicode strings (if applicable).\n\n\n\n__Returns__\n\n- A list of synonyms\n\n\n## valid_keys()\n\nTries to guess which key names are accepted by the back-end. For\ninternal use.\n\n\n\n__Returns__\n\n- A list of valid key names.\n\n\n</div>\n\n",
    "title": "Keyboard functions",
    "url": "https://osdoc.cogsci.nl/4.1/manual/python/keyboard",
    "path": "content/pages/manual/python/keyboard.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Access experimental variables\n\ntitle: Access experimental variables\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `var` object does not need to be imported\n- Explain that there are two ways to refer to experimental variables:\n    - Preferred: as global variables: (`my_var = 10`)\n    - Non-preferred: as properties of the `var` object (`var.my_var = 10`)\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"ClassDoc YAMLDoc\" markdown=\"1\">\n\n# instance __var__\n\n__New in 4.0.0__: As of OpenSesame 4.0, all experimental variables are\nalso available in the Python workspace. This means that you therefore \ndon't need the `var` object anymore.\n\nThe `var` object provides access to experimental variables.\nExperimental variables are the variables that live in the GUI, and are\ncommonly set as independent variables in the LOOP item, referred\nto using\nthe square-bracket (`[my_variable]`) notation, and logged by\nthe LOGGER\nitem.\n\nA `var` object is created automatically when the experiment starts.\nIn addition to the functions listed below, the following semantics are\nsupported:\n\n__Example__:\n\n~~~ .python\n# Set an experimental variable\nvar.my_variable = u'my_value'\n# Get an experimental variable\nprint(u'Subject nr = %d' % var.subject_nr)\n# Delete (unset) an experimental\nvariable\ndel var.my_variable\n# Check if an experimental variable exists\nif\nu'my_variable' in var:\n    print(u'my_variable exists!')\n# Loop through all\nexperimental variables\nfor var_name in var:\n        print(u'variable found:\n%s' % var_name)\n~~~\n\n[TOC]\n\n## clear(preserve=[])\n\n*New in 3.1.2*\n\nClears all experimentals variables.\n\n__Parameters__\n\n- **preserve**: A list of variable names that shouldn't be cleared.\n\n__Example__\n\n~~~ .python\nvar.clear()\n~~~\n\n\n\n## get(var, default=None, _eval=True, valid=None)\n\nGets an experimental variable.\n\n\n__Parameters__\n\n- **var**: The variable to retrieve.\n- **default**: A default value in case the variable doesn't exist, or `None` for\nno default value.\n- **_eval**: Determines whether the returned should be evaluated for variable\nreferences.\n- **valid**: A list of valid values, or `None` to allow all values.\n\n__Example__\n\n~~~ .python\nprint('my_variable = %s' % var.get(u'my_variable'))\n# Equivalent to:\nprint('my_variable = %s' % var.my_variable)\n# But if you want to pass keyword arguments you need to use `get()`:\nvar.get(u'my_variable', default=u'a_default_value')\n~~~\n\n\n\n## has(var)\n\nChecks if an experimental variable exists.\n\n\n__Parameters__\n\n- **var**: The variable to check.\n\n__Example__\n\n~~~ .python\nif var.has(u'my_variable'):\n        print(u'my_variable has been defined!')\n# Equivalent to:\nif u'my_variable' in var:\n        print(u'my_variable has been defined!')\n~~~\n\n\n\n## inspect()\n\nGenerates a description of all experimental variables, both alive\nand hypothetical.\n\n\n\n__Returns__\n\n- A dict where variable names are keys, and values are dicts with\nsource, value, and alive keys.\n\n\n## items()\n\nReturns a list of (variable_name, value) tuples. See `var.vars()`\nfor a note about the non-exhaustiveness of this function.\n\n\n\n__Returns__\n\n- A list of (variable_name, value) tuples.\n\n__Example__\n\n~~~ .python\nfor varname, value in var.items():\n        print(varname, value)\n~~~\n\n\n\n## set(var, val)\n\nSets and experimental variable.\n\n\n__Parameters__\n\n- **var**: The variable to assign.\n- **val**: The value to assign.\n\n__Example__\n\n~~~ .python\nvar.set(u'my_variable', u'my_value')\n# Equivalent to\nvar.my_variable = u'my_value'\n~~~\n\n\n\n## unset(var)\n\nDeletes a variable.\n\n\n__Parameters__\n\n- **var**: The variable to delete.\n\n__Example__\n\n~~~ .python\nvar.unset(u'my_variable')\n# Equivalent to:\ndel var.my_variable\n~~~\n\n\n\n## vars()\n\nReturns a list of experimental variables. Because experimental\nvariables can be stored in multiple places, this list may not be\nexhaustive. That is, `u'my_var' in var` may return `True`, while\nu'my_var' is not in the list of variables as returned by this function.\n\n\n\n__Returns__\n\n- A list of variable names.\n\n__Example__\n\n~~~ .python\nfor varname in var.vars():\n        print(varname)\n~~~\n\n\n\n</div>\n\n",
    "title": "Access experimental variables",
    "url": "https://osdoc.cogsci.nl/4.1/manual/python/var",
    "path": "content/pages/manual/python/var.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# OpenSesame as a Python library (no GUI)\n\ntitle: OpenSesame as a Python library (no GUI)\n\nYou can also write experiments fully programmatically by using OpenSesame as a Python module. This is mainly suited for people who prefer coding over using a graphical user interface.\n\nUsing OpenSesame as a Python module works much the same way as using Python `inline_script` items in the user interface, with two notable exceptions:\n\n- Functions and classes need to be explicitly imported from `libopensesame.python_workspace_api`. All functions and classes described under [Common functions](%url:manual/python/common%) are available.\n- An `experiment` object needs to be explicitly created using the `Experiment()` factory function.\n\nA simple Hello World experiment looks like this:\n\n```python\nfrom libopensesame.python_workspace_api import \\\n  Experiment, Canvas, Keyboard, Text\n\n# Initialize the experiment window using the legacy backend\nexp, win, clock, log = Experiment(canvas_backend='legacy')\n# Prepare a stimulus canvas and a keyboard\ncnv = Canvas()\ncnv += Text('Hello world')\nkb = Keyboard()\n# Show the canvas, wait for a key press, and then end the experiment\ncnv.show()\nkb.get_key()\nexp.end()\n```\n\nYou can also programmatically open a `.osexp` experiment file and execute it:\n\n```python\nfrom libopensesame.python_workspace_api import Experiment\nexp, win, clock, log = Experiment(osexp_path='my_experiment.osexp',\n                                  subject_nr=2)\nexp.run()\n```",
    "title": "OpenSesame as a Python library (no GUI)",
    "url": "https://osdoc.cogsci.nl/4.1/manual/python/nogui",
    "path": "content/pages/manual/python/nogui.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Sound\n\ntitle: Sound\n\nThe most common way to play sound is using the SAMPLER item, for playback of audio files, or the SYNTH item, for playback of simple beeps, etc.\n\n[TOC]\n\n## The sampler\n\nThe SAMPLER plays back a single sound file, typically from the file pool.\n\nSound files are always played back at the sampling rate that is used by the OpenSesame sampler backend. If your sample appears to be sped up (high pitch) or slowed down (low pitch), you can adjust the sampling rate of your sound file in a sound editor, or change the sampling rate used by the OpenSesame sampler backend (under 'Show backend settings and info' in the General tab).\n\nThe SAMPLER has a few options:\n\n- *Sound file* indicates the file to be played.\n- *Volume* between 0 (silent) and 1 (normal volume).\n- *Pan* turns the right (negative values) or left (positive values) channel down. For full panning, enter 'left' or 'right',\n- *Pitch* indicates the playback speed, where 1 corresponds to the original speed.\n- *Stop after* indicates for how long the sound file should be played. For example, a value of 100 ms means that playback will be stopped after 100 ms, regardless of how long the sound file is. A value of 0 ms means that the sound file will be played back completely.\n- *Fade in* indicates the fade-in time for the sound file. For example, a value of 100 ms means that the sound file will start silent, and build up to maximum value in 100 ms.\n- *Duration* indicates the duration of the sampler item, before the next item is presented. This doesn't need to match the length of the sound file. For example, if the duration of the sampler is set to 0 ms, OpenSesame will advance directly to the item that follows the SAMPLER (e.g., a sketchpad), *while the sound file continues playing in the background*. In addition to a numeric value, you can set duration to:\n\t- 'keypress' to wait for a key press\n\t- 'mouseclick' to wait for a mouse click\n\t- 'sound' to wait until the sampler has finished playing.\n\n## The synth\n\nThe SYNTH is a basic sound synthesizer.\n\nYou can specify a\nnumber of options:\n\n- *Waveform* can be set to sine, sawtooth, square, or white noise\n- *Attack* is the time it takes for the sound the reach maximum volume (i.e. fade in).\n- *Decay* is the time it takes for the sound to die out (i.e. fade out). Note that the decay occurs within the length of the sound.\n- *Volume* between 0 and 100%\n- *Pan* turns the right (negative values) or left (positive values) channel down. Setting pan to -20 or 20 completely mutes the right or left channel, respectively.\n- *Length* indicates the length of the sound (in milliseconds).\n- *Duration* indicates the duration of the SYNTH item, before the next item is presented. This doesn't need to match the length of the sound. For example, the duration of the SYNTH may be set to 0ms, in order to advance directly to the next item (e.g., a SKETCHPAD), while the sound continues playing in the background. In addition to a numeric value, you can set the duration to 'keypress', to wait for a keyboard press, 'mouseclick', to wait for a mouse click, or 'sound', to wait until the SYNTH has finished playing.\n\n## Sound playback in Python\n\nYou can use the SAMPLER object and the SYNTH function to present visual stimuli in Python:\n\n- %link:sampler%\n- %link:manual/python/common%\n\n\n## Audio Low Latency plugins\n\nThe main goal of the Audio Low Latency plugins, developed by Bob Rosbag, is to play and record audio with minimal and predictable latencies to achieve a high accuracy and precision. The `PyAlsaAudio` package which uses the Linux ALSA audio system provided the best results within Python. `PortAudio` and `sounddevice` are cross-platform and work on both Windows as Linux.\n\nThe plugins are not installed by default, but can be installed through pip:\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nSee also:\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>",
    "title": "Sound",
    "url": "https://osdoc.cogsci.nl/4.1/manual/stimuli/sound",
    "path": "content/pages/manual/stimuli/sound.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Text\n\ntitle: Text\n\n[TOC]\n\n## How can I present text?\n\nThe most common way to show text is using a SKETCHPAD or FEEDBACK item. These allow you to enter text and other visual stimuli. For a questionnaire-like way to show text, you can use [forms](%link:manual/forms/about%).\n\n\n## HTML formatting\n\nYou can use a HTML tags, which you can simply insert into your text. You can use these tags everywhere: In SKETCHPAD items, in INLINE_SCRIPTs (provided you use the `Canvas` class), in forms, etc.\n\nExample:\n\n~~~ .html\nOpenSesame supports a sub-set of HTML tags:\n- <b>Bold face</b>\n- <i>Italic</i>\n- <u>Underline</u>\n\nIn addition, you can pass 'color', 'size', and 'style' as keywords to a 'span' tag:\n- <span style='color:red;'>Color</span>\n- <span style='font-size:32px;'>Font size</span>\n- <span style='font-family:serif;'>Font style</span>\n\nFinally, you can force newlines with the 'br' tag:\nLine 1<br>Line 2\n~~~\n\n\n## Variables and inline Python\n\nYou can embed variables in text using the `{...}` syntax. For example, the following:\n\n~~~ .python\nThe subject number is {subject_nr}\n~~~\n\n... might evaluate to (for subject 1):\n\n~~~ .python\nThe subject number is 1\n~~~\n\nYou can also embed Python expression. For example, the following:\n\n~~~ .python\nThe subject number modulo five is {subject_nr % 5}\n~~~\n\n... might evaluate to (for subject 7)\n\n~~~ .python\nThe subject number modulo five is 2\n~~~\n\n\n## Fonts\n\n### Default fonts\n\nYou can select one of the default fonts from the font-selection dialogs (%FigFontSelect). These fonts are included with OpenSesame and your experiment will therefore be fully portable when you use them.\n\n%--\nfigure:\n id: FigFontSelect\n source: font-selection-dialog.png\n caption: \"A number of default fonts, which are bundled with OpenSesame, can be selected through the font-selection dialogs.\"\n--%\n\nThe fonts have been renamed for clarity, but correspond to the following open-source fonts:\n\n|__Name in OpenSesame__\t\t|__Actual font__\t\t|\n|---------------------------|-----------------------|\n|`sans`\t\t\t\t\t\t|Droid Sans\t\t\t\t|\n|`serif`\t\t\t\t\t|Droid Serif\t\t\t|\n|`mono`\t\t\t\t\t\t|Droid Sans Mono\t\t|\n|`chinese-japanese-korean`\t|WenQuanYi Micro Hei\t|\n|`arabic`\t\t\t\t\t|Droid Arabic Naskh\t\t|\n|`hebrew`\t\t\t\t\t|Droid Sans Hebrew\t\t|\n|`hindi`\t\t\t\t\t|Lohit Hindi\t\t\t|\n\n### Selecting a custom font through the font-selection dialog\n\nIf you select 'other ...' in the font selection dialog, you can select any font that is available on your operating system. If you do this, your experiment is no longer fully portable, and will require that the selected font is installed on the system that you run your experiment on.\n\nThis is only works for OpenSesame on the desktop, not for online OSWeb experiments.\n\n\n### Placing a custom font in the file pool (OpenSesame desktop)\n\nWhen running your experiment on the desktop, another way to use a custom font is to put a font file in the file pool. For example, if you place the font file `inconsolata.ttf` in the file pool, you can use this font in a SKETCHPAD item, like so:\n\n\tdraw textline 0.0 0.0 \"This will be inconsolata\" font_family=\"inconsolata\"\n\nThe font file must be a truetype `.ttf` file. This is only works for OpenSesame on the desktop, not for online OSWeb experiments.\n\n\n### Using a custom font from Google Fonts (OSWeb)\n\nWhen running your experiment in a browser with OSWeb, you can use fonts from Google Fonts. To do so, simply edit the script of a text element and specify the name of the font under `font_family`:\n\n```\ndraw textline x=0 y=0 font_family=\"Jacquard 12 Charted\" text=\"This is shown in a funny font\"\n```\n\nThis is only works for online OSWeb experiments, not for OpenSesame on the desktop.",
    "title": "Text",
    "url": "https://osdoc.cogsci.nl/4.1/manual/stimuli/text",
    "path": "content/pages/manual/stimuli/text.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Visual stimuli\n\ntitle: Visual stimuli\n\nThe most common way to present visual stimuli is using the SKETCHPAD item, or, for non-time-critical stimuli, the FEEDBACK item.\n\n\n[TOC]\n\n\n## Using the sketchpad and feedback items\n\nThe SKETCHPAD and FEEDBACK item offer basic what-you-see-is-what-you get drawing tools (%FigSketchpad).\n\n%--\nfigure:\n id: FigSketchpad\n source: sketchpad.png\n caption: The SKETCHPAD provides built-in drawing tools.\n--%\n\n\n## Using show-if expressions\n\nYou can use show-if expressions to determine whether or not a particular element should be shown. For example, if you have an image of a happy face that should be shown only when the variable `valence` has the value 'positive', then you can set the show-if expression for the corresponding image element to:\n\n```python\nvalence == 'positive'\n```\n\nIf you leave a show-if expression empty or enter `True`, element will always be shown. Show-if expressions use the same syntax as other conditional expressions. For more information, see:\n\n- %link:manual/variables%\n\nShow-if expressions are evaluated at the moment that the display is prepared. This means that for SKETCHPAD items, they are evaluated during the prepare phase, whereas for FEEDBACK items, they are evaluated during the run phase (see also the section below).\n\n\n## The difference between sketchpad and feedback items\n\nThe SKETCHPAD and FEEDBACK items are identical in most ways, except for two important differences.\n\n\n### Sketchpad items are prepared in advance, feedback items are not\n\nThe contents of a SKETCHPAD are prepared during the prepare phase of the SEQUENCE that it is part of. This is necessary to ensure accurate timing: It allows the SKETCHPAD to be shown right away during the run phase, without any delays due to stimulus preparation. However, the downside of this is that the contents of a SKETCHPAD cannot depend on what happens during the SEQUENCE that it is part of. For example, you cannot use a SKETCHPAD to provide immediate feedback on the response time collected by a KEYBOARD_RESPONSE item (assuming that the SKETCHPAD and KEYBOARD_RESPONSE are part of the same sequence.)\n\nIn contrast, the contents of a FEEDBACK item are only prepared when they are actually shown, that is, during the run phase of the SEQUENCE that it is part of. This makes it possible to provide feedback on things that just happened--hence the name. However, the FEEDBACK item should not be used to present time-critical stimuli, because it suffers from delays due to stimulus preparation.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Feedback variables are (by default) reset by feedback items\n\nThe FEEDBACK item has an option 'Reset feedback variables'. When this option is enabled (it is by default), feedback variables are reset when the FEEDBACK item is shown.\n\nFor more information about feedback variables, see:\n\n- %link:manual/variables%\n\n\n## Presenting visual stimuli in Python inline script\n\n### Accessing a SKETCHPAD in Python\n\nYou can access the `Canvas` object for a SKETCHPAD as the items `canvas` property. For example, say that your SKETCHPAD is called *my_sketchpad*, and contains an image elements with the name 'my_image'. You could then have this image rotate with the following script:\n\n~~~ .python\nmy_canvas = items['my_sketchpad'].canvas\nfor angle in range(360):\n\tmy_canvas['my_image'].rotation = angle\n\tmy_canvas.show()\n~~~\n\n\n### Creating a Canvas in Python\n\nYou can use the `Canvas` object to present visual stimuli in Python:\n\n- %link:manual/python/canvas%",
    "title": "Visual stimuli",
    "url": "https://osdoc.cogsci.nl/4.1/manual/stimuli/visual",
    "path": "content/pages/manual/stimuli/visual.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Intermediate tutorial (JavaScript): visual search\n\ntitle: Intermediate tutorial (JavaScript): visual search\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a user-friendly program for the development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface. For advanced users, OpenSesame supports Python (desktop only) and JavaScript (desktop and browser).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a basic visual-search experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012)][references]. We will use both the graphical interface and JavaScript to develop an experiment that you can run online in a browser. Some experience with OpenSesame and JavaScript is recommended. This tutorial takes approximately one hour.\n\nA Python-based version of this tutorial is also available. If you don't need to run your experiments online, then the Python tutorial is likely what you need:\n\n- %link:tutorials/intermediate%\n\n\n## Resources\n\n- __Download__ \u2014 This tutorial assumes that you are running OpenSesame version 4.0.0 or later and OSWeb 2.0 or later. You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ \u2014 A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ \u2014 A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n- __Sigmund__ -- SigmundAI is an AI assistant with expert knowledge of OpenSesame and can be found at:\n\t- <https://sigmundai.eu/>\n\n\n## The experiment\n\nIn this tutorial, you will create a basic visual-search experiment. The experiment resembles the classic visual-search studies of [Treisman and Gelade (1980)][references], but it is not identical.\n\nBefore starting to *build* the experiment for yourself, you can already *participate* in it. This will give you a good idea of what you're working towards in this tutorial.\n\n<a role=\"button\" class=\"btn btn-success btn-align-left\" href=\"https://jatos.mindprobe.eu/publix/1938/start?batchId=2191&generalMultiple\">Participate in the experiment!</a>\n\nIn this experiment, participants search for a target object, which can be a yellow square, a yellow circle, a blue square, or a blue circle; the identity of the target is varied between blocks of trials. Participants indicate whether the target is present or not by pressing the right (present) or left (absent) arrow key.\n\nIn addition to the target, zero or more distractor objects are shown. There are three conditions, and the condition determines what kind of distractors there are:\n\n- In the *Conjunction* condition, distractors can have any shape and color, with the only restriction that distractors cannot be identical to the target. So, for example, if the target is a yellow square, then distractors are yellow circles, blue circles, and blue squares.\n- In the *Shape Feature* condition, distractors have a different shape from the target, but can have any color. So, for example, if the target is a yellow square, then distractors are yellow circles and blue circles.\n- In the *Color Feature* condition, distractors can have any shape, but have a different color from the target. So, for example, if the target is a yellow square, then distractors are blue squares and blue circles.\n\nImmediate feedback is shown after each trial: a green dot after a correct response, and a red dot after an incorrect response. Detailed feedback on average response times and accuracy is shown after each block of trials.\n\n%--\nfigure:\n id: FigVisualSearch\n source: visual-search.svg\n caption: |\n  The visual-search experiment that you will implement in this tutorial.\n--%\n\nExperiments like this show two typical findings:\n\n- It takes more time to find the target in the Conjunction condition than in the two Feature conditions.\n- In the Conjunction condition, response times increase as the number of distractors increases. This suggests that people search for the target one item at a time; this is called *serial search*.\n- In the Feature conditions (both shape and color), response times do not, or hardly, increase as the the number of distractors increases. This suggests that people process the entire display at once; this is called *parallel search*.\n\nAccording to Treisman and Gelade's feature-integration theory, these results reflect that the Conjunction condition requires that you combine, or *bind*, the color and shape of each object. This binding requires attention, and you therefore need to shift your attention from one object to the next; this is slow, and explains why response times depend on how many objects there are. In contrast, in the Feature conditions, color and shape do not need to be bound, and therefore the whole display can be processed in a single sweep without attention being directed at each and every object.\n\n## Experimental design\n\nThis design:\n\n- Is *within-subject*, because all participants do all conditions\n- Is *fully-crossed* (or full factorial), because all combinations of conditions occur\n- Has three conditions (or factors):\n\t- Varied within blocks:\n\t\t- `set_size` with three levels (1, 5, 15), or SS<sub>3</sub>\n\t\t- `condition` with three levels (conjunction, feature_shape, feature_color), or CN<sub>3</sub>\n\t\t- `target_present` with two levels (present, absent), or TP<sub>2</sub>\n\t- Varied between blocks:\n\t\t- `target_shape` with two levels (square, circle), or TS<sub>2</sub>\n\t\t- `target_color` with two levels (yellow, blue), or TC<sub>2</sub>\n- Has N subjects, or <u>S</u><sub>N</sub>\n\nYou can write this design as <u>S</u><sub>N</sub>\u00d7SS<sub>3</sub>\u00d7CN<sub>3</sub>\u00d7TP<sub>2</sub>\u00d7TS<sub>2</sub>\u00d7TC<sub>2</sub>\n\nFor more information about this notation for experimental design, see:\n\n- %link:experimentaldesign%\n\n## Step 1: Create the basic structure of the experiment\n\nStart OpenSesame and, in the 'Get started!' tab, select the Extended template. This template provides the basic structure that is common to many cognitive-psychology experiments, such as the one that we will create here.\n\nThe Extended template contains a few items that we don't need. Delete the following items:\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nWhen you have deleted these items, they are still visible in the 'Unused items' bin. To permanently delete these items, click on the 'Unused items' bin, and then click on the 'Permanently delete unused items' button.\n\nFinally, give the experiment a good title, such as 'Visual search'. To do this, open the general-properties tab (by clicking on 'Extended template' in the overview area) and click on the experiment name to edit it.\n\nAlso configure OpenSesame to run the experiment in a browser, rather than on the desktop.\n\nThe overview area should now look like %FigStep1:\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of step 1.\n--%\n\n\n## Step 2: Define experimental variables that are varied between blocks\n\nAs described above, two variables are varied between blocks in our experiment: `target_shape` and `target_color`. We therefore need to define these variables in the *experimental_loop*. To understand why, consider the structure shown in %FigStep1, starting from the bottom (i.e. the most indented level).\n\n- *trial_sequence* corresponds to a single trial\n- *block_loop* corresponds to a block of a trials\n\t- Therefore, variables defined here vary for each run of *trial_sequence*; in other words, variables defined in *block_loop* are varied __within blocks__.\n- *block_sequence* corresponds to a block of trials, preceded by resetting of the feedback variables, and followed by participant feedback\n- *experimental_loop* corresponds to multiple blocks of trials\n\t- Therefore, variables defined here vary for each run of *block_sequence*; in other words, variables defined in *experimental_loop* are varied __between blocks__.\n- *experiment* corresponds to the entire experimental, which is an instruction screen, followed by multiple blocks of trials, followed by an end-of-experiment screen\n\nClick on experimental loop, and define:\n\n- `target_shape`, which can be 'square' or 'circle'; and\n- `target_color`, which can be 'yellow' or 'blue'.\n\nWe have a full-factorial design, which means that all 2 \u00d7 2 = 4 combinations must occur. The table of *experimental_loop* should now look like %FigStep2:\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The table of *experimental_loop* at the end of step 2.\n--%\n\n## Step 3: Give instructions at the start of each block\n\nRight now, the experiment starts with a single *instructions* screen. In our case, we want to give instructions before each block of trials, to tell the participant what target to look for (because the identity of the target varies between blocks).\n\n__Move the instructions into block_sequence__\n\nTherefore, pick up the *instructions* item and drag it onto *block_sequence*. A pop-up will appear, asking you if you want to:\n\n- Insert the item into *block_sequence*, in which case *instructions* would become the first item of *block_sequence*; or\n- Insert the item after *block_sequence*, in which case *instructions* would move to a position after *block_sequence*.\n\nSelect the first option ('Insert into'). Now *block_sequence* starts with an instructions screen, which is what we want.\n\n__Add instructional text__\n\nClick on *instructions* to open it, and add a good instructional text, such as:\n\n```text\nINSTRUCTIONS\n\nSearch for the {target_color} {target_shape}\n\nPress the right-arrow key if you find it\nPress the left-arrow key if you don't\n\nPress any key to begin\n```\n\nThe curly braces brackets around '{target_color}' and '{target_shape}' indicate that these are not literal text, but refer to the variables that we have defined in *experimental_loop*. When the experiment runs, the values of these variables will appear here, and the participant will see (for example), 'Search for the yellow circle'.\n\n__Give a visual preview of the target__\n\nIt also good to show the participant the actual stimulus that she needs to find. To do this:\n\n- Draw a filled circle at the center of the display (make sure it doesn't overlap with the text);\n- Change the color of the circle to '{target_color}'. This means that the color of the circle depends on the value of the variable `target_color`; and\n- Change the show-if expression to `target_shape == 'circle'`. This is a Python expression that checks if the variable `target_shape` has the value 'circle'. Note that even though you *cannot* use full-fledged Python `inline_script` items when running experiments in a browser, you *can* use Python for these simple conditional expressions.\n\nIn other words, we have drawn a circle of which the color is determined by `target_color`; furthermore, this circle is only shown when the variable `target_shape` has the value 'circle'. For more information about variables and show-if statements, see:\n\n- %link:manual/variables%\n\nWe use the same trick to draw a square:\n\n- Draw a filled square at the center of the display;\n- Change the color of the square to '{target_color}'; and\n- Change the show-if statement to `target_shape == 'square'`\n\nThe *instructions*  screen should now look like %FigStep3:\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\n\n## Step 4: Define experimental variables that are varied within blocks\n\nThree variables are varied within blocks in our experiment: `condition`, `set_size`, and `target_present`. As described under Step 2, we need to define these variables in the *block_loop* so that they vary for each run of *trial_sequence*.\n\nThe three variables make a total of 3 \u00d7 3 \u00d7 2 = 18 different combinations. We can type these into the table manually, but, because we have full-factorial design, we can also use the full-factorial-design wizard. To do this, first open *block_loop* and click on the 'Full-factorial design' button.\n\nIn the table that appears, put the variable names on the first row, and the values on the rows below, as shown in %FigFullFactorial.\n\n%--\nfigure:\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\nNow click on 'Ok' to generate the full design. The table of *block_loop* should now look like %FigStep4.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The table of *block_loop* at the end of step 4.\n--%\n\n## Step 5: Create the trial sequence and add an initialization script\n\nWe want our trial sequence to look as follows:\n\n- A fixation dot, for which we will use a SKETCHPAD.\n- A search display, which we will create in JavaScript with a custom INLINE_JAVASCRIPT.\n- Response collection, for which we will use a KEYBOARD_RESPONSE.\n- Data logging, for which we will use a LOGGER.\n- (We also want immediate feedback after each trial, but we will get back to this later.)\n\nSo the only thing that is missing from *trial_sequence* is an INLINE_JAVASCRIPT.\n\n- Insert a new INLINE_JAVASCRIPT after *sketchpad* and rename it to *search_display_script*.\n- Rename *sketchpad* to *fixation_dot*, so that its function is clear; and\n- Change the duration of *fixation_dot* to 500, so that the fixation dot is shown for 500 ms. (There should already be a fixation dot drawn; if not, draw one in the center of *fixation_dot*.)\n\nWe also need to add a initialization script to start of the experiment. We will use this only to define (`let`) a variable that will hold the `Canvas` object on which we will draw. In JavaScript, you have to define a variable exactly once, which is why we cannot do that in the *trial_sequence*.\n\n- Insert a new INLINE_JAVASCRIPT at the top of the *experiment* sequence and rename it to *init*.\n\nThe overview area should now look like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The overview area at the end of step 5.\n--%\n\n## Step 6: Generate the search display\n\n__Top-down and defensive programming__\n\nNow things will get interesting: We will start programming in JavaScript. We will use two guiding principles: *top-down* and *defensive* programming.\n\n- *Top-down programming* means that we start with the most abstract logic, without bothering with how this logic is implemented. Once the most abstract logic is in place, we will move down to a slightly less abstract logic, and so on, until we arrive at the details of the implementation. This technique helps to keep the code structured.\n- *Defensive programming* means that we assume that we make mistakes. Therefore, to protect us from ourselves, we build sanity checks into the code.\n\n*Note:* The explanation below assumes that you're somewhat familiar with JavaScript. If concepts like `Array`, `for` loop, and functions don't mean anything to you, then it's best to first walk through an introductory JavaScript tutorial. You can find links to JavaScript tutorials here:\n\n- %link:manual/javascript/about%\n\nThe logic of the code is shown in %FigHierarchy. The numbers indicate the order in which we will implement the functionality, starting at the abstract level.\n\n%--\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  The logic of the code to draw a visual-search display.\n--%\n\n__Declaring variables with let, var, and const__\n\nIn JavaScript, you have to 'declare' a variable before you can use it. (In Python, this is not necessary.) In our case, we will use a variable called `c`, which we therefore need to declare. To do so, open the Prepare tab of the *init* script and use the `let` keyword to declare the variable `c`:\n\n```js\nlet c\n```\n\nThere are three different ways to declare variables:\n\n- Using `let`, as we've done here. In OpenSesame, this makes the variable available in JavaScript but not as an experimental variable in the user interface.\n- Using `var`. In OpenSesame, this makes the variable also available as an experimental variable in the user interface. (We will do that later for the variable `correct_response`.)\n- Using `const`. This is like `var` with the important difference that the variable cannot be re-assigned later.\n\n\n__The Prepare and Run phases__\n\nOpen *search_display_script* and switch to the Prepare tab. OpenSesame distinguishes two phases of execution:\n\n- During the Prepare phase, each item is given the opportunity to prepare itself; what this means depends on the item: For a SKETCHPAD, it means drawing a canvas (but not showing it); for a SAMPLER, it means loading a sound file (but not playing it); etc.\n- During the Run phase, each item is actually executed; again, what this means depends on the item: For a SKETCHPAD, it means showing the previously prepared canvas; for a SAMPLER, it means playing a previously loaded sound file.\n\nFor an INLINE_JAVASCRIPT, you have to decide yourself what to put in the Prepare phase, and what to put in the Run phase. The distinction is usually quite clear: In our case, we put the code for drawing the canvas in the Prepare phase, and the code for showing the canvas (which is small) in the Run phase.\n\nSee also:\n\n- %link:prepare-run%\n\n\n__Implement the abstract level__\n\nWe start at the most abstract level: defining a function that draws a visual-search display. We don't specify *how* this is done; we simply assume that there is a function that does this, and we will worry about the details later\u2014that's top-down programming.\n\nIn the Prepare tab, enter the following code:\n\n```js\nc = draw_canvas()\n```\n\nWhat happens here? We \u2026\n\n- Call `draw_canvas()`, which returns a `Canvas` object that we store as `c`; in other words, `c` is a `Canvas` object that corresponds the search display. This assumes that there is a function `draw_canvas()`, even though we haven't defined it yet.\n\nA `Canvas` object is a single display; it is, in a sense, the JavaScript counterpart of a SKETCHPAD. See also:\n\n- %link:manual/javascript/canvas%\n\nWe now go one step down by defining `draw_canvas()` (above the rest of the script so far):\n\n```js\n/**\n * Draws the search canvas.\n * @return A Canvas\n **/\nfunction draw_canvas() {\n    let c = Canvas()\n    let xy_list = xy_random(set_size, 500, 500, 75)\n    if (target_present === 'present') {\n        let [x, y] = xy_list.pop()\n        draw_target(c, x, y)\n    } else if (target_present !== 'absent') {\n        throw 'Invalid value for target_present ' + target_present\n    }\n    for (let [x, y] of xy_list) {\n        draw_distractor(c, x, y)\n    }\n    return c\n}\n```\n\n\nWhat happens here? We \u2026\n\n- Create an empty canvas, `c`, using the factory function `Canvas()`.\n- Generate an array of random `x, y` coordinates, called `xy_list`, using another common function, `xy_random()`. This array determines where the stimuli are shown. Locations are sampled from a 500 \u00d7 500 px area with a minimum spacing of 75 px.\n- Check if the experimental variable `target_present` has the value 'present'; if so, `pop()` one `x, y` tuple from `xy_list`, and draw the target at this location. This assumes that there is a function `draw_target()`, even though we haven't defined it yet.\n- If `target_present` is neither 'present' nor 'absent', we `throw` an error; this is defensive programming, and protects us from typos (e.g. if we had accidentally entered 'presenr' instead of 'present').\n- Loop through all remaining `x, y` values and draw a distractor at each position. This assumes that there is a function `draw_distractor()`, even though we haven't defined it yet.\n- Return `c`, which now has the search display drawn onto it.\n\nThere are several common functions, such as `Canvas()` and `xy_random()`, which are always available in an INLINE_JAVASCRIPT item. See:\n\n- %link:manual/javascript/common%\n\nExperimental variables are global variables. That's why you can refer to `set_size`, which is defined in *block_loop*, even though the variable `set_size` is never explicitly defined in the script. The same is true for `target_shape`, `target_color`, `condition`, etc. See:\n\n- %link:var%\n\n\n__Implement the intermediate level__\n\nWe now go one more step down by defining `draw_target` (above the rest of the script so far):\n\n```js\n/**\n * Draws the target.\n * @param c A Canvas\n * @param x An x coordinate\n * @param y A y coordinate\n **/\nfunction draw_target(c, x, y) {\n    draw_shape(c, x, y, target_color, target_shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Call another function, `draw_shape()`, and specify the color and shape that needs to be drawn. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nWe also define `draw_distractor` (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor.\n * @param c A Canvas\n * @param x An x coordinate\n * @param y A y coordinate\n **/\nfunction draw_distractor(c, x, y) {\n    if (condition === 'conjunction') {\n        draw_conjunction_distractor(c, x, y)\n    } else if (condition === 'feature_shape') {\n        draw_feature_shape_distractor(c, x, y)\n    } else if (condition === 'feature_color') {\n        draw_feature_color_distractor(c, x, y)\n    } else {\n        throw 'Invalid condition: ' + condition\n    }\n}\n```\n\nWhat happens here? We \u2026\n\n- Call another function to draw a more specific distractor depending on the Condition.\n- Check whether `condition` has any of the expected values. If not, we `throw` an error. This is defensive programming! Without this check, if we made a typo somewhere, the distractor might simply not be shown without causing an error message.\n\nNow we define the function that draws distractors in the Conjunction condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the conjunction condition: an object that\n * can have any shape and color, but cannot be identical to the target.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_conjunction_distractor(c, x, y) {\n    let conjunctions = [\n        ['yellow', 'circle'],\n        ['blue', 'circle'],\n        ['yellow', 'square'],\n        ['blue', 'square']\n    ]\n    let [color, shape] = random.pick(conjunctions)\n    while (color === target_color && shape === target_shape) {\n        [color, shape] = random.pick(conjunctions)\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Define a list, `conjunctions`, of all possible color and shape combinations.\n- Randomly select one of the color and shape combinations from `conjunctions`.\n- Check if the selected color and shape are both equal to the color and shape of the target. If so, keep selecting a new color and shape until this is no longer the case. After all, the distractor cannot be identical to the target!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nIn addition, we \u2026\n\n- Use the `random` library, which is corresponds to the `random-ext` package. This library contains useful randomization functions (such as `random.pick()`) and is one of the non-standard JavaScript libraries that is included with OSWeb.\n\nNow we define the function that draws distractors in the Shape Feature condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the feature-shape condition: an object that\n * has a different shape from the target, but can have any color.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_feature_shape_distractor(c, x, y) {\n    let colors = ['yellow', 'blue']\n    let color = random.pick(colors)\n    let shape\n    if (target_shape === 'circle') {\n        shape = 'square'\n    } else if (target_shape === 'square') {\n        shape = 'circle'\n    } else {\n        throw 'Invalid target_shape: ' + target_shape\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Randomly select a color.\n- Choose a square shape if the target is a circle, and a circle shape if the target is square.\n- If `target_shape` is neither 'circle' nor 'square', `throw` an error\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nNow we define the function that draws distractors in the Color Feature condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the feature-color condition: an object that\n * has a different color from the target, but can have any shape.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_feature_color_distractor(c, x, y) {\n    let shapes = ['circle', 'square']\n    let shape = random.pick(shapes)\n    let color\n    if (target_color === 'yellow') {\n        color = 'blue'\n    } else if (target_color === 'blue') {\n        color = 'yellow'\n    } else {\n        throw 'Invalid target_color: ' + target_color\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Randomly select a shape.\n- Choose a blue color if the target is yellow, and a yellow color if the target is blue.\n- If `target_color` is neither 'yellow' nor 'blue', `throw` and error\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\n__Implement the detailed level__\n\nNow we go all the way down to the details by defining the function that actually draws a shape to the canvas (above the rest of the script so far):\n\n```js\n/**\n * Draws a single shape.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n * @param color A color (yellow or blue)\n * @param shape A shape (square or circle)\n **/\nfunction draw_shape(c, x, y, color, shape) {\n    if (shape === 'square') {\n        // Parameters are passed as an Object!\n        c.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n    } else if (shape === 'circle') {\n        // Parameters are passed as an Object!\n        c.circle({x:x, y:y, r:25, color:color, fill:true})\n    } else {\n        throw 'Invalid shape: ' + shape\n    }\n    if (color !== 'yellow' && color !== 'blue') {\n        throw 'Invalid color: ' + color\n    }\n}\n```\n\nWhat happens here? We \u2026\n\n- Check which shape should be drawn. For squares, we add a `rect()` element to the canvas. For circles, we add a `circle()` element.\n- Check if the the shape is either a square or a circle, and if not `throw` and error. This is another example of defensive programming! We're making sure that we haven't accidentally specified an invalid shape.\n- Check if the the color is neither yellow nor blue, and if not `throw` and error.\n\nImportantly, `Canvas` functions accept a single object (`{}`) that specifies all parameters by name, like so:\n\n```js\n// Correct: pass a single object that contains all parameters by name\nc.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n// Incorrect: do not pass parameters by order\n// c.rect(x-25, y-25, 50, 50, color, true)\n// Incorrect: named parameters are not supported in JavaScript\n// c.rect(x=x-25, y=y-25, w=50, h=50, color=color, fill=true)\n```\n\n__Implement the Run phase__\n\nBecause we have done all the hard work in the Prepare phase, the Run phase is just:\n\n```js\nc.show()\n```\n\nThat's it! Now you have drawn a full visual-search display. And, importantly, you have done so in a way that is easy to understand, because of top-down programming, and safe, because of defensive programming.\n\n\n## Step 7: Define the correct response\n\nTo know if the participant responds correctly, we need to know the correct response. You can define this explicitly in the *block_loop* (as done in the beginner tutorial); but here we're going to use some simple JavaScript that checks whether the target is present or not, and defines the correct response accordingly.\n\nTo do this, we first need to declare the variable in the Prepare tab of the *init* script, just below `let c`. This time, we use the `var` keyword to declare `correct_response`, because this makes the variable available in the user interface (whereas `let` does not do this):\n\n```js\nvar correct_response\n```\n\nNext, insert a new INLINE_JAVASCRIPT at the start of *trial_sequence*, and rename it to *correct_response_script*. In the Prepare phase, enter the following code:\n\n```js\nif (target_present === 'present') {\n    correct_response = 'right'\n} else if (vars.target_present === 'absent') {\n    correct_response = 'left'\n} else {\n    throw 'target_present should be absent or present, not ' + target\n}\n```\n\nWhat happens here? We \u2026\n\n- Check whether the target is present or not. If the target is present, the correct response is 'right' (the right arrow key); if the target is absent, the correct response is 'left' (the left arrow key). The experimental variable `correct_response` is automatically used by OpenSesame; therefore, we don't need to explicitly indicate that this variable contains the correct response.\n- Check if the target is either present or absent, and if not `throw` an error\u2014another example of defensive programming.\n\n## Step 8: Give per-trial feedback\n\nFeedback after every trial can motivate participants; however, per-trial feedback should not interfere with the flow of the experiment. A good way to give per-trial feedback is to briefly show a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nTo do this:\n\n- Insert two new SKETCHPADs into *trial_sequence*, just after *keyboard_response*.\n- Rename one SKETCHPAD to *green_dot*, draw a central green fixation dot onto it, and change its duration to 500.\n- Rename the other SKETCHPAD to *red_dot*, draw a central red fixation dot onto it, and change its duration to 500.\n\nOf course, only one of the two dots should be shown on each trial. To accomplish this, we will specify run-if statements in *trial_sequence*:\n\n- Change the run-if statement for *green_dot* to 'correct == 1', indicating that it should only be shown after a correct response.\n- Change the run-if statement for *red_dot* to 'correct == 0', indicating that it should only be shown after an incorrect response.\n\nThe variable `correct` is automatically created if the variable `correct_response` is available; that's why we defined `correct_response` in step 7. For more information about variables and run-if statements, see:\n\n- %link:manual/variables%\n\nThe *trial_sequence* should now look like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n--%\n\n\n## Finished!\n\nCongratulations, the experiment is complete! You can give it a test run by pressing on the toolbar button that shows a green circle with a gray play button inside (shortcut: `Alt+Ctrl+W`).\n\nIf the experiment doesn't work on the first try: Don't worry, and calmly figure out where the mistake comes from. Crashes are part of the normal development process. But you can save yourself a lot of time and headache by working in a structured way, as we have done in this tutorial.\n\n## References\n\n<div class='reference' markdown='1'>\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, 12(1), 97\u2013136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html",
    "title": "Intermediate tutorial (JavaScript): visual search",
    "url": "https://osdoc.cogsci.nl/4.1/tutorials/intermediate-javascript",
    "path": "content/pages/tutorials/intermediate-javascript.md",
    "topics": [
      "opensesame",
      "inline_javascript"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Beginner tutorial: gaze cuing\n\ntitle: Beginner tutorial: gaze cuing\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a program for easy of development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface. For advanced users, OpenSesame supports Python scripting (not covered in this tutorial).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a simple but complete psychological experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012; Math\u00f4t & March, 2022)][references]. You will use mainly the graphical user interface of OpenSesame (i.e., no Python inline coding), although you will make small modifications to the OpenSesame script. This tutorial takes approximately one hour.\n\n## Resources\n\n- __Download__ -- This tutorial assumes that you are running OpenSesame version 4.0.0 or later. To check which version you are running, see the bottom right of the 'Get started' tab (see %FigGetStarted). You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ -- A dedicated documentation website can be found at:\n\t- <https://osdoc.cogsci.nl/>\n- __Forum__ -- A support forum can be found at:\n\t- <https://forum.cogsci.nl/>\n- __Sigmund__ -- SigmundAI is an AI assistant with expert knowledge of OpenSesame and can be found at:\n\t- <https://sigmundai.eu/>\n\n## The experiment\n\nIn this tutorial, you will create a gaze-cuing experiment as introduced by [Friesen and Kingstone (1998)][references]. In this experiment, a face is presented in the center of the screen (%FigGazeCuing). This face looks either to the right or to the left. A target letter (an 'F' or an 'H') is presented to the left or right of the face. A distractor stimulus (the letter 'X') is presented on the other side of the face. The task is to indicate as quickly as possible whether the target letter is an 'F' or an 'H'. In the congruent condition, the face looks at the target. In the incongruent condition, the face looks at the distractor. As you may have guessed, the typical finding is that participant respond faster in the congruent condition than in the incongruent condition, even though the direction of gaze is not predictive of the target location. This shows that our attention is automatically guided by other people's gaze, even in situations where this doesn't serve any purpose. (And even when the face is just a smiley!)\n\n%--\nfigure:\n id: FigGazeCuing\n source: gaze-cuing.png\n caption: |\n  The gaze-cuing paradigm [(Friesen and Kingstone, 1998)][references] that you will implement in this tutorial. This example depicts a trial in the incongruent condition, because the smiley looks at the distractor ('X') and not at the target ('F').\n--%\n\nThe experiment consists of a practice and an experimental phase. Visual feedback will be presented after every block of trials. A sound will be played after every incorrect response.\n\n## Experimental design\n\nThis design:\n\n- is *within-subject*, because all participants do all conditions\n- is *fully crossed* (or full-factorial), because all combinations of conditions occur\n- has three factors (or factors):\n    - *gaze side* with two levels (left, right)\n    - *target side* with two levels (left, right)\n    - *target letter* with two levels (F, H)\n- has N subjects\n\n\nSee also %DesignScreencast for an explanation of the logic and design of the experiment:\n\n\n%--\nvideo:\n source: youtube\n id: DesignScreencast\n videoid: aWvibRH6D4E\n width: 640\n height: 360\n caption: |\n  An explanation of the experimental logic and design.\n--%\n\n\n## Step 1: Create the main sequence\n\nWhen you start OpenSesame, you see the 'Get started!' tab (%FigGetStarted). A list of templates is shown below 'Start a new experiment'. These templates provide convenient starting points for new experiments. After you saved an experiment the first time, recently opened experiments are shown under 'Continue with a recent experiment'. At the bottom of the page there are links to the documentation (which includes this tutorial), the community forum, and a page with professional (paid) support options. And of course a link where you can buy us a cup of coffee to help us stay awake while we are working on providing the best free software!\n\n%--\nfigure:\n id: FigGetStarted\n source: get-started.png\n caption: |\n  The 'Get started' dialog on OpenSesame start-up.\n--%\n\nClick on 'Default template' to start with a minimal experimental template.\n\nBy default there is a main SEQUENCE, which is simply called *experiment*. Click on *experiment* in the overview area (by default on the left side, see %FigInterface) to open its controls in the tab area. The *experiment* SEQUENCE consists of two items: a `notepad` called *getting started* and a SKETCHPAD called *welcome*.\n\nWe don't need these two items. Remove *getting_started* by right-clicking on it in the overview area and selecting 'Delete' (shortcut: `Del`). Remove *welcome* in the same way. The *experiment* SEQUENCE is now empty.\n\n%--\nfigure:\n id: FigInterface\n source: interface.png\n caption: \"The default layout of the OpenSesame interface.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Names vs types__ -- Items in OpenSesame have a name and a type. The name and type can be the same, but they are usually not. For example, a SKETCHPAD item can have the name *my_target_sketchpad*. To make this distinction clear, we will use `monospace` to indicate item types, and *italics* to indicate names.\n\n__Tip__ -- The 'Extended template' is a good starting point for many experiments. It already contains the basic structure of a trial-based experiment.\n\n__Tip__ -- You can click on the Help icons in the top right of an item's tab to get context-sensitive help.\n\n__Tip__ -- Save (shortcut: `Ctrl+S`) your experiment often! In the unfortunate (and unlikely) event of data loss, you will often be able to recover your work from the back-ups that are created automatically, by default, every 10 minutes (Menu \u2192 Tools \u2192 Open backup folder).\n\n__Tip__ -- Unless you have used 'Permanently delete' (shortcut: `Shift+Del`), deleted items are still available in the 'Unused items' bin, until you select 'Permanently delete unused items' in the 'Unused items' tab. You can re-add deleted items to a SEQUENCE by dragging them out of the 'Unused items' bin to somewhere in your experiment.\n\n__Tip__ -- %FigExperimentStructure schematically shows the structure of the experiment that you will create. If you get confused during the tutorial, you can refer to %FigExperimentStructure to see where you are.\n\n%--\nfigure:\n id: FigExperimentStructure\n source: experiment-structure.png\n caption: |\n  A schematic representation of the structure of the 'Gaze cuing' experiment. The item types are in bold face, item names in regular face.\n--%\n\n</div>\n\n__Append a form_text_display item for the instruction display__\n\nAs the name suggests, a `form_text_display` is a form that displays text. We are going to use a `form_text_display` to give instructions to the participant at the beginning of the experiment.\n\nClick on *experiment* in the overview area to open its controls in the tab area. You will see an empty SEQUENCE. Drag a `form_text_display` from the item toolbar (under 'Form', see %FigInterface) onto the *experiment* SEQUENCE in the tab area. When you let go, a new `form_text_display` item will be inserted into the SEQUENCE. (We will get back to this in Step 12.)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can drag items into the overview area and into SEQUENCE tabs.\n\n__Tip__ -- If a drop action is ambiguous, a pop-up menu will ask you what you want to do.\n\n__Tip__ -- A `form_text_display` only shows text. If you require images etc., you can use a SKETCHPAD item. We will meet the SKETCHPAD in Step 5.\n\n</div>\n\n__Append a loop item, containing a new sequence item, for the practice phase__\n\nWe need to append a LOOP item to the *experiment* SEQUENCE. We will use this LOOP for the practice phase of the experiment. Click on the *experiment* SEQUENCE to open its controls in the tab area.\n\nDrag the LOOP item from the item toolbar into the SEQUENCE just the way you added the `form_text_display`. New items are inserted below the item that they are dropped on, so if you drop the new LOOP onto the previously created `form_text_display`, it will appear where you want it: after the `form_text_display`. But don't worry if you drop a new item in the wrong place, because you can always re-order things later.\n\nBy itself, a LOOP does not do anything. A LOOP always needs another item to run. Therefore, you have to fill the new LOOP item with another item. (If you view the loop item, you will also see a warning: 'No item selected'.) Drag a SEQUENCE item from the item toolbar onto the LOOP item. A pop-up menu will appear, asking you whether you want to insert the SEQUENCE after or into the LOOP item. Select 'Insert into new_loop'. (We will get back to this in Step 2.)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a LOOP item?__ -- A LOOP is an item that adds structure to your experiment. It repeatedly runs another item, typically a SEQUENCE. A LOOP is also the place where you will usually define your independent variables, that is, those variables that you manipulate in your experiment.\n\n__What is a SEQUENCE item?__ -- A SEQUENCE item also adds structure to your experiment. As the name suggests, a SEQUENCE runs multiple other items one after another.\n\n__The LOOP-SEQUENCE structure__ -- You often want to repeat a sequence of events. To do this, you will need a LOOP item that contains a SEQUENCE item. By itself, a SEQUENCE does not repeat. It simply starts with the first item and ends with the last item. By 'wrapping' a LOOP item around the SEQUENCE, you can repeat the SEQUENCE multiple times. For example, a single trial usually corresponds to a single SEQUENCE called *trial_sequence*. A LOOP (often called *block_loop*) around this *trial_sequence* would then constitute a single block of trials. Similarly, but at another level of the experiment, a SEQUENCE (often called *block_sequence*) may contain a single block of trials, followed by a FEEDBACK display. A *practice_phase* LOOP around this 'block' SEQUENCE would then constitute the practice phase of the experiment. This may seem a bit abstract right now, but as you follow this tutorial, you will become familiar with the use of LOOPs and SEQUENCEs.\n\n__Tip__ -- For more information about SEQUENCEs and LOOPs, see:\n\n- %link:loop%\n- %link:sequence%\n\n</div>\n\n__Append a new form_text_display item for the end-of-practice message__\n\nAfter the practice phase, we want to inform the participant that the real experiment will begin. For this we need another `form_text_display`. Go back to the *experiment* SEQUENCE, and drag a `form_text_display` from the item toolbar onto the LOOP item. The same pop-up menu will appear as before. This time, select 'Insert after new_loop'. (We will get back to this in Step 12.)\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- Don't worry if you have accidentally changed a LOOP's item to run. You can undo this easily by clicking the 'Undo' button in the toolbar (`Ctrl+Shift+Z`).\n\n</div>\n\n__Append a new loop item, containing the previously created sequence, for the experimental phase__\n\nWe need a LOOP item for the experimental phase, just like for the practice phase. Therefore, drag a LOOP from the item toolbar menu onto *_form_text_display*.\n\nThe newly created LOOP (called *new_loop_1*) is empty, and should be filled with a SEQUENCE, just like the LOOP we created before. However, because the trials of the practice and experimental phase are identical, they can use the same SEQUENCE. Therefore, instead of dragging a new SEQUENCE from the item toolbar, you can re-use the *existing* one (i.e. create a linked copy).\n\nTo do this, right-click on the previously created *new_sequence*, and select 'Copy (linked)'. Now, right-click on *new_loop_1* and select 'Paste'. In the pop-up menu that appears, select 'Insert into new_loop 1'.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ \u2014 There is an important distinction between *linked* and *unlinked* copies. If you create a linked copy of an item, you create another occurrence of the same item. Therefore, if you modify the original item, the linked copy will change as well. In contrast, if you create an unlinked copy of an item, the copy will be initially look identical (except for its name), but you can edit the original without affecting the unlinked copy, and vice versa.\n\n</div>\n\n__Append a new form_text_display item, for the goodbye message__\n\nWhen the experiment is finished, we should say goodbye to the participant. For this we need another `form_text_display` item. Go back to the *experiment* SEQUENCE, and drag a `form_text_display` from the item toolbar onto *new_loop_1*. In the pop-up menu that appears, select 'Insert after new_loop_1'. (We will get back to this in Step 12.)\n\n__Give the new items sensible names__\n\nBy default, new items have names like *new_sequence* and *new_form_text_display_2*. It is good practice to give items sensible names. This makes it much easier to understand the structure of the experiment. If you want, you can also add a description to each item. Item names must consist of alphanumeric characters and/or underscores.\n\n- Select *new_form_text_display* in the overview area, double-click on its label in the top of the tab area and rename the item to *instructions*. (Overview-area shortcut: `F2`)\n- Rename *new_loop* to *practice_loop*.\n- Rename *new_sequence* to *block_sequence*. Because you have re-used this item in *new_loop_1*, the name automatically changes there as well. (This illustrates why it is efficient to create linked copies whenever this is possible.)\n- Rename *new_form_text_display_1* to *end_of_practice*.\n- Rename *new_loop_1* to *experimental_loop*.\n- Rename *new_form_text_display_2* to *end_of_experiment*.\n\n__Give the whole experiment a sensible name__\n\nThe experiment in its entirety also has a title and a description. Click on 'New experiment' in the overview area. You can rename the experiment in the same way as you renamed its items. The title currently is 'New experiment'. Rename the experiment to 'Tutorial: Gaze cuing'. Unlike item names, the experiment title may contain spaces etc.\n\nThe overview area of your experiment now looks like %FigStep1. This would be a good time to save your experiment (shortcut: `Ctrl+S`).\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of the step 1.\n--%\n\n\n## Step 2: Create the block sequence\n\nClick on *block_sequence* in the overview. At the moment this SEQUENCE is empty. We want *block sequence* to consist of a block of trials, followed by a  FEEDBACK display. For this we need to do the following:\n\n__Append a reset_feedback item to reset the feedback variables__\n\nWe don't want our feedback to be confounded by key presses that participants have made during the instruction phase or previous blocks of trials. Therefore, we start each block of trials by resetting the feedback variables. To do this we need a `reset_feedback` item. Grab `reset_feedback` from the item toolbar (under 'Response collection') and drag it onto *block_sequence*.\n\n__Append a new loop, containing a new sequence, for a block of trials__\n\nFor a single trial we need a SEQUENCE. For a block of trials, we need to repeat this SEQUENCE multiple times. Therefore, for a block of trials we need to wrap a LOOP around a SEQUENCE. Drag a LOOP from the item toolbar onto *new_reset_feedback*. Next, drag a SEQUENCE from the item toolbar onto the newly created LOOP, and select 'Insert into new_loop' in the pop-up menu that appears. (We will get back to this in Step 3.)\n\n__Append a feedback item__\n\nAfter every block of trials we want to give feedback to the participant, so that the participant knows how well he/ she is doing. For this we need a FEEDBACK item. Drag a FEEDBACK from the item toolbar onto *new_loop*, and select 'Insert after loop' in the pop-up menu that appears. (We will get back to this in Step 10.)\n\n__Give the new items sensible names__\n\nRename: (See Step 1 if you don't remember how to do this.)\n\n- *new_loop* to *block_loop*\n- *new_sequence* to *trial_sequence*\n- *new_reset_feedback* to *reset_feedback*\n- *new_feedback* to *feedback*\n\nThe overview of your experiment now looks like %FigStep2. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The overview area at the end of Step 2.\n--%\n\n## Step 3: Fill the block loop with independent variables\n\nAs the name suggests, *block_loop* corresponds to a single block of trials. In the previous step we created the *block_loop*, but we still need to define the independent variables that will be varied within the block. Our experiment has three independent variables:\n\n- __gaze_cue__ can be 'left' or 'right'.\n- __target_pos__ (the position of the target) can be '-300' or '300'. These values reflect the X-coordinate of the target in pixels (0 = center). Using the coordinates directly, rather than 'left' and 'right', will be convenient when we create the target displays (see Step 5).\n- __target_letter__ (the target letter) can be 'F' or 'H'.\n\nTherefore, our experiment has 2 x 2 x 2 = 8 levels. Although 8 levels is not that many (most experiments will have more), we don't need to enter all possible combinations by hand. Click on *block_loop* in the overview to open its tab. Now click on the 'Full-factorial design' button. In the variable wizard, you simply define all variables by typing the name in the first row and the levels in the rows below the name (see %FigVariableWizard). If you select 'Ok', you will see that *block_loop* has been filled with all 8 possible combinations.\n\n%--\nfigure:\n id: FigVariableWizard\n source: variable-wizard.png\n caption: |\n  The loop variable wizard in Step 3.\n--%\n\nIn the resulting loop table, each row corresponds to one run of *trial_sequence*. Because, in our case, one run of *trial_sequence* corresponds to one trial, each row in our loop table corresponds to one trial. Each column corresponds to one variable, which can have a different value on each trial.\n\nBut we are not done yet. We need to add three more variables: the location of the distractor, the correct response, and the congruency.\n\n- __dist_pos__ -- On the first row of the first empty column, enter 'dist_pos'. This automatically adds a new experimental variable named 'dist_pos'. In the rows below, enter '300' wherever 'target_pos' is -300, and '-300' wherever 'target_pos' is 300. In other words, the target and the distractor should be positioned opposite from each other.\n- __correct_response__ -- Create another variable, in another empty column, with the name 'correct_response'. Set 'correct_response' to 'z' where 'target_letter' is 'F', and to 'm' where 'target_letter' is 'H'. This means that the participant should press the 'z' key if she sees an 'F' and the 'm' key if she sees an 'H'. (Feel free to choose different keys if 'z' and 'm' are awkward on your keyboard layout; for example, 'w' and 'n' are better on AZERTY keyboards.)\n- __congruency__ -- Create another variable with the name 'congruency'. Set 'congruency' to 'congruent' where 'target_pos' is '-300' and 'gaze_cue' is 'left', and where 'target_pos' is '300' and 'gaze_cue' is 'right'. In other words, a trial is congruent if the face looks at the target. Set 'congruency' to 'incronguent' for the trials on which the face looks at the distractor. The 'congruency' variable is not necessary to run the experiment; however, it is useful for analyzing the data later on.\n\nWe need to do one last thing. 'Repeat' is currently set to '1.00'. This means that each cycle will be executed once. So the block now consists of 8 trials, which is a bit short. A reasonable length for a block of trials is 24, so set 'Repeat' to 3.00 (3 repeats x 8 cycles = 24 trials). You don't need to change 'Order', because 'random' is exactly what we want.\n\nThe *block_loop* now looks like %FigStep3. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: \"The *block_loop* at the end of Step 3.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can prepare your loop table in your favorite spreadsheet program and copy-paste it into the LOOP variable table.\n\n__Tip__ -- You can specify your loop table in a separate file (in `.xlsx` or `.csv`) format, and use this file directly. To do so, select 'file' under 'Source'.\n\n__Tip__ -- You can set 'Repeat' to a non-integer number. For example, by setting 'Repeat' to '0.5', only half the trials (randomly selected) are executed.\n\n</div>\n\n## Step 4: Add images and sound files to the file pool\n\nFor our stimuli, we will use images from file. In addition, we will play a sound if the participant makes an error. For this we need a sound file.\n\nYou can download the required files here (in most webbrowsers you can right-click the links and choose 'Save Link As' or a similar option):\n\n- [gaze_neutral.png](/img/beginner-tutorial/gaze_neutral.png)\n- [gaze_left.png](/img/beginner-tutorial/gaze_left.png)\n- [gaze_right.png](/img/beginner-tutorial/gaze_right.png)\n- [incorrect.ogg](/img/beginner-tutorial/incorrect.ogg)\n\nAfter you have downloaded these files (to your desktop, for example), you can add them to the file pool. If the file pool is not already visible (by default on the right side of the window), click on the 'Show file pool' button in the main toolbar (shortcut: `Ctrl+P`). The easiest way to add the four files to the file pool is to drag them from the desktop (or wherever you have downloaded the files to) into the file pool. Alternatively, you can click on the '+' button in the file pool and add files using the file select dialog that appears. The file pool will be automatically saved with your experiment.\n\nYour file pool now looks like %FigStep4. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: \"The file pool at the end of Step 4.\"\n--%\n\n## Step 5: Fill the trial sequence with items\n\nA trial in our experiment looks as follows:\n\n1. __Fixation dot__ -- 750 ms, SKETCHPAD item\n2. __Neutral gaze__ -- 750 ms, SKETCHPAD item\n3. __Gaze cue__ -- 500 ms, SKETCHPAD item\n4. __Target__  -- 0 ms, SKETCHPAD item\n5. __Response collection__ \t-- KEYBOARD_RESPONSE item\n6. __Play a sound if response was incorrect__ --  SAMPLER item\n7. __Log response to file__ -- LOGGER item\n\nClick on *trial_sequence* in the overview to open the *trial_sequence* tab. Pick up a SKETCHPAD from the item toolbar and drag it into the *trial_sequence*. Repeat this three more times, so that *trial_sequence* contains four SKETCHPADs. Next, select and append a KEYBOARD_RESPONSE item, a SAMPLER item, and a LOGGER item.\n\nAgain, we will rename the new items, to make sure that the *trial_sequence* is easy to understand. Rename:\n\n- *new_sketchpad* to *fixation_dot*\n- *new_sketchpad_1* to *neutral_gaze*\n- *new_sketchpad_2* to *gaze_cue*\n- *new_sketchpad_3* to *target*\n- *new_keyboard_response* to *keyboard_response*\n- *new_sampler* to *incorrect_sound*\n- *new_logger* to *logger*\n\nBy default, items are always executed, which is indicated by the run-if expression `True`. However, we want to change this for the *incorrect_sound* item, which should only be executed if an error was made. To do this, we need to change the 'Run if' expression to `correct == 0` in the *trial_sequence* tab. This works, because the *keyboard_response* item automatically creates a `correct` variable, which is set to `1` (correct), `0` (incorrect), or `undefined` (this relies on the `correct_response` variable that was defined in Step 3). The double equals sign is Python syntax and indicates that you want to compare whether the two things are equal to each other, in this case whether the variable `correct` is equal to 0. To change a run-if expression, double click on it (shortcut: `F3`).\n\nThe *trial_sequence* now looks like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: \"The *trial_sequence* at the end of Step 5.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a SKETCHPAD item?__ -- A SKETCHPAD is used to present visual stimuli: text, geometric shapes, fixation dots, Gabor patches, etc. You can draw on the SKETCHPAD using the built-in drawing tools.\n\n__What is a KEYBOARD_RESPONSE item?__ -- A KEYBOARD_RESPONSE item collects a single participant's response from the keyboard.\n\n__What is a SAMPLER item?__ -- A SAMPLER item plays a sound from a sound file.\n\n__What is a LOGGER item?__ -- A LOGGER item writes data to the log file. This is very important: If you forget to include a LOGGER item, no data will be logged during the experiment!\n\n__Tip__ -- Variables and conditional \"if\" expressions are very powerful! To learn more about them, see:\n\n- %link:manual/variables%\n\n</div>\n\n## Step 6: Draw the sketchpad items\n\nThe SKETCHPAD items that we have created in Step 5 are still blank. It's time to do some drawing!\n\n__Set the background color to white__\n\nClick on *fixation_dot* in the overview area to open its tab. The SKETCHPAD is still dark gray, while the images that we have downloaded have a white background. Oops, we forgot to set the background color of the experiment to white (it is dark gray by default)! Click on 'Tutorial: Gaze cuing' in the overview area to open the 'General properties' tab. Change 'Foreground' to 'black' and 'Background' to 'white'.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- For more fine-grained control over colors, you can also use the hexadecimal RGB notation (e.g., `#FF000` for red), use various color spaces, or use the color-picker tool. See also:\n\n- %link:manual/python/canvas%\n\n</div>\n\n__Draw the fixation dot__\n\nGo back to the *fixation_dot* by clicking on *fixation_dot* in the overview. Now select the fixation-dot element by clicking on the button with the crosshair. If you move your cursor over the sketchpad, you can see the screen coordinates in the top-right. Set the (foreground) color to 'black'. Click on the center of the screen (0, 0) to draw a central fixation dot.\n\nFinally, change the 'Duration' field from 'keypress' to '745', because we want the fixation dot to be presented for 750 ms. Wait ... *why didn't we just specify a duration of 750 ms?* The reason for this is that the actual display-presentation duration is always rounded up to a value that is compatible with your monitor's refresh rate. This may sound complicated, but for most purposes the following rules of thumb are sufficient:\n\n1. Choose a duration that is possible given your monitor's refresh rate. For example, if your monitor's refresh rate is 60 Hz, it means that every frame lasts 16.7 ms (= 1000 ms/60 Hz). Therefore, on a 60 Hz monitor, you should always select a duration that is a multiple of 16.7 ms, such as 16.7, 33.3, 50, 100, etc.\n2. In the duration field of the SKETCHPAD specify a duration that is a few milliseconds less than what you're aiming for. So if you want to present a SKETCHPAD for 50 ms, choose a duration of 45. If you want to present a SKETCHPAD for 1000 ms, choose a duration of 995. Etcetera.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- For a detailed discussion of experimental timing, see:\n\n- %link:timing%\n\n__Tip__ -- The duration of a SKETCHPAD can be a value in milliseconds, but you can also enter 'keypress' or 'mouseclick' to collect a keyboard press or mouse click respectively. In this case a SKETCHPAD will work much the same as a KEYBOARD_RESPONSE item (but with fewer options).\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n__Draw the neutral gaze__\n\nOpen the *neutral_gaze* SKETCHPAD. Now select the image tool by clicking on the button with the mountain-landscape-like icon. Click on the center of the screen (0, 0). The 'Select file from pool' dialog will appear. Select the file `gaze_neutral.png` and click on the 'Select' button. The neutral gaze image will now stare at you from the center of the screen! Finally, like before, change the 'Duration' field from 'keypress' to '745'. (And note again that this means a duration of 750 ms on most monitors!)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- OpenSesame can handle a wide variety of image formats. However, some (non-standard) `.bmp` formats are known to cause trouble. If you find that a `.bmp` image is not shown, you can convert it to a different format, such as `.png`. You can convert images easily with free tools such as [GIMP].\n</div>\n\n__Draw the gaze cue__\n\nOpen the *gaze_cue* SKETCHPAD, and again select the image tool. Click on the center of the screen (0, 0) and select the file `gaze_left.png`.\n\nBut we are not done yet! Because the gaze cue should not always be 'left', but should depend on the variable `gaze_cue`, which we have defined in Step 3. However, by drawing the `gaze_left.png` image to the SKETCHPAD, we have generated a script that needs only a tiny modification to make sure that the proper image is shown. Click on the 'Select view' button at the top-right of the *gaze_cue* tab and select 'View script'. You will now see the script that corresponds to the sketchpad that we have just created:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nThe only thing that we need to do is replace `gaze_left.png` with `gaze_{gaze_cue}.png`. This means that OpenSesame uses the variable `gaze_cue` (which has the values `left` and `right`) to determine which image should be shown.\n\nWhile we are at it, we might as well change the duration to '495' (rounded up to 500!). The script now looks like this:\n\n~~~ .python\nset duration 495\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nClick the 'Apply' button at the top right to apply your changes to the script and return to the regular item controls. OpenSesame will warn you that the image cannot be shown, because it is defined using variables, and a placeholder image will be shown instead. Don't worry, the correct image will be shown during the experiment!\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- The variable inspector (shortcut: `Ctrl+I`) is a powerful way to find out which variables have been defined in your experiment, and which values they have (see %FigVariableInspector). When your experiment is not running, most variables don't have a value yet. But when you run your experiment in a window, while having the variable inspector visible, you can see variables changing in real time. This is very useful for debugging your experiment.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: \"The variable inspector is a convenient way to get an overview of the variables that exist in your experiment.\"\n--%\n\n</div>\n\n__Draw the target__\n\nWe want three objects to be part of the target display: the target letter, the distractor letter, and the gaze cue (see %FigGazeCuing). As before, we will start by creating a static display using the SKETCHPAD editor. After this, we will only need to make minor changes to the script so that the exact display depends on the variables.\n\nClick on *target* in the overview to open the target tab and like before, draw the `gaze_left.png` image at the center of the screen. Now select the draw text tool by clicking on the button with the 'A' icon. Change the foreground color to 'black' (if it isn't already). The default font size is 18 px, which is a bit small for our purpose, so change the font size to 32 px. Now click on (-320, 0) in the SKETCHPAD (the X-coordinate does not need to be exactly 320, since we will change this to a variable anyway). Enter \"{target_letter}\" in the dialog that appears, to draw the target letter (when drawing text, you can use variables directly). Similarly, click on (320, 0) and draw an 'X' (the distractor is always an 'X').\n\nNow open the script editor by clicking on the 'Select view' button at the top-right of the tab and selecting 'View script'. The script looks like this:",
    "title": "Beginner tutorial: gaze cuing",
    "url": "https://osdoc.cogsci.nl/4.1/tutorials/beginner",
    "path": "content/pages/tutorials/beginner.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 2
  },
  {
    "content": "# Beginner tutorial: gaze cuing\n\n\n~~~ .python\nset duration keypress\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x=-320 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x=320 y=0 z_index=0\n~~~\n\nLike before, change `gaze_left.png` to `gaze_{gaze_cue}.png`. We also need to make the position of the target and the distractor depend on the variables `target_pos` and `dist_pos` respectively. To do this, simply change `-320` to `{target_pos}` and `320` to `{dist_pos}`. Make sure that you leave the `0`, which is the Y-coordinate. The script now looks like this:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x={target_pos} y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x={dist_pos} y=0 z_index=0\n~~~\n\nClick on the 'Apply' button to apply the script and go back to the regular item controls.\n\nFinally, set the 'Duration' field to '0'. This does not mean that the target is presented for only 0 ms, but that the experiment will advance to the next item (the *keyboard_response*) right away. Since the *keyboard_response* waits for a response, but doesn't change what's on the screen, the target will remain visible until a response has been given.\n\nRemember to save your experiment regularly.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- Each element of a SKETCHPAD has a 'Show if' option, which specifies when the element should be shown. You can use this to hide/ show elements from a SKETCHPAD depending on certain variables, similar to run-if statements in a SEQUENCE.\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n## Step 7: Configure the keyboard response item\n\nClick on *keyboard_response* in the overview to open its tab. You see three options: Correct response, Allowed responses, Timeout, and Event type.\n\nWe have already set the `correct_response` variable in Step 3. Unless we explicitly specify a correct response, OpenSesame automatically uses the `correct_response` variable if it is available. Therefore, we don't need to change the 'Correct response' field here.\n\nWe do need to set the allowed responses. Enter 'z;m' in the allowed-responses field (or other keys if you have chosen different response keys). The semicolon is used to separate responses. The KEYBOARD_RESPONSE now only accepts 'z' and 'm' keys. All other key presses are ignored, with the exception of 'escape', which pauses the experiment.\n\nWe also want to set a timeout, which is the maximum interval that the KEYBOARD_RESPONSE waits before deciding that the response is incorrect and setting the 'response' variable to 'None'. '2000' (ms) is a good value.\n\nWe don't need to change the Event type, because we want the participant to respond by pressing a key (keypress, the default) and not by releasing a key (keyrelease).\n\nThe KEYBOARD_RESPONSE now looks like %FigStep7.\n\n%--\nfigure:\n id: FigStep7\n source: step7.png\n caption: \"The KEYBOARD_RESPONSE at the end of Step 7.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- By default, the KEYBOARD_RESPONSE will use the `correct_response` variable to determine whether a response was correct. But you can use a different variable as well. To do this, enter a variable name between curly braces (`{my_variable}`) in the correct response field.\n\n__Tip__ -- If 'flush pending key presses' is enabled (it is by default), all pending key presses are discarded when the KEYBOARD_RESPONSE item is called. This prevents carry-over effects, which might otherwise occur if the participant accidentally presses a key during a non-response part of the trial.\n\n__Tip__ -- To use special keys, such as '/' or the up-arrow key, you can use key names (e.g., 'up' and 'space') or associated characters (e.g., '/' and ']'). The 'List available keys' button provides an overview of all valid key names.\n\n</div>\n\n## Step 8: Configure the incorrect (sampler) item\n\nThe *incorrect_sound* item doesn't need much work: We only need to select the sound that should be played. Click on *incorrect_sound* in the overview to open its tab. Click on the 'Browse' button and select `incorrect.ogg` from the file pool.\n\nThe sampler now looks like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: \"The *incorrect_sound* item at the end of Step 8.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can use variables to specify which sound should be played by using a variable name between curly braces as (part of) the file name. For example: `{a_word}.ogg`\n\n__Tip__ -- The SAMPLER handles files in `.ogg`, `.mp3`, and `.wav` format. If you have sound files in a different format, [Audacity] is a great free tool to convert sound files (and much more).\n\n</div>\n\n## Step 9: Configure the variable logger\n\nActually, we don't need to configure the variable LOGGER, but let's take a look at it anyway. Click on *logger* in the overview to open its tab. You see that the option 'Automatically log all variables' is selected. This means that OpenSesame logs everything, which is fine.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- If you like your log-files clean, you can disable the 'Automatically log all variables' option and manually select variables, either by entering variable names manually ('Add custom variable'), or by dragging variables from the variable inspector into the LOGGER table. You can also leave the 'Automatically log all variables' option enabled and exclude variables that you are not interested in.\n\n__The one tip to rule them all__ -- Always triple-check whether all the necessary variables are logged in your experiment! The best way to check this is to run the experiment and investigate the resulting log files.\n\n</div>\n\n## Step 10: Draw the feedback item\n\nAfter every block of trials, we want to present feedback to the participant to let him/ her know how well he/ she is doing. Therefore, in Step 2, we added a FEEDBACK item, simply named *feedback* to the end of *block_sequence*.\n\nClick on *feedback* in the overview to open its tab, select the draw text tool, change the foreground color to 'black' (if it isn't already), and click at (0, 0). Now enter the following text:\n\n```text\nEnd of block\n\nYour average response time was {avg_rt} ms\nYour accuracy was {acc} %\n\nPress any key to continue\n```\n\nBecause we want the feedback item to remain visible as long as the participant wants (i.e. until he/ she presses a key), we leave 'Duration' field set to 'keypress'.\n\nThe feedback item now looks like %FigStep_10.\n\n%--\nfigure:\n id: FigStep_10\n source: step10.png\n caption: \"The feedback item at the end of Step 10.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a feedback item?__ -- A FEEDBACK item is almost identical to a SKETCHPAD item. The only difference is that a FEEDBACK item is not prepared in advance. This means that you can use it to present feedback, which requires up-to-date information about a participant's response. You should not use FEEDBACK items to present time-critical displays, because the fact that it is not prepared in advance means that its timing properties are not as good as that of the SKETCHPAD item. See also:\n\n- %link:visual%\n\n__Feedback and variables__ -- Response items automatically keep track of the accuracy and average response time of the participant in the variables 'acc' (synonym: 'accuracy') and 'avg_rt' (synonym: 'average_response_time') respectively. See also:\n\n- %link:manual/variables%\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n## Step 11: Set the length of the practice phase and experimental phase\n\nWe have previously created the *practice_loop* and *experiment_loop* items, which both call *block_sequence* (i.e., a block of trials). However, right now they call *block_sequence* only once, which means that both the practice and the experimental phase consist of only a single block of trials.\n\nClick on *practice_loop* to open its tab and set 'Repeat' to '2.00'. This means that the practice phase consists of two blocks.\n\nClick on *experimental_loop* to open its tab and set 'Repeat' to '8.00'. This means that the experimental phase consists of eight blocks.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can create a variable `practice` in both *practice_loop* and *experimental_loop* and set it to 'yes' and 'no' respectively. This is an easy way of keeping track of which trials were part of the practice phase.\n\n</div>\n\n## Step 12: Write the instruction, end_of_practice and end_of_experiment forms\n\nI think you can handle this step your own! Simply open the appropriate items and add some text to present instructions, an end-of-practice message, and an end-of-experiment message.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can use a subset of HTML tags to format your text. For example, *&lt;b&gt;this will be bold&lt;b&gt;* and *&lt;span color='red'&gt;this will be red&lt;span&gt;*. For more information, see:\n\n- %link:text%\n\n</div>\n\n## Step 13: Run the experiment!\n\nYou're done! Click on the 'Run in window' (shortcut: `Ctrl+W`) or 'Run fullscreen' (shortcut: `Ctrl+R`) buttons in the toolbar to run your experiment.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- A test run is executed even faster by clicking the orange 'Run in window' button (shortcut: `Ctrl+Shift+W`), which doesn't ask you how to save the logfile (and should therefore only be used for testing purposes).\n\n</div>\n\n\n## Understanding errors\n\nBeing able to understand error messages is a crucial skill when working with OpenSeame. After all, a newly built experiment rarely runs immediately without any errors!\n\nLet's say that we made a mistake during one of the steps above. When trying to run the experiment, we get the following error message (%FigErrorMessage):\n\n%--\nfigure:\n id: FigErrorMessage\n source: error-message.png\n caption: \"An error message in OpenSesame.\"\n--%\n\nThe error message starts with a name, in this case `FStringError`, which indicates the general type of error. This is followed by a short explanatory text, in this case 'Failed to evaluate f-string expression in the following text: gaze_{gaze_ceu}.png`. Even without understanding what an f-string is (it's a string that contains Python code between curly braces), it's clear that there is something wrong with the text '{gaze_ceu}.png'.\n\nThe error message also indicates that the error comes from the prepare phase of the *gaze_cue* item.\n\nFinally, the error message indicates what specifically went wrong when evaluating the text 'gaze_{gaze_ceu}.png': the name 'gaze_ceu' is not defined.\n\nWhile reading the error message carefully, the cause and solution probably already came to your mind: we made a simple spelling mistake in the *gaze_cue* item, writing '{gaze_ceu}' instead of '{gaze_cue}'! And this resulted in an error because there is no variable with the name `gaze_ceu`. This can be easily fixed by opening the script of the *gaze_cue* item and fixing the typo.\n\n\n## Finally: Some general considerations regarding timing and backend selection\n\nIn the 'General properties' tab of the experiment (the tab that you open by clicking on the experiment name), you can select a backend. The backend is the layer of software that controls the display, input devices, sound, etc. Most experiments work with all backends, but there are reasons to prefer one backend over the other, mostly related to timing. Currently there are four backends (depending on your system, not all three may be available):\n\n- __psycho__ -- a hardware-accelerated backend based on PsychoPy [(Peirce, 2007)][references]. This is the default.\n- __xpyriment__ -- a hardware-accelerated backend based on Expyriment [(Krause & Lindeman, 2013)][references]\n- __legacy__ -- a 'safe' backend, based on PyGame. It provides reliable performance on most platforms, but, due to a lack of hardware acceleration, its timing properties are not as good as those of the other backends.\n- __osweb__ -- runs experiments in a browser [(Math\u00f4t & March, 2022)][references].\n\nSee also:\n\n- %link:backends%\n- %link:timing%\n\n\n## References\n\n<div class='reference' markdown='1'>\n\nBrand, A., & Bradley, M. T. (2011). Assessing the effects of technical variance on the statistical outcomes of web experiments measuring response times. *Social Science Computer Review*. doi:10.1177/0894439311415604\n\nDamian, M. F. (2010). Does variability in human performance outweigh imprecision in response devices such as computer keyboards? *Behavior Research Methods*, *42*, 205-211. doi:10.3758/BRM.42.1.205\n\nFriesen, C. K., & Kingstone, A. (1998). The eyes have it! Reflexive orienting is triggered by nonpredictive gaze. *Psychonomic Bulletin & Review*, *5*, 490\u2013495. doi:10.3758/BF03208827\n\nKrause, F., & Lindemann, O. (2013). Expyriment: A Python library for cognitive and neuroscientific experiments. *Behavior Research Methods*. doi:10.3758/s13428-013-0390-6\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nMath\u00f4t, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n\nUlrich, R., & Giray, M. (1989). Time resolution of clocks: Effects on reaction time measurement\u2014Good news for bad clocks. *British Journal of Mathematical and Statistical Psychology*, *42*(1), 1-12. doi:10.1111/j.2044-8317.1989.tb01111.x\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html\n[gimp]: http://www.gimp.org/\n[audacity]: http://audacity.sourceforge.net/\n[python inline scripting]: /python/about",
    "title": "Beginner tutorial: gaze cuing",
    "url": "https://osdoc.cogsci.nl/4.1/tutorials/beginner",
    "path": "content/pages/tutorials/beginner.md",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 2,
    "total_chunks": 2
  },
  {
    "content": "# Intermediate tutorial (Python) visual search\n\ntitle: Intermediate tutorial (Python) visual search\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a user-friendly program for the development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface.  For advanced users, OpenSesame supports Python (desktop only) and JavaScript (desktop and browser).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a basic visual-search experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012)][references]. We will use both the graphical interface and Python scripting to develop an experiment that you can run on the desktop in a traditional lab-based setting. Some experience with OpenSesame and Python is recommended. This tutorial takes approximately one hour.\n\nA JavaScript-based version of this tutorial is also available. If you want to run your experiments online in a browser (with OSWeb), then the JavaScript tutorial is what you need:\n\n- %link:tutorials/intermediate-javascript%\n\n## Resources\n\n- __Download__ \u2014 This tutorial assumes that you are running OpenSesame version 4.0.0 or later. You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ \u2014 A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ \u2014 A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n- __Sigmund__ -- SigmundAI is an AI assistant with expert knowledge of OpenSesame and can be found at:\n\t- <https://sigmundai.eu/>\n\n## The experiment\n\nIn this tutorial, you will create a basic visual-search experiment. The experiment resembles the classic visual-search studies of [Treisman and Gelade (1980)][references], but it is not identical.\n\nIn this experiment, participants search for a target object, which can be a yellow square, a yellow circle, a blue square, or a blue circle; the identity of the target is varied between blocks of trials. Participants indicate whether the target is present or not by pressing the right (present) or left (absent) arrow key.\n\nIn addition to the target, zero or more distractor objects are shown. There are three conditions, and the condition determines what kind of distractors there are:\n\n- In the *Conjunction* condition, distractors can have any shape and color, with the only restriction that distractors cannot be identical to the target. So, for example, if the target is a yellow square, then distractors are yellow circles, blue circles, and blue squares.\n- In the *Shape Feature* condition, distractors have a different shape from the target, but can have any color. So, for example, if the target is a yellow square, then distractors are yellow circles and blue circles.\n- In the *Color Feature* condition, distractors can have any shape, but have a different color from the target. So, for example, if the target is a yellow square, then distractors are blue squares and blue circles.\n\nImmediate feedback is shown after each trial: a green dot after a correct response, and a red dot after an incorrect response. Detailed feedback on average response times and accuracy is shown after each block of trials.\n\n%--\nfigure:\n id: FigVisualSearch\n source: visual-search.svg\n caption: |\n  The visual-search experiment that you will implement in this tutorial.\n--%\n\nExperiments like this show two typical findings:\n\n- It takes more time to find the target in the Conjunction condition than in the two Feature conditions.\n- In the Conjunction condition, response times increase as the number of distractors increases. This suggests that people search for the target one item at a time; this is called *serial search*.\n- In the Feature conditions (both shape and color), response times do not, or hardly, increase as the the number of distractors increases. This suggests that people process the entire display at once; this is called *parallel search*.\n\nAccording to Treisman and Gelade's feature-integration theory, these results reflect that the Conjunction condition requires that you combine, or *bind*, the color and shape of each object. This binding requires attention, and you therefore need to shift your attention from one object to the next; this is slow, and explains why response times depend on how many objects there are. In contrast, in the Feature conditions, color and shape do not need to be bound, and therefore the whole display can be processed in a single sweep without attention being directed at each and every object.\n\n## Experimental design\n\nThis design:\n\n- Is *within-subject*, because all participants do all conditions\n- Is *fully crossed* (or full-factorial), because all combinations of conditions occur\n- Has three conditions (or factors):\n\t- Varied within blocks:\n\t\t- `set_size` with three levels (1, 5, 15), or SS<sub>3</sub>\n\t\t- `condition` with three levels (conjunction, feature_shape, feature_color), or CN<sub>3</sub>\n\t\t- `target_present` with two levels (present, absent), or TP<sub>2</sub>\n\t- Varied between blocks:\n\t\t- `target_shape` with two levels (square, circle), or TS<sub>2</sub>\n\t\t- `target_color` with two levels (yellow, blue), or TC<sub>2</sub>\n- Has N subjects, or <u>S</u><sub>N</sub>\n\nYou can write this design as <u>S</u><sub>N</sub>\u00d7SS<sub>3</sub>\u00d7CN<sub>3</sub>\u00d7TP<sub>2</sub>\u00d7TS<sub>2</sub>\u00d7TC<sub>2</sub>\n\nFor more information about this notation for experimental design, see:\n\n- %link:experimentaldesign%\n\n## Step 1: Create the basic structure of the experiment\n\nStart OpenSesame and, in the 'Get started!' tab, select the Extended template. This template provides the basic structure that is common to many cognitive-psychology experiments, such as the one that we will create here.\n\nThe Extended template contains a few items that we don't need. Delete the following items:\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nWhen you have deleted these items, they are still visible in the 'Unused items' bin. To permanently delete these items, click on the 'Unused items' bin, and then click on the 'Permanently delete unused items' button.\n\nFinally, give the experiment a good title, such as 'Visual search'. To do this, open the general-properties tab (by clicking on 'Extended template' in the overview area) and click on the experiment name to edit it.\n\nThe overview area should now look like %FigStep1:\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of step 1.\n--%\n\n## Step 2: Define experimental variables that are varied between blocks\n\nAs described above, two variables are varied between blocks in our experiment: `target_shape` and `target_color`. We therefore need to define these variables in the *experimental_loop*. To understand why, consider the structure shown in %FigStep1, starting from the bottom (i.e. the most indented level).\n\n- *trial_sequence* corresponds to a single trial\n- *block_loop* corresponds to a block of a trials\n\t- Therefore, variables defined here vary for each run of *trial_sequence*; in other words, variables defined in *block_loop* are varied __within blocks__.\n- *block_sequence* corresponds to a block of trials, preceded by resetting of the feedback variables, and followed by participant feedback\n- *experimental_loop* corresponds to multiple blocks of trials\n\t- Therefore, variables defined here vary for each run of *block_sequence*; in other words, variables defined in *experimental_loop* are varied __between blocks__.\n- *experiment* corresponds to the entire experimental, which is an instruction screen, followed by multiple blocks of trials, followed by an end-of-experiment screen\n\nClick on experimental loop, and define:\n\n- `target_shape`, which can be 'square' or 'circle'; and\n- `target_color`, which can be 'yellow' or 'blue'.\n\nWe have a full-factorial design, which means that all 2 \u00d7 2 = 4 combinations must occur. The table of *experimental_loop* should now look like %FigStep2:\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The table of *experimental_loop* at the end of step 2.\n--%\n\n## Step 3: Give instructions at the start of each block\n\nRight now, the experiment starts with a single *instructions* screen. In our case, we want to give instructions before each block of trials, to tell the participant what target to look for (because the identity of the target varies between blocks).\n\n__Move the instructions into block_sequence__\n\nTherefore, pick up the *instructions* item and drag it onto *block_sequence*. A pop-up will appear, asking you if you want to:\n\n- Insert the item into *block_sequence*, in which case *instructions* would become the first item of *block_sequence*; or\n- Insert the item after *block_sequence*, in which case *instructions* would move to a position after *block_sequence*.\n\nSelect the first option ('Insert into'). Now *block_sequence* starts with an instructions screen, which is what we want.\n\n__Add instructional text__\n\nClick on *instructions* to open it, and add a good instructional text, such as:\n\n```text\nINSTRUCTIONS\n\nSearch for the {target_color} {target_shape}\n\nPress the right-arrow key if you find it\nPress the left-arrow key if you don't\n\nPress any key to begin\n```\n\nThe curly braces brackets around '{target_color}' and '{target_shape}' indicate that these are not literal text, but refer to the variables that we have defined in *experimental_loop*. When the experiment runs, the values of these variables will appear here, and the participant will see (for example), 'Search for the yellow circle'.\n\n__Give a visual preview of the target__\n\nIt also good to show the participant the actual stimulus that she needs to find. To do this:\n\n- Draw a filled circle at the center of the display (make sure it doesn't overlap with the text);\n- Change the color of the circle to '{target_color}'. This means that the color of the circle depends on the value of the variable `target_color`; and\n- Change the show-if expression to `target_shape == 'circle'`. This is a Python expression that checks if the variable `target_shape` has the value 'circle'.\n\nIn other words, we have drawn a circle of which the color is determined by `target_color`; furthermore, this circle is only shown when the variable `target_shape` has the value 'circle'. For more information about variables and show-if statements, see:\n\n- %link:manual/variables%\n\nWe use the same trick to draw a square:\n\n- Draw a filled square at the center of the display;\n- Change the color of the square to '{target_color}'; and\n- Change the show-if statement to `target_shape == 'square'`\n\nThe *instructions*  screen should now look like %FigStep3:\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\n## Step 4: Define experimental variables that are varied within blocks\n\nThree variables are varied within blocks in our experiment: `condition`, `set_size`, and `target_present`. As described under Step 2, we need to define these variables in the *block_loop* so that they vary for each run of *trial_sequence*.\n\nThe three variables make a total of 3 \u00d7 3 \u00d7 2 = 18 different combinations. We can type these into the table manually, but, because we have full-factorial design, we can also use the full-factorial-design wizard. To do this, first open *block_loop* and click on the 'Full-factorial design' button.\n\nIn the table that appears, put the variable names on the first row, and the values on the rows below, as shown in %FigFullFactorial.\n\n%--\nfigure:\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\nNow click on 'Ok' to generate the full design. The table of *block_loop* should now look like %FigStep4.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The table of *block_loop* at the end of step 4.\n--%\n\n## Step 5: Create the trial sequence\n\nWe want our trial sequence to look as follows:\n\n- A fixation dot, for which we will use a SKETCHPAD.\n- A search display, which we will create in Python with a custom INLINE_SCRIPT.\n- Response collection, for which we will use a KEYBOARD_RESPONSE.\n- Data logging, for which we will use a LOGGER.\n- (We also want immediate feedback after each trial, but we will get back to this later.)\n\nSo the only thing that is missing is an INLINE_SCRIPT.\n\n- Insert a new INLINE_SCRIPT after *sketchpad* and rename it to *search_display_script*.\n- Rename *sketchpad* to *fixation_dot*, so that its function is clear; and\n- Change the duration of *fixation_dot* to 500, so that the fixation dot is shown for 500 ms. (There should already be a fixation dot drawn; if not, draw one in the center of *fixation_dot*.)\n\nThe overview area should now look like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The overview area at the end of step 5.\n--%\n\n## Step 6: Generate the search display\n\n__Top-down and defensive programming__\n\nNow things will get interesting: We will start programming in Python. We will use two guiding principles: *top-down* and *defensive* programming.\n\n- *Top-down programming* means that we start with the most abstract logic, without bothering with how this logic is implemented. Once the most abstract logic is in place, we will move down to a slightly less abstract logic, and so on, until we arrive at the details of the implementation. This technique helps to keep the code structured.\n- *Defensive programming* means that we assume that we make mistakes. Therefore, to protect us from ourselves, we build sanity checks into the code.\n\n*Note:* The explanation below assumes that you're somewhat familiar with Python code. If concepts like `list`, `tuple`, and functions don't mean anything to you, then it's best to first walk through an introductory Python tutorial, such as this one:\n\n- <https://pythontutorials.eu/>\n\nThe logic of the code is shown in %FigHierarchy. The numbers indicate the order in which we will implement the functionality, starting at the abstract level.\n\n%--\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  The logic of the code to draw a visual-search display.\n--%\n\n__The Prepare and Run phases__\n\nOpen *search_display_script* and switch to the Prepare tab. OpenSesame distinguishes two phases of execution:\n\n- During the Prepare phase, each item is given the opportunity to prepare itself; what this means depends on the item: For a SKETCHPAD, it means drawing a canvas (but not showing it); for a SAMPLER, it means loading a sound file (but not playing it); etc.\n- During the Run phase, each item is actually executed; again, what this means depends on the item: For a SKETCHPAD, it means showing the previously prepared canvas; for a SAMPLER, it means playing a previously loaded sound file.\n\nFor an INLINE_SCRIPT, you have to decide yourself what to put in the Prepare phase, and what to put in the Run phase. The distinction is usually quite clear: In our case, we put the code for drawing the canvas in the Prepare phase, and the code for showing the canvas (which is small) in the Run phase.\n\nSee also:\n\n- %link:prepare-run%\n\n__Implement the abstract level__\n\nWe start at the most abstract level: defining a function that draws a visual-search display. We don't specify *how* this is done; we simply assume that there is a function that does this, and we will worry about the details later\u2014that's top-down programming.\n\nIn the Prepare tab, enter the following code:\n\n~~~ .python\nc = draw_canvas()\n~~~\n\nWhat happens here? We \u2026\n\n- Call `draw_canvas()`, which returns a `Canvas` object that we store as `c`; in other words, `c` is a `Canvas` object that corresponds the search display. This assumes that there is a function `draw_canvas()`, even though we haven't defined it yet.\n\nA `Canvas` object is a single display; it is, in a sense, the Python counterpart of a SKETCHPAD. See also:\n\n- %link:manual/python/canvas%\n\nWe now go one step down by defining `draw_canvas()` (above the rest of the script so far):\n\n~~~ .python\ndef draw_canvas():\n    \"\"\"Draws the search canvas.\n\n    Returns\n    -------\n    Canvas\n    \"\"\"\n    c = Canvas()\n    xy_list = xy_random(n=set_size, width=500, height=500, min_dist=75)\n    if target_present == 'present':\n        x, y = xy_list.pop()\n        draw_target(c, x, y)\n    elif target_present != 'absent':\n        raise Exception(f'Invalid value for target_present: {target_present}')\n    for x, y in xy_list:\n        draw_distractor(c, x, y)\n    return c\n~~~\n\n\nWhat happens here? We \u2026\n\n- Create an empty canvas, `c`, using the factory function `Canvas()`.\n- Generate a list of random `x, y` coordinates, called `xy_list`, using another common function, `xy_random()`. This list determines where the stimuli are shown.\n- Check if the experimental variable `target_present` has the value 'present'; if so, `pop()` one `x, y` tuple from `xy_list`, and draw the target at this location. This assumes that there is a function `draw_target()`, even though we haven't defined it yet.\n- If `target_present` is neither 'present' nor 'absent', we raise an `Exception`; this is defensive programming, and protects us from typos (e.g. if we had accidentally entered 'presenr' instead of 'present').\n- Loop through all remaining `x, y` tuples and draw a distractor at each position. This assumes that there is a function `draw_distractor()`, even though we haven't defined it yet.\n- Return `c`, which now has the search display drawn onto it.\n\nThere are several common functions, such as `Canvas()` and `xy_random()`, which are always available. See:\n\n- %link:manual/python/common%\n\nExperimental variables are global variables. That's why you can refer to `set_size`, which is defined in *block_loop*, even though the variable `set_size` is never explicitly defined in the script. The same is true for `target_shape`, `target_color`, `condition`, etc. See:\n\n- %link:var%\n\n__Implement the intermediate level__\n\nWe now go one more step down by defining `draw_target` (above the rest of the script so far):\n\n~~~ .python\ndef draw_target(c, x, y):\n    \"\"\"Draws the target.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    draw_shape(c, x, y, color=target_color, shape=target_shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Call another function, `draw_shape()`, and specify the color and shape that needs to be drawn. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nWe also define `draw_distractor` (above the rest of the script so far):\n\n~~~ .python\ndef draw_distractor(c, x, y):\n    \"\"\"Draws a single distractor.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    if condition == 'conjunction':\n        draw_conjunction_distractor(c, x, y)\n    elif condition == 'feature_shape':\n        draw_feature_shape_distractor(c, x, y)\n    elif condition == 'feature_color':\n        draw_feature_color_distractor(c, x, y)\n    else:\n        raise Exception(f'Invalid condition: {condition}')\n~~~\n\nWhat happens here? We \u2026\n\n- Call another function to draw a more specific distractor depending on the Condition.\n- Check whether `condition` has any of the expected values. If not, we raise an `Exception`. This is defensive programming! Without this check, if we made a typo somewhere, the distractor might simply not be shown without causing an error message.\n\nNow we define the function that draws distractors in the Conjunction condition (above the rest of the script so far):\n\n~~~ .python\nimport random\n\n\ndef draw_conjunction_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the conjunction condition: an object that\n    can have any shape and color, but cannot be identical to the target.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    conjunctions = [('yellow', 'circle'),\n                    ('blue',   'circle'),\n                    ('yellow', 'square'),\n                    ('blue',   'square')]\n    conjunctions.remove((target_color, target_shape))\n    color, shape = random.choice(conjunctions)\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Define a list, `conjunctions`, of all possible color and shape combinations.\n- Remove the target from this list; this is necessary, because the distractor cannot be identical to the target.\n- Randomly select one of the color and shape combinations from `conjunctions`.\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nIn addition, we \u2026\n\n- Add the line `import random` to the top of the script. This is necessary so that we can use functions that are part of the `random` module, such as `random.choice()`.\n\nNow we define the function that draws distractors in the Shape Feature condition (right below the `import` statement):\n\n~~~ .python\ndef draw_feature_shape_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the feature-shape condition: an object that\n    has a different shape from the target, but can have any color.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    colors = ['yellow', 'blue']\n    color = random.choice(colors)\n    if target_shape == 'circle':\n        shape = 'square'\n    elif target_shape == 'square':\n        shape = 'circle'\n    else:\n        raise Exception(f'Invalid target_shape: {target_shape}')\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Randomly select a color.\n- Choose a square shape if the target is a circle, and a circle shape if the target is square.\n- If `target_shape` is neither 'circle' nor 'square', raise an `Exception`\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nNow we define the function that draws distractors in the Color Feature condition (right below the `import` statement):\n\n~~~ .python\ndef draw_feature_color_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the feature-color condition: an object that\n    has a different color from the target, but can have any shape.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    shapes = ['circle', 'square']\n    shape = random.choice(shapes)\n    if target_color == 'yellow':\n        color = 'blue'\n    elif target_color == 'blue':\n        color = 'yellow'\n    else:\n        raise Exception(f'Invalid target_color: {target_color}')\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Randomly select a shape.\n- Choose a blue color if the target is yellow, and a yellow color if the target is blue.\n- If `target_color` is neither 'yellow' nor 'blue', raise an `Exception`\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\n__Implement the detailed level__\n\nNow we go all the way down to the details by defining the function that actually draws a shape to the canvas (right below the `import` statement):\n\n~~~ .python\ndef draw_shape(c, x, y, color, shape):\n    \"\"\"Draws a single shape.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    color: str\n    shape: str\n    \"\"\"\n    if shape == 'square':\n        c += Rect(x=x-25, y=y-25, w=50, h=50, color=color, fill=True)\n    elif shape == 'circle':\n        c += Circle(x=x, y=y, r=25, color=color, fill=True)\n    else:\n        raise Exception(f'Invalid shape: {shape}')\n    if color not in ['yellow', 'blue']:\n        raise Exception(f'Invalid color: {color}')\n~~~\n\nWhat happens here? We \u2026\n\n- Check which shape should be drawn. For squares, we add a `Rect()` element to the canvas. For circles, we add a `Circle()` element.\n- Check if the the shape is either a square or a circle, and if not raise an `Exception`. This is another example of defensive programming! We're making sure that we haven't accidentally specified an invalid shape.\n- Check if the the color is neither yellow nor blue, and if not raise an `Exception`.\n\n__Implement the Run phase__\n\nBecause we have done all the hard work in the Prepare phase, the Run phase is just:\n\n~~~ .python\nc.show()\n~~~\n\nThat's it! Now you have drawn a full visual-search display. And, importantly, you have done so in a way that is easy to understand, because of top-down programming, and safe, because of defensive programming.\n\n\n## Step 7: Define the correct response\n\nTo know if the participant responds correctly, we need to know the correct response. You can define this explicitly in the *block_loop* (as done in the beginner tutorial); but here we're going to use a simple Python script that checks whether the target is present or not, and defines the correct response accordingly.\n\nTo do this, insert a new INLINE_SCRIPT at the start of *trial_sequence*, and rename it to *correct_response_script*. In the Prepare phase (not the Run phase!), enter the following code:\n\n~~~ .python\nif target_present == 'present':\n    correct_response = 'right'\nelif target_present == 'absent':\n    correct_response = 'left'\nelse:\n    raise Exception(f'target_present should be absent or present, not {target}')\n~~~\n\nWhat happens here? We \u2026\n\n- Check whether the target is present or not. If the target is present, the correct response is 'right' (the right arrow key); if the target is absent, the correct response is 'left' (the left arrow key). The experimental (global) variable `correct_response` is automatically recognized by *keyboard_response*; therefore, we don't need to explicitly indicate that this variable contains the correct response.\n- Check if the target is either present or absent, and if not raise an `Exception`\u2014another example of defensive programming.\n\n## Step 8: Give per-trial feedback\n\nFeedback after every trial can motivate participants; however, per-trial feedback should not interfere with the flow of the experiment. A good way to give per-trial feedback is to briefly show a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nTo do this:\n\n- Insert two new SKETCHPADs into *trial_sequence*, just after *keyboard_response*.\n- Rename one SKETCHPAD to *green_dot*, draw a central green fixation dot onto it, and change its duration to 500.\n- Rename the other SKETCHPAD to *red_dot*, draw a central red fixation dot onto it, and change its duration to 500.\n\nOf course, only one of the two dots should be shown on each trial. To accomplish this, we will specify run-if expressions in *trial_sequence*:\n\n- Change the run-if expression for *green_dot* to 'correct == 1', indicating that it should only be shown after a correct response.\n- Change the run-if expression for *red_dot* to 'correct == 0', indicating that it should only be shown after an incorrect response.\n\nThe variable `correct` is automatically created if the variable `correct_response` is available; that's why we defined `correct_response` in step 7. For more information about variables and run-if statements, see:\n\n- %link:manual/variables%\n\nThe *trial_sequence* should now look like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n--%\n\n## Finished!\n\nCongratulations, the experiment is complete! You can give it a test run by pressing on the blue double-arrow button (shortcut: `Ctrl+W`).\n\nIf the experiment doesn't work on the first try: Don't worry, and calmly figure out where the mistake comes from. Crashes are part of the normal development process. But you can save yourself a lot of time and headache by working in a structured way, as we have done in this tutorial.\n\n## References\n\n<div class='reference' markdown='1'>\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, 12(1), 97\u2013136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html",
    "title": "Intermediate tutorial (Python) visual search",
    "url": "https://osdoc.cogsci.nl/4.1/tutorials/intermediate",
    "path": "content/pages/tutorials/intermediate.md",
    "topics": [
      "opensesame",
      "inline_script"
    ],
    "collection": "opensesame",
    "foundation": false,
    "howto": false,
    "chunk": 1,
    "total_chunks": 1
  },
  {
    "content": "# Important\n\n- If you need more information to answer the question, ask the user for clarification.\n- Never put variables in conditional (run-if, show-if, break-if) expressions between square brackets. Use Python syntax instead. Correct: `variable_name == 1` Incorrect: `[variable_name] = 1`\n- Remember the distinction between the prepare and the run phase. Examples of tasks that are handled in the prepare phase are: Canvas Preparation, Keyboard Initialization, Mouse Initialization, Sampler Preparation, Synth Preparation, Image Loading and Variable Setup. Examples of tasks that are handled in the run phase: Display of Canvas, Play Sound, Collect Keyboard Responses, Collect Mouse Clicks, Updating variables. Make use of this distinction when providing content for inline_script. \n- In Python and JavaScript: always capitalize the first letter of `Canvas`, `Keyboard`, `Mouse`, `Sampler`, and `Synth`.\n- In Python and JavaScript: never prefix variable names with `var` or `vars` \n- In Python and JavaScript: Avoid usage of the `exp.get()` and `self.set()` methods when initializing, getting or setting variables \n- Experimental variables are globals and can be directly referred to.\n\n\n# Instructions for OpenSesame\n\n- Execute Python code for desktop or laboratory experiments. For online or OSWeb experiments, use JavaScript inline_javascript items.\n- Embed Python in GUI controls as f-strings/ template strings. Example: sketchpad text: `Your response time was {resonse_time} ms`. Example: sampler sound file: `{sound_name}.mp3`\n- inline_script and inline_javascript can be combined with GUI items. Example: show stimulus display with inline_script, collect key press with keyboard_response GUI item\n- The code comments are for you. You don't need to include them verbatim in your responses.\n- Variables defined in loop item are globals in inline_script\n- Don't suggest Python scripts when the question refers to the GUI. Example: don't suggest using a Canvas when the question is about a sketchpad\n- Scripts in GUI items do not support if statements or for loops\n- A sketchpad is a GUI item, and a `Canvas` is a Python object\n- A keyboard_response is a GUI item, and a `Keyboard` is a Python object\n- A mouse_response is a GUI item, and a `Mouse` is a Python object\n- Sampler and Synth can refer to either GUI items or Python objects, depending on the context\n\n\n# Instructions for inline_javascript in OSWeb\n\n- `Canvas` is a function and not a class constructor. Therefore, never use `new` to create `Canvas` objects.\n- There is no JavaScript equivalent of `Keyboard`, `Mouse`, `Sampler`, and `clock`. You can only use this functionality with the corresponding GUI items.\n\n\n# Instructions for Python inline_script\n\n- In Python: use `clock.sleep(millisecond)` instead of `time.sleep(seconds)`\n\n\n# Instructions for conditional expressions\n\n- A run-if expression is used in a sequence to determine whether an item should be executed\n- A show-if expression is used in a sketchpad to determine an element should be shown\n- A break-if expression is used in a loop to determine whether the loop should break\n- Conditional expressions should be syntactically valid Python\n- Do not put square brackets around variables\n- Do not place quotation marks around the numerical values in the run-if or show-if expressions\n\nExample conditional expressions:\n\ncorrect == 1\nresponse_time < 2000 and correct == 1\ncount_trial_sequence % 10 == 1\n\n\n# Built-in variables\n\nThe following variables have a special meaning in OpenSesame. Do not make up your own variable names, but use these variable names whenever they are applicable.\n\nAutomatically set by response items (KEYBOARD_RESPONSE, MOUSE_RESPONSE, etc.):\n\n- `response`: the participant's last response (key name, mouse button, etc.)\n- `response_time`: the response time for the participant's last response in milliseconds\n- `correct`: whether the participant's last respones was correct (1) or not (0)\n- `acc` or `accuracy`: the percentage of correct responses since the last reset of feedback variables\n- `avg_rt` or `average_response_time`: the average response time since the last reset of feedback variables\n\nUsed by response items (KEYBOARD_RESPONSE, MOUSE_RESPONSE, etc.):\n\n- `correct_response`: the expected response, which is often specified in a LOOP, which is used to determine whether the participant's response was correct.\n",
    "title": "Foundation document for opensesame",
    "collection": "opensesame",
    "topic": "opensesame",
    "howto": false,
    "foundation": true
  },
  {
    "content": "\"\"\"\n# Instructions for Python in inline_script\n\n- Stimulus preparation should be done in Prepare phase. Stimulus presentation, response collection, etc. should be done in Run phase. The Prepare and Run phase are tabs in the `inline_script` GUI item. When providing scripts to the user, use the START_PREPARE_PHASE and START_RUN_PHASE comments to clearly indicate what goes where.\n- Canvas, Keyboard, FixDot, Rect, Circle, xy_random, responses, clock, etc. are always available and do not need to be imported.\n- The code comments and the API documentation are for you. You don't need to include this verbatim in your responses.\n- Variables defined in loop item are globals in inline_script\n\n# Canvas class API Reference\n\nCanvas is used for visual stimulus presentation. Create canvases, draw on them, and show them on screen. All drawing methods accept style keywords: `color`, `background_color`, `fill`, `penwidth`, `font_family`, `font_size`, `font_bold`, `font_italic`, `font_underline`, `html`. Colors can be names, hex, RGB tuples, or CSS strings.\n\n## Examples\n```python\n# Basic drawing and display\ncanvas = Canvas()\ncanvas.fixdot(color='black')\ncanvas.circle(0, -100, 50, fill=True, color='red')\ncanvas.text('Hello', y=100, font_size=24)\ntimestamp = canvas.show()\n\n# Named elements with interaction\ncanvas = Canvas()\ncanvas['target'] = Circle(100, 0, 30, color='green')\ncanvas['feedback'] = Text('Click the circle!')\ncanvas.show()\nmouse = Mouse()\nbutton, (x, y), time = mouse.get_click()\nif (x, y) in canvas['target']:\n    canvas['feedback'].text = 'Hit!'\n    canvas.show()\n```\n\n## API\n```python\nCanvas(color=None, background_color=None, **style_args) -> Canvas\ncanvas.line(sx: float, sy: float, ex: float, ey: float, **style_args) -> None\ncanvas.arrow(sx: float, sy: float, ex: float, ey: float, body_length: float = 0.8, body_width: float = 0.5, head_width: float = 30, **style_args) -> None\ncanvas.rect(x: float, y: float, w: float, h: float, **style_args) -> None\ncanvas.circle(x: float, y: float, r: float, **style_args) -> None\ncanvas.ellipse(x: float, y: float, w: float, h: float, **style_args) -> None\ncanvas.polygon(vertices: List[Tuple[float, float]], **style_args) -> None\ncanvas.text(text: str, center: bool = True, x: float = None, y: float = None, max_width: float = None, **style_args) -> None\ncanvas.text_size(text: str, center: bool = True, max_width: float = None, **style_args) -> Tuple[float, float]\ncanvas.image(fname: str, center: bool = True, x: float = None, y: float = None, scale: float = None, rotation: float = None) -> None\ncanvas.fixdot(x: float = None, y: float = None, style: str = 'default', **style_args) -> None\ncanvas.gabor(x: float, y: float, orient: float, freq: float, env: str = 'gaussian', size: int = 96, stdev: float = 12, phase: float = 0, col1: str = 'white', col2: str = 'black', bgmode: str = 'avg') -> None\ncanvas.noise_patch(x: float, y: float, env: str = 'gaussian', size: int = 96, stdev: float = 12, col1: str = 'white', col2: str = 'black', bgmode: str = 'avg') -> None\ncanvas.show() -> float\ncanvas.prepare() -> None\ncanvas.clear(**style_args) -> None\ncanvas.elements_at(x: float, y: float) -> List[Element]\ncanvas.width: int\ncanvas.height: int\ncanvas.size: Tuple[int, int]\n```\n\n# Keyboard Class API Reference\n\nKeyboard collects key presses from participants. Create instances with `Keyboard()`. Response keywords `timeout` and `keylist` can be passed to constructor or methods. Key names are case-insensitive and include letters, numbers, arrow keys ('up', 'down', 'left', 'right'), and special keys ('space', 'return', 'escape').\n\n## Examples\n```python\n# Basic response collection\nkb = Keyboard()\nstart_time = clock.time()\nkey, end_time = kb.get_key()\nrt = end_time - start_time\n\n# Multiple choice with timeout\nkb = Keyboard(keylist=['1', '2', '3'], timeout=5000)\nkey, time = kb.get_key()\nif key is None:\n    print('No response!')\n\n# Check modifiers\nkey, time = kb.get_key()\nif 'shift' in kb.get_mods():\n    print('Shift was pressed!')\n```\n\n## API\n```python\nKeyboard(timeout: int = None, keylist: List[str] = None) -> Keyboard\nkeyboard.get_key(**resp_args) -> Tuple[str, float]\nkeyboard.get_key_release(**resp_args) -> Tuple[str, float]\nkeyboard.get_mods() -> List[str]\nkeyboard.flush() -> bool\nkeyboard.timeout: int\nkeyboard.keylist: List[str]\n```\n\n# Mouse Class API Reference\n\nMouse collects mouse input including clicks, position, and button states. Create instances with `Mouse()`. Button numbers: 1=left, 2=middle, 3=right, 4=scroll up, 5=scroll down. Response keywords: `timeout`, `buttonlist`, `visible`.\n\n## Examples\n```python\n# Get click with coordinates\nmouse = Mouse()\nbutton, (x, y), timestamp = mouse.get_click()\nprint(f'Clicked button {button} at ({x}, {y})')\n\n# Track cursor movement\nmouse = Mouse()\ncanvas = Canvas()\nfor t in clock.loop_for(5000):\n    (x, y), timestamp = mouse.get_pos()\n    canvas.clear()\n    canvas.fixdot(x, y)\n    canvas.show()\n```\n\n## API\n```python\nMouse(timeout: int = None, buttonlist: List[int] = None) -> Mouse\nmouse.get_click(**resp_args) -> Tuple[int, Tuple[float, float], float]\nmouse.get_click_release(**resp_args) -> Tuple[int, Tuple[float, float], float]\nmouse.get_pos() -> Tuple[Tuple[float, float], float]\nmouse.get_pressed() -> Tuple[bool, bool, bool]\nmouse.flush() -> bool\nmouse.show_cursor(show: bool = True) -> None\nmouse.set_pos(pos: Tuple[float, float] = (0, 0)) -> None\nmouse.synonyms(button: Union[int, str]) -> List[Union[int, str]]\n```\n\n# Sampler Class API Reference\n\nSampler plays sound files from the file pool. Supports WAV, MP3, and OGG formats. Playback keywords: `volume` (0-1), `pitch` (speed multiplier), `pan` (-1 to 1), `duration` (ms), `fade_in` (ms), `block` (bool).\n\n## Examples\n```python\n# Play a sound\nsound = Sampler(pool['beep.wav'])\nsound.play()\n\n# Background music with control\nmusic = Sampler(pool['music.ogg'], volume=0.3)\nmusic.play(block=False)\nclock.sleep(5000)\nmusic.stop()\n\n# Stereo and pitch effects\nsound = Sampler(pool['tone.wav'])\nsound.play(pan='left', pitch=1.5)\n```\n\n## API\n```python\nSampler(src: str, **playback_args) -> Sampler\nsampler.play(**playback_args) -> None\nsampler.stop() -> None\nsampler.pause() -> None\nsampler.resume() -> None\nsampler.is_playing() -> bool\nsampler.wait() -> None\nsampler.volume: float\nsampler.pitch: float\nsampler.pan: float\nsampler.duration: float\nsampler.fade_in: float\nsampler.block: bool\n```\n\n# clock Object API Reference\n\nThe `clock` singleton provides timing functions. All times are in milliseconds.\n\n## Examples\n```python\n# Measure reaction time\nt0 = clock.time()\nresponse = get_response()\nrt = clock.time() - t0\n\n# Create timed displays\nfixation.show()\nclock.sleep(500)\nstimulus.show()\n\n# Implement timeout\nfor ms in clock.loop_for(5000):\n    if keyboard.get_key()[0] is not None:\n        print(f'Response at {ms} ms')\n        break\n```\n\n## API\n```python\nclock.time() -> float\nclock.sleep(ms: float) -> None\nclock.loop_for(ms: float, throttle: float = None, t0: float = None) -> Iterator[float]\nclock.once_in_a_while(ms: float = 1000) -> bool\n```\n\n# log Object API Reference\n\nThe `log` singleton handles data logging to files. Write individual messages or all experiment variables.\n\n## Examples\n```python\n# Write all variables (like logger item)\nlog.write_vars()\n\n# Write specific variables\nlog.write_vars(['response_time', 'correct', 'subject_nr'])\n\n# Write custom messages\nlog('Trial started')\nlog.write(f'RT: {rt}')\n```\n\n## API\n```python\nlog.write(msg: str, newline: bool = True) -> None\nlog.write_vars(var_list: List[str] = None) -> None\nlog.open(path: str) -> None\nlog.close() -> None\nlog(msg: str) -> None\n```\n\n# responses Object API Reference\n\nThe `responses` singleton stores response history and calculates accuracy/RT feedback. Responses are stored in reverse chronological order (newest first). Adding responses automatically updates variables like `var.response`, `var.correct`, `var.acc`, and `var.avg_rt`.\n\n## Examples\n```python\n# Add a response\nkb = Keyboard()\nstart = clock.time()\nkey, end = kb.get_key()\ncorrect = 1 if key == var.correct_response else 0\nresponses.add(response=key, correct=correct, response_time=end-start)\n\n# Check performance\nprint(f\"Accuracy: {var.acc}%\")\n\n# Analyze recent responses\nfor r in responses[:10]:\n    if r.correct == 1 and r.response_time < 500:\n        print(\"Fast correct!\")\n```\n\n## API\n```python\nresponses.add(response=None, correct: int = None, response_time: float = None, item: str = None, feedback: bool = True) -> None\nresponses.clear() -> None\nresponses.reset_feedback() -> None\nlen(responses) -> int\nresponses[index] -> Response\nfor response in responses: ...\nresponse.response: Any\nresponse.correct: int\nresponse.response_time: float\nresponse.item: str\nresponse.feedback: bool\n```\n\n# pool Object API Reference\n\nThe `pool` singleton provides dict-like access to the file pool. Files can be in the temporary pool folder or the __pool__ subfolder of the experiment.\n\n## Examples\n```python\n# Get file paths\nimage_path = pool['stimulus.png']\nsound_path = pool['beep.wav']\n\n# Check existence\nif 'image.png' in pool:\n    canvas.image(pool['image.png'])\n\n# Add external file\npool.add('/home/user/photo.jpg', 'stimulus.jpg')\n```\n\n## API\n```python\npool[filename: str] -> str\nfilename in pool -> bool\ndel pool[filename] -> None\nlen(pool) -> int\nfor filename in pool: ...\npool.add(path: str, new_name: str = None) -> None\npool.rename(old_path: str, new_path: str) -> None\npool.folder() -> str\npool.folders(include_fallback_folder: bool = True, include_experiment_path: bool = False) -> List[str]\npool.fallback_folder() -> str\npool.files() -> List[str]\npool.size() -> int\npool.in_folder(path: str) -> bool\n```\n\n# Miscellaneous Functions API Reference\n\n# Synthesize a tone and return it as a Sampler object.\nSynth(osc: Literal['sine','saw','square','white_noise'] = 'sine', freq: Union[int, str] = 440, length: int = 100, attack: int = 0, decay: int = 5, **playback_args) -> Sampler\n# Return a copy of a sketchpad's canvas by the item name.\ncopy_sketchpad(name: str) -> Canvas\n# Pause the experiment until externally resumed.\npause() -> None\n# Register a function to be executed after the experiment ends (incl. crashes).\nregister_cleanup_function(fnc: Callable[[], None]) -> None\n# Reset all feedback variables to their initial values.\nreset_feedback() -> None\n# Set the subject number and derived parity (even/odd).\nset_subject_nr(nr: int) -> None\n# Return True with probability p.\nsometimes(p: float = 0.5) -> bool\n# Generate n (x,y) coordinates arranged on a circle.\nxy_circle(n: int, rho: float, phi0: float = 0, pole: Tuple[float, float] = (0, 0)) -> List[Tuple[float, float]]\n# Compute Euclidean distance between two points.\nxy_distance(x1: float, y1: float, x2: float, y2: float) -> float\n# Convert polar (rho, phi\u00b0 clockwise) to Cartesian (x,y).\nxy_from_polar(rho: float, phi: float, pole: Tuple[float, float] = (0, 0)) -> Tuple[float, float]\n# Generate (x,y) coordinates in a grid arrangement.\nxy_grid(n: Union[int, Tuple[int, int]], spacing: Union[float, Tuple[float, float]], pole: Tuple[float, float] = (0, 0)) -> List[Tuple[float, float]]\n# Generate n random (x,y) coordinates with a minimum inter-point distance.\nxy_random(n: int, width: float, height: float, min_dist: float = 0, pole: Tuple[float, float] = (0, 0)) -> List[Tuple[float, float]]\n# Convert Cartesian (x,y) to polar (rho, phi counterclockwise).\nxy_to_polar(x: float, y: float, pole: Tuple[float, float] = (0, 0)) -> Tuple[float, float]\n\"\"\"\n# START_PREPARE_PHASE\nsearch_canvas = Canvas()  # Uppercase. Never pass exp parameter. Do not import from openexp.\nsearch_canvas += FixDot()\nfor x, y in xy_random(6, width=200, height=200, min_dist=40):  # 6 random coordinates within a 200x200 area\n    search_canvas += Rect(x=x-10, y=y+10, w=20, h=20, fill=True)\nmy_keyboard = Keyboard(keylist=['z', 'm'], timeout=2000)  # Uppercase. Never pass exp parameter. Only accept z or m. Timeout after 200 ms.\n# END_PREPARE_PHASE\n# START_RUN_PHASE\nt0 = search_canvas.show()\nkey, t1 = my_keyboard.get_key()  # key is `None` when a timeout occurs\nresponse_time = t1 - t0\ncorrect = 1 if key == correct_response else 0  # Assumes that the expected (or correct) response is defined as `correct_response`\nresponses.add(response=key, correct=correct, response_time=response_time)  # Remember the response\n# END_RUN_PHASE",
    "title": "Foundation document for inline_script",
    "collection": "opensesame",
    "topic": "inline_script",
    "howto": false,
    "foundation": true
  },
  {
    "content": "/**\n# Instuctions for JavaScript in inline_javascript\n\n- Stimulus preparation should be done in Prepare phase. Stimulus presentation, response collection, etc. should be done in Run phase. The Prepare and Run phase are tabs in the `inline_javascript` GUI item.\nJavaScript in the GUI:\n- The code comments are for you. You don't need to include them verbatim in your responses.\n- The following classes and objects are not available in `inline_javscript`: Keyboard, Mouse, Sampler, clock. Instead, use equivalent functionality in the GUI.\n**/\n// START_EXAMPLE: randomly positioned rectangles\n// Related terms: visual search\n// START_PREPARE_PHASE\nvar search_canvas = Canvas()  // Don't use `new`. Define with `var` to make object globally available\nsearch_canvas.fixdot()\nfor (let [x, y] of xy_random(6, 200, 200, 40)) {  // 6 random coordinates within a 200x200 area and a minimum distance of 40\n    search_canvas.rect({x:x-10, y:y+10, w:20, h:20, fill:true})  // pass parameters as object\n}\n// END_PREPARE_PHASE\n// START_RUN_PHASE\nsearch_canvas.show()\n// END_RUN_PHASE\n// END_EXAMPLE\n\n// START_EXAMPLE: circles in a circular arrangement\n// Related terms: visual search, additional singleton\n// START_PREPARE_PHASE\nvar search_canvas = Canvas()\nsearch_canvas.fixdot()\ntarget_index = random.integer(5, 0)  // randomly select target position with random-ext package\nlet color\nfor (let [index, [x, y]] of enumerate(xy_circle(6, rho=200))) {  // 6 coordinates in a circle. Use enumerate from pythonic package\n    color = (index === target_index ? 'red' : 'blue')\n    search_canvas.rect({x:x-10, y:y+10, w:20, h:20, fill:true, color:color})\n}\n// END_PREPARE_PHASE\n// END_EXAMPLE\n\n// START_EXAMPLE: bilateral display with images on left and right0\n// START_PREPARE_PHASE\nvar target_canvas = Canvas()\ntarget_canvas.fixdot()\ntarget_canvas.image({fname:left_img, x:-200})  // Assume that `left_img` and `right_img` contain names to files in the file pool\ntarget_canvas.image({fname:left_img, x:200})\n// END_PREPARE_PHASE\n// END_EXAMPLE\n\n// START_EXAMPLE: cueing paradigm with delay between cue and target\n// Related terms: spatial cuing, posner task, symbolic cuing\n// START_PREPARE_PHASE\nvar cue_canvas = Canvas()\nvar arrow_direction = (cue_side == 'left' ? -20 : 20)\ncue_canvas.arrow({sx:20, sy:0, ex:arrow_direction, ey:0})\nvar blank_canvas = Canvas()\nblank_canvas.fixdot()\nvar target_canvas = Canvas()\ntarget_canvas.fixdot()\nvar target_x = (cue === 'valid' ? (cue_side === 'left' ? -200 : 200) : (cue_side === 'left' ? 200 : -200))\ntarget_canvas.circle({x:target_x, y:0, r:20, fill:true})\n// END_PREPARE_PHASE\n// START_RUN_PHASE\ncue_canvas.show()\nsetTimeout(function() {  // use setTimeout because there is no clock.sleep() in javascript\n    blank_canvas.show()\n    setTimeout(target_canvas.show(), 195)\n}, 95)\n// END_RUN_PHASE\n// END_EXAMPLE\n\n// START_EXAMPLE: rapid serial visual presentation (RSVP) with dynamic display\n// Related term: attentional blink\n// START_RUN_PHASE\nconst ascii_uppercase = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\nvar letters = random.subArray([...ascii_uppercase], 6)\nvar t_list = []\nvar delay = 0\nletters.forEach(function(letter) {  // use forEach and setTimeout because you cannot use a loop and clock.sleep() in JavaScript\n    setTimeout(function() {\n        var rsvp_canvas = Canvas()\n        rsvp_canvas.text({text:letter})\n        var t = rsvp_canvas.show()\n        t_list.push(t)\n    }, delay)\n    delay += 95\n})\n// END_RUN_PHASE\n// END_EXAMPLE\n\n// START_EXAMPLE: random functions\nvar randomLetter = random.pick([\"a\", \"b\", \"c\"])\nvar array = [1, 2, 3, 4, 5, 6, 7, 8, 9]\nrandom.shuffle(array)  // shuffles in-place\nvar subArray = random.subArray(array, 4)  // randomly pick 4 elements\nvar randomColor = random.color()  // hex color\nvar randInt = random.integer(9, 0)  // max(inclusive), min\nvar randFloat = random.float(9, 0)  // limit, min\n// END_EXAMPLE\n",
    "title": "Foundation document for inline_javascript",
    "collection": "opensesame",
    "topic": "inline_javascript",
    "howto": false,
    "foundation": true
  },
  {
    "content": "# How to switch between different backends in OpenSesame\n\nIn OpenSesame, the backend is the software library that is used to run the experiment. To switch between different backends in OpenSesame:\n\n1. Open your experiment script in OpenSesame.\n2. Open the Experiment Properties tab by clicking on the top-level item in the overview area.\n3. Locate the \"Run experiment\" option.\n4. Select the desired backend:\n    - On the desktop with PsychoPy (psycho)\n    - On the desktop with Expyriment (xpyriment)\n    - On the desktop with PyGame (legacy)\n    - In a browser with OSWeb (osweb)\n5. Save your experiment and run it to test if the experiment works as expected.",
    "title": "How to switch between different backends in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to diagnose and fix crash issues in OpenSesame\n\nTo diagnose and fix crash issues in OpenSesame:\n\n1. Run your experiment script in OpenSesame with the debug window open (View > Show console).\n2. When the crash occurs, check the console for any error messages or tracebacks that can help identify the cause of the crash.\n3. If an error message is displayed, search for the error online in the OpenSesame documentation, forums, or general programming resources to find potential solutions.\n4. Review your experiment script for any syntax errors, incorrect variable names, or other coding issues that may be causing the crash.\n5. Try running your experiment script with a different backend or on a different computer to see if the crash is specific to a particular setup.",
    "title": "How to diagnose and fix crash issues in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to optimize audio playback in OpenSesame\n\nTo optimize audio playback in OpenSesame:\n\n1. Ensure that your audio files are in a compatible format (e.g., .wav or .ogg) and have appropriate sample rates and bit depths.\n2. Use the \"sampler\" item in OpenSesame to play audio files.\n3. Adjust the \"duration\", \"fade_in\", and other properties of the sampler item to fine-tune the audio playback timing and onset.\n5. Test your experiment script on different computers and audio setups to ensure consistent playback across various environments.",
    "title": "How to optimize audio playback in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to randomly select an image from a list in an inline_script an show it in a SKETCHPAD\n\nTo randomly select an image from a predefined list in an inline_script:\n\n1. In an INLINE_SCRIPT item, create a list of image file names, e.g., `image_list = [\"image1.png\", \"image2.png\", \"image3.png\"]`\n2. Use `random.choice(image_list)` to randomly select an image file name from the list\n3. Store the randomly selected image file name in an experimental variable, e.g., `chosen_image = random.choice(image_list)`\n4. In a SKETCHPAD item, draw a dummy image (which can be anything)\n4. Edit the script of the SKETCHPAD and use the `chosen_image` variable for the `file` keyword:\n    ```\n    draw image center=1 file=\"{chosen_image}\" scale=1 show_if=True x=0 y=0 z_index=0\n    ```",
    "title": "How to randomly select an image from a list in an inline_script an show it in a SKETCHPAD",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to properly display accented characters in OpenSesame\n\nTo properly display accented characters in OpenSesame:\n\n1. If you are reading text from a text file, such as the source file for a LOOP item, ensure that the file (e.g., CSV) is saved with UTF-8 encoding.\n2. When displaying the text, use a font that supports the required character set. The default Sans font in OpenSesame supports most accented characters.\n3. Run the experiment and verify that the accented characters are displayed correctly.",
    "title": "How to properly display accented characters in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to use HTML formatting to display special characters in OpenSesame\n\nTo use HTML formatting to display special characters in OpenSesame:\n\n1. Convert the accented characters in your text to their HTML entity equivalents. For example, '\u00e9' becomes `&eacute;`, '\u00e2' becomes `&acirc;`, '\u00e7' becomes `&ccedil;`, etc.\n2. When displaying the text, enable HTML formatting by setting the `html` parameter to `yes`. For example, in a SKETCHPAD item: `draw textline 0 0 \"Expos&eacute;\" html=yes`.\n3. Run the experiment and verify that the special characters are displayed correctly using the HTML formatting.",
    "title": "How to use HTML formatting to display special characters in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to create two blocks of questions and randomize the order within each block in OpenSesame\n\nTo create two blocks of questions and randomize the order within each block in OpenSesame:\n\n1. Create a LOOP item for each block of questions (e.g., \"block1_loop\" and \"block2_loop\").\n2. Within the table of each LOOP item, add a column called `question`. \n3. Add all questions to the `question` column.\n4. In the LOOP item's properties, set the \"Order\" field to \"random\" to randomize the order of questions within the block.\n5. Inside the loop, create a trial sequence that presents the question to the participant, for example using a `form_text_input` item.\n5. Create a SEQUENCE item to contain the two LOOP items.\n6. Add the LOOP items to the SEQUENCE in the desired order of the blocks.",
    "title": "How to create two blocks of questions and randomize the order within each block in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to record the start time of a trial in OpenSesame\n\nIf your trial corresponds to an item called trial_sequence, the start time of a trial is available as the variable `time_trial_sequence`.\n\nIf the start of a trial corresponds to another event, you need to manually register it as follows:\n\n1. Create an `inline_script` item at the beginning of your trial sequence.\n2. In the `inline_script`, use the `clock.time()` function to get the current time in seconds (e.g., `start_time = clock.time()`).\n3. Use the stored start time variable in subsequent items or calculations as needed.",
    "title": "How to record the start time of a trial in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to measure response times in a custom FORM_BASE item\n\nTo measure response times for each option in a custom FORM_BASE item:\n\n1. FORM_BASE items don't automatically record a response time, so you need to manually track it.\n2. Insert a FORM_BASE item into your experiment. Let's assume it's called `my_form`.\n3. Insert an INLINE_SCRIPT item after the my_form.\n4. In the run phase of the INLINE_SCRIPT, calculate the response time by subtracting the onset time of `my_form` from the current time, like so:\n    ```python\n    response_time = clock.time() - time_my_form\n    ```",
    "title": "How to measure response times in a custom FORM_BASE item",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to log complex data types in OpenSesame\n\nBy default, the LOGGER only logs simple data types (`int`, `float`, `str`, `bytes`, `None`). This is to avoid the log file from being polluted by complex data types, which are often not intended for logging. However, in some cases you may want to also log complex data types. You can do this by explicitly entering the name of the to-be-logged variable in the Include field of the LOGGER item. Always check that your variables are logged correctly!",
    "title": "How to log complex data types in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to set the color of a Rectangle element on a Canvas\n\nTo set the color of a Rectangle element on a Canvas:\n\n1. In an inline_script item, create a Canvas object using `my_canvas = Canvas()`.\n2. Add a Rectangle element to the Canvas using `my_canvas['rect'] = Rect(x, y, w, h)`, specifying the position and size.\n3. Set the color property of the Rectangle element directly in the constructor: `my_canvas['rect'] = Rect(x, y, w, h, color='red')`.\n4. If needed, modify the color after the Rectangle element has been created using the `color` attribute: `my_canvas['rect'].color = 'blue'`.\n5. Call `my_canvas.show()` to display the Canvas with the colored Rectangle.",
    "title": "How to set the color of a Rectangle element on a Canvas",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to modify properties of Canvas elements after creation\n\nTo modify properties of Canvas elements after creation:\n\n1. Create a Canvas object and add elements to it, assigning them unique names.\n2. Access the desired element using its name, like `my_canvas['element_name']`.\n3. Modify the element's properties using dot notation, e.g., `my_canvas['circle'].radius = 50`.\n4. Update other properties such as position, color, or visibility in a similar manner.\n5. Redraw the Canvas using `my_canvas.show()` to reflect the changes.",
    "title": "How to modify properties of Canvas elements after creation",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to animate Canvas elements using Python inline_script\n\nTo animate Canvas elements using Python inline_script:\n\n1. Create a Canvas object and add the elements you want to animate.\n2. Use a `for` loop to update the properties of the elements incrementally.\n3. Call `my_canvas.show()` within the loop to redraw the Canvas after each update.\n4. Use `clock.sleep()` to introduce a small delay between each frame of the animation.\n5. Adjust the loop range and property changes to control the duration and behavior of the animation.",
    "title": "How to animate Canvas elements using Python inline_script",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to create complex shapes and patterns on a Canvas\n\nTo create complex shapes and patterns on a Canvas:\n\n1. Break down the desired shape or pattern into simpler components, such as lines, circles, or polygons.\n2. Create individual elements for each component using the appropriate Canvas element types (Line, Polygon, etc.).\n3. Position and style the elements to form the desired shape or pattern.\n4. Use loops and mathematical functions to generate repetitive or symmetrical patterns programmatically.\n5. Combine multiple Canvas elements to build more intricate designs or illustrations.",
    "title": "How to create complex shapes and patterns on a Canvas",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to collect gaze data continuously in an eye-tracking experiment\n\nMost eye trackers, such as the EyeLink, write gaze data automatically to a log file, in which case there is no need to write gaze data to a file yourself. However, if you do need to collect gaze data continuously in an eye-tracking experiment, you can do this as follows:\n\n1. Initialize the eye tracker using the PYGAZE_INIT item.\n2. Start recording eye movements using the PYGAZE_START_RECORDING item.\n3. Create a loop that continuously retrieves the current gaze position using the `eyetracker.sample()` function.\n4. Store the gaze data in a list or write it to a file within the loop.\n5. Break the loop when a specific condition is met, such as a button press or a time limit.\n6. Stop recording eye movements using the PYGAZE_STOP_RECORDING item.\n7. Analyze the collected gaze data as needed.\n\nExample:\n\n```python\nmy_keyboard = Keyboard(timeout=0)\nmy_gaze_data = []\nwhile True:\n    # the eyetracker object is created by PYGAZE_INIT\n    # eyetracker.sample() returns a tuple of x and y coordinates\n    xy = eyetracker.sample()  \n    my_gaze_data.append(xy)\n    key, timestamp = my_keyboard.get_key()\n    if key is not None:\n        break\n```",
    "title": "How to collect gaze data continuously in an eye-tracking experiment",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to trigger an event based on gaze position\n\nTo trigger an event, such as displaying a SKETCHPAD, based on gaze position:\n\n1. Initialize the eye tracker using the PYGAZE_INIT item.\n3. Start recording eye movements using the PYGAZE_START_RECORDING item.\n2. Show a SKETCHPAD (or Canvas) in which the target area of interest (AOI) is defined as a named element.\n5. Use an INLINE_SCRIPT to wait until gaze position falls within the target AOI or until a timeout expired.\n    ```python\n    TIMEOUT = 5000\n    TARGET_AOI = 'my_target_aoi'  # needs to match the name of an element on a SKETCHPAD or Canvas\n    t0 = clock.time()\n    my_canvas = items['my_sketchpad'].canvas  # use the canvas from the SKETCHPAD item that contains the target AOI\n    while True:\n        x, y = eyetracker.sample()\n        # Eye-tracking data uses 0, 0 for the top-left. OpenSesame use 0,0 for the display center. We need to correct for this.\n        x += my_canvas.left\n        y += my_canvas.top\n        # Check if gaze falls within the target area of interest\n        if (x, y) in my_canvas[TARGET_AOI]:\n            print('gaze on target!')\n            break\n        # Also include a timeout to avoid the experiment from freezing indefinitely\n        if clock.time() - t0 >= TIMEOUT:\n            print('timeout occurred!')\n            break\n    ```\n6. Show another SKETCHPAD, or implement some other event that should be triggered based on gaze position.\n7. Stop recording eye movements using the PYGAZE_STOP_RECORDING item.",
    "title": "How to trigger an event based on gaze position",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to navigate the overview area efficiently in a large experiment\n\nTo navigate the overview area efficiently in a large experiment:\n\n1. Use the scroll wheel on your mouse to quickly scroll through the items in the overview area.\n2. Click and hold the scroll bar's thumb (the draggable part of the scroll bar) to quickly jump to a specific section of the overview area.\n3. Use the arrow keys on your keyboard to move the selection up or down one item at a time in the overview area.\n4. Press the \"Home\" key to jump to the top of the overview area, and press the \"End\" key to jump to the bottom.\n5. Collapse items that you are not currently working on by clicking the expand/collapse symbol next to the item name. This will reduce the amount of scrolling needed.",
    "title": "How to navigate the overview area efficiently in a large experiment",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to optimize OpenSesame's usability for large experiments\n\nTo optimize OpenSesame's performance for large experiments:\n\n1. Break your experiment into smaller, more manageable parts by using linked copies of items and sequences.\n2. Use keyboard shortcuts to quickly navigate and edit items in your experiment (e.g., \"Ctrl+C\" to copy, \"Ctrl+V\" to paste, \"Ctrl+S\" to save).",
    "title": "How to optimize OpenSesame's usability for large experiments",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to use the search function to find specific items in a large experiment\n\nTo use the search function to find specific items in a large experiment:\n\n1. Press \"Ctrl+Space\" to open the item quick switcher.\n2. Type the name or part of the name of the item you are looking for in the search bar.\n3. Press \"Enter\" or click the search button to highlight the first occurrence of the search term in the overview area.",
    "title": "How to use the search function to find specific items in a large experiment",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to use the item toolbar to quickly add items to your experiment\n\nTo use the item toolbar to quickly add items to your experiment:\n\n1. Locate the item toolbar. It is typically on the right side of the OpenSesame window, although the position can be changed.\n2. Click and drag the desired item, such as a `keyboard_response` or `sketchpad`, from the item toolbar to the appropriate location in the overview area.\n3. Release the mouse button to add the item to your experiment.\n4. The properties of the new item will be automatically opened.",
    "title": "How to use the item toolbar to quickly add items to your experiment",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to use the undo and redo functions to revert changes in your experiment\n\nTo use the undo and redo functions to revert changes in your experiment:\n\n1. Make changes to your experiment, such as moving or editing items.\n2. Press \"Alt+Ctrl+Z\" or click the \"Undo\" button in the main toolbar to revert the last change you made.\n3. Press \"Alt+Ctrl+Z\" multiple times to undo additional changes in the reverse order that you made them.\n4. Press \"Alt+Ctrl+Shift+Z\" or click the \"Redo\" button in the main toolbar to reapply a change that you previously undid.\n5. Press \"Alt+Ctrl+Shift+Z\" multiple times to redo additional changes in the order that you originally made them.",
    "title": "How to use the undo and redo functions to revert changes in your experiment",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to show or hid the mouse cursor in OSWeb\n\nTo make the mouse cursor visible or invisible in OSWeb:\n\n1. Insert an inline_javascript at the location where you want to make the mouse cursor visible.\n2. In the run phase of this inline_javascript item, use the following script to change the visibility of the mouse cursor\n   ```javascript\n   // To make the cursor visible\n   runner._renderer.view.style.cursor = 'default'\n   // To hide the cursor\n   runner._renderer.view.style.cursor = 'none'\n   ```\n   \nImportant note: this script directly accesses the OSWeb internals, which may break in future versions of OSWeb.",
    "title": "How to show or hid the mouse cursor in OSWeb",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to create a custom mouse-tracking task in OSWeb\n\nTo create a custom mouse-tracking task using JavaScript in OSWeb:\n\n1. Create a new inline_javascript item in your experiment.\n2. In the prepare phase of the inline_javascript item, set up the necessary variables and functions for your mouse-tracking task. For example:\n   ```javascript\n   var startTime;\n   var mousePositions = [];\n   \n   function recordMousePosition(e) {\n     var currentTime = new Date().getTime();\n     var elapsedTime = currentTime - startTime;\n     mousePositions.push({x: e.clientX, y: e.clientY, time: elapsedTime});\n   }\n   ```\n3. In the run phase of the inline_javascript item, attach the `recordMousePosition` function to the `mousemove` event listener:\n   ```javascript\n   document.addEventListener('mousemove', recordMousePosition);\n   startTime = new Date().getTime();\n   ```\n4. Present your stimuli and perform any necessary task-specific logic in the run phase.\n5. When the task is complete, in the run phase of another inline_javascript item, remove the event listener and save the recorded mouse positions by assigning it as a string to a global variable (`mouse_positions`), which will be logged by the LOGGER item.\n   ```javascript\n   document.removeEventListener('mousemove', recordMousePosition);\n   mouse_positions = JSON.stringify(mousePositions);\n   ```\n6. Save the changes to the experiment script.\n7. Run the experiment to test the custom mouse-tracking task.",
    "title": "How to create a custom mouse-tracking task in OSWeb",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to display the mouse coordinates in real-time in OSWeb\n\nTo display the mouse coordinates in real-time using JavaScript in OSWeb:\n\n1. Create a new inline_javascript item in your experiment.\n2. In the prepare phase of the inline_javascript item, create a text element to display the mouse coordinates:\n   ```javascript\n   var coordinatesDisplay = document.createElement('div');\n   coordinatesDisplay.style.position = 'absolute';\n   coordinatesDisplay.style.top = '10px';\n   coordinatesDisplay.style.left = '10px';\n   coordinatesDisplay.style.fontSize = '16px';\n   document.body.appendChild(coordinatesDisplay);\n   ```\n3. In the same script, attach a function to the `mousemove` event listener to update the coordinates display:\n   ```javascript\n   document.addEventListener('mousemove', function(e) {\n     coordinatesDisplay.innerHTML = 'X: ' + e.clientX + ', Y: ' + e.clientY;\n   });\n   ```\n4. Optionally, you can customize the appearance of the coordinates display by modifying the CSS styles in the prepare phase.\n5. Save the changes to the experiment script.\n6. The mouse coordinates are now shown continuously in the top left of the browser window.",
    "title": "How to display the mouse coordinates in real-time in OSWeb",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to set up a Tobii eye tracker in OpenSesame\n\nTo set up a Tobii eye tracker in OpenSesame:\n\n1. Install the necessary Tobii drivers and software on your computer.\n2. Install the `tobii-research` Python library. This library may require a specific version of Python, which may be different from the version of Python that OpenSesame uses. If that is the case, you will need to build a custom Python environment, for example using Anaconda. Consult the OpenSesame documentation for instructions.\n3. In OpenSesame, add a PYGAZE_INIT item to the start of your experiment.\n4. In the PYGAZE_INIT item properties, select \"Tobii\" as the eye tracker type.\n5. Configure the Tobii settings according to your preferences and hardware setup.\n6. Add a PYGAZE_START_RECORDING item before the trial sequence to start recording eye tracking data.\n7. Add a PYGAZE_LOG item at the end of the trial sequence to log experimental variables to the log file.\n8. Add a PYGAZE_STOP_RECORDING item after the trial sequence to stop recording eye tracking data.\n9. You can also use the 'Eye tracking template', which already contains the basic structure of an eye-tracking experiment.",
    "title": "How to set up a Tobii eye tracker in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to log eye tracking data in OpenSesame\n\nTo log eye-tracking data in OpenSesame:\n\n1. Set up your eye tracker using the PYGAZE_INIT item.\n2. Add a PYGAZE_LOG item at the points in your experiment where you want to log eye tracking data.\n3. It is often useful to log the start of epochs or phases during the trial, for example by logging the text 'start_phase cue' immediately after the presentation of a cue stimulus.\n4. It is also important to log experimental variables to the eye-tracking data. You can do this by specifying individual variables to log in PYGAZE_LOG on separate lines (for example `var cue {cue}`). You can also enabled the 'Automatically log all variables' option.\n5. Alternatively, you can use the `eyetracker.log()` function in INLINE_SCRIPT items to log text to the eye-tracking log file.\n6. OpenSesame will now log all relevant information to the eye-tracking log file.",
    "title": "How to log eye tracking data in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to analyze eye-tracking data that was collected with OpenSesame\n\nThere is no standard format for eye-tracking data, and no standard way to analyze eye-tracking data. Therefore, it is important to think about how you intend to analyze the data already during the design of the experiment, because the analysis pipeline determines which information needs to be written to the eye-tracking log file.\n\nFor example, if you intend to use the Python `eyelinkparser` library, you need to send messages that follow the conventions of the `eyelinkparser`, which you can find in the documentation of that package.\n\nSimilarly, if you intend to use the SR Research DataViewer application, you need to send messages that follow the conventions of the DataViewer.",
    "title": "How to analyze eye-tracking data that was collected with OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to change the color theme in OpenSesame\n\nTo change the color theme in OpenSesame:\n\n1. Go to Menu \u2192 Tools \u2192 Preferences.\n2. In the Preferences window, select the 'Common settings' tab.\n3. In the section 'Application appearance', under 'Color theme', choose your desired color theme from the dropdown menu.\n4. Restart OpenSesame to have the change take effect.",
    "title": "How to change the color theme in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to customize the code editor color scheme\n\nTo customize the color scheme of the code editor in OpenSesame:\n\n1. Go to Menu \u2192 Tools \u2192 Preferences.\n2. In the Preferences window, select the 'Common settings' tab.\n3. Under 'Code editor: Appearance', click on the 'Color scheme' dropdown menu.\n4. Choose your desired color scheme from the available options.\n5. Restart OpenSesame to have the change take effect.\n6. If you want to revert to the default color scheme, select 'monokai' from the 'Color scheme' dropdown menu and click 'OK'.",
    "title": "How to customize the code editor color scheme",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to draw a circle using PsychoPy\n\nTo draw a circle using PsychoPy:\n\n1. In the experiment properties of OpenSesame, under 'Run experiment', select 'On the desktop with PsychoPy (psycho)'.\n2. Insert an inline_script into your experiment. The code below should go in this inline_script.\n3. Import the necessary modules (e.g., `from psychopy import visual`).\n4. In OpenSesame, the window object is available as the global `win` variable. Therefore, you don't need to explicitly create a window object.\n5. Create a `Circle` object using `visual.Circle()`, specifying the `win` object as the first argument. Note that this is a different object from the built-in OpenSesame `Circle` object.\n6. Set the `size` parameter of the `Circle` object to the desired diameter in pixels (e.g., `circle.size = (100, 100)` for a circle with a diameter of 100 pixels).\n7. Optionally, set other parameters such as `pos`, `fillColor`, and `lineColor` to customize the appearance and position of the circle.\n8. Use the `draw()` method of the `Circle` object to draw the circle on the window (e.g., `circle.draw()`).\n9. Update the window to display the circle (e.g., `win.flip()`).\n\nExample:\n\n```python\nfrom psychopy import visual\n\ncircle = visual.Circle(win)\ncircle.size = (100, 100)\ncircle.fillColor = 'red'\ncircle.draw()\nwin.flip()\n```",
    "title": "How to draw a circle using PsychoPy",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to abort an OpenSesame experiment\n\nThere are two ways to abort an OpenSesame experiment while it is running. To gently abort the experiment:\n\n1. Press the `Escape` key to pause the experiment. A confirmation prompt will appear.\n2. Press the `q` key to confirm quitting the experiment. \n3. The experiment process will cleanly exit and you will return to the OpenSesame window.\n\nTo kill the experiment process, for example when it is unresponsive:\n\n1. Switch to the OpenSesame window.\n2. Click on the icon marked 'Forcibly kill the experiment' in the main toolbar.\n3. The experiment process will now be killed.",
    "title": "How to abort an OpenSesame experiment",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to create a basic experiment structure in OpenSesame\n\nTo create a basic experiment structure in OpenSesame:\n\n1. Create a new experiment and add a loop item to the main sequence, which is generally called 'experiment'.\n2. Rename the new loop item to 'block_loop' to indicate that it corresponds to a block of trials.\n3. Add a sequence item as the item to run for the block_loop.\n4. Rename the new sequence to 'trial_sequence' to indicate that it corresponds to a single trial.\n2. Within the trial sequence item, add sketchpad items for each visual stimulus display of your trial (e.g., baseline, fixation, emotion induction, instruction, emotion regulation, black screen, relax, and rating).\n3. Adjust the duration of each sketchpad item according to your experimental design.\n4. Add a keyboard_response item after the display that participants should respond to.",
    "title": "How to create a basic experiment structure in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to present images randomly in OpenSesame\n\nTo present images randomly in OpenSesame:\n\n1. Create a loop item and add a list of image file names as rows to a column of the loop table called 'image_file'\n2. In the loop item's properties, set the \"Order\" to \"random\".\n3. Create a sketchpad item within the loop and add an image element to it.\n4. Add the script of the image element, and set the \"file\" keywowrd to \"{image_file}\": `file=\"{image_file}\"'. The curly braces indicate that image_file is a Python expression that refers to the variable `image_file`.\n5. Each iteration of the loop will now display a randomly selected image from your list.",
    "title": "How to present images randomly in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to implement different instructions based on trial conditions\n\nTo implement different instructions based on trial conditions:\n\n1. Decide whether you want to vary the instruction from trial to trial, in which case the instructions below relate to the block_loop and the trial_sequence (assuming that you named your items following the standard OpenSesame naming conventions); or from block to block, in which case the instructions below relate to the experimental_loop and block_sequence.\n1. In your loop table, create a column called `instruction_text` that contains the text that should be presented as instruction to the participant (e.g., \"maintain\" or \"decrease\").\n2. Add a sketchpad item for the instruction screen to the start of the sequence.\n3. Add a text element to the instruction sketchpad to show the text \"{instruction_text}\".\n4. The curly braces indicate that instruction_text is a Python expression that refers to the variable `instruction_text`.\n5. OpenSesame will now display the appropriate instruction for each trial or each block based on the value in the loop table.",
    "title": "How to implement different instructions based on trial conditions",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to create a rating scale in OpenSesame\n\nOpenSesame does not contain a rating scale by default, but it is easy to implement one.\n\nHow to create a rating scale using a form_multiple_choice item:\n\n1. Add a form_multiple_coice item to your experiment.\n2. Make sure that 'Allow multiple options to be selected' is disabled.\n3. Add each rating option as a separate line in the options field at the bottom of the controls.\n\nHow to create a rating scale using a sketchpad item:\n\n1. Design the rating scale using one sketchpad element, called 'rating_sketchpad', for each clickable option. For example, you could use five filled circles or five images of a star to create five-point likert scale.\n2. Give each clickable element a unique name, such as 'rating1', 'rating2', etc.\n3. After rating_sketchpad, insert a mouse_response.\n4. In the mouse_response, select rating_sketchpad as 'Linked sketchpad'.\n5. The clicked option will now be available through the `cursor_roi` variable.\n6. To let the experiment continue only when participants have clicked on an option (and not the background, for example), put the mouse_response in a loop that breaks only when an option was clicked, for example with a break-if expression: `'cursor_roi.startswith('rating')`.",
    "title": "How to create a rating scale in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to set the size of a Canvas in OpenSesame\n\nYou cannot change the size of a Canvas in OpenSesame, because a Canvas always covers the entire window, the size of which is determined by the resolution of the experiment. However, you can change the resolution of the experiment as follows:\n\n1. Open the Experiment Properties by clicking on the top-level element of the overview area.\n2. Change the resolution (width and height) to the desired dimension.\n3. The resolution will available as the `width` and `height` variables.\n\nImportant note: when running the experiment full-screen, the resolution of the experiment means something different depending on the selected backend:\n\n- When you have selected 'On the desktop with PsychoPy (psycho)' or 'On the desktop with Expyriment (xpyriment)', the resolution of the display is not actually changed, so it's recommended to change the experiment resolution to match the display resolution.\n- When you have selected 'On the desktop with legacy (psycho)', the resolution of the display is changed tp the experiment resolution.\n- When you have selected 'In a browser with OSWeb', the resolution determines the size of the experiment canvas that is shown in the browser window. You can experiment with different values to find out which resolution works best.",
    "title": "How to set the size of a Canvas in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to position elements on a Canvas using pixel coordinates\n\nTo position elements on a Canvas using pixel coordinates in OpenSesame:\n\n1. Create a Python INLINE_SCRIPT.\n2. In the INLINE_SCRIPT, create a Canvas object.\n3. Add the desired elements (e.g., Rectangle, Circle, Image, etc.) and specify their positions using the `x` and `y` parameters. For example:\n   ```python\n   my_canvas = Canvas()\n   my_canvas['rect'] = Rect(x=100, y=200, w=50, h=50)\n   my_canvas['circle'] = Circle(x=300, y=400, r=30)\n   my_canvas.show()\n   ```\n4. The `x` and `y` values represent the pixel coordinates relative to the center of the Canvas. Positive `x` values move the element to the right, while positive `y` values move it downward.\n5. Adjust the `x` and `y` values to position the elements at the desired locations on the Canvas.\n6. Run the experiment to verify that the elements are positioned correctly.",
    "title": "How to position elements on a Canvas using pixel coordinates",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to display an image on a Canvas\n\nTo display an image on a Canvas in OpenSesame:\n\n1. Create a Python INLINE_SCRIPT.\n2. In the INLINE_SCRIPT, create a Canvas object.\n2. Add an `Image` element to load and display the image. For example:\n   ```python\n   my_canvas = Canvas()\n   my_canvas['image'] = Image(pool['image.png'], x=0, y=0)\n   my_canvas.show()\n   ```\n   Replace `'image.png'` with the actual name of your image file, which should be placed in the file pool.\n3. Use the `x` and `y` parameters to specify the position of the image on the Canvas. The default values of `x=0` and `y=0` will center the image on the Canvas.\n4. If needed, you can adjust the size of the image using the `scale` parameter. For example:\n   ```python\n   my_canvas['image'] = Image(pool['image.png'], x=0, y=0,scale=0.5)\n   ```\n   A `scale` value of 1.0 represents the original size of the image, while values less than 1.0 will shrink the image and values greater than 1.0 will enlarge it.\n5. Run the experiment to verify that the image is displayed correctly on the Canvas.",
    "title": "How to display an image on a Canvas",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to fix psychopy.exceptions.SoundFormatError\n\nThis error is ocurring because PsychoPy does not support playing audio files with different sample rates in the same experiment. \nTo avoid the psychopy.exceptions.SoundFormatError in OpenSesame when using multiple audio files:\n\n1. Ensure all audio files have the same sample rate\n  - Use audio editing software (e.g., Audacity) to check and convert all audio files to the same sample rate (e.g., 44100 Hz).\n  - In Audacity: Open the file, then set project rate to 44100 Hz, then export the file (File > Export > WAV).\n2. Replace the old audio files by the newly converted ones in your OpenSesame experiment (pool)\n3. Check for other interfering sounds\n  - Ensure that all system-generated sounds in the experiment use the same sample rate.\n  - Synthetic beeps (e.g., from eye-tracking calibration) also count as different audio streams.",
    "title": "How to fix psychopy.exceptions.SoundFormatError",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to create a math problem verification task with additions and subtractions\n\nTo create a math problem verification task with additions and subtractions in OpenSesame:\n\n1. In the LOOP item, prepare a table with columns for the problem type (addition or subtraction), the operands, and the correct answer.\n2. Create a SEQUENCE item to represent a single trial.\n3. Inside the SEQUENCE, add a SKETCHPAD to display the math problem using the variables from the LOOP.\n4. Add a KEYBOARD_RESPONSE item to collect the participant's response.",
    "title": "How to create a math problem verification task with additions and subtractions",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to group and randomize math problems by operation type\n\nTo group and randomize math problems by operation type (addition and subtraction) in OpenSesame:\n\n1. Create a SEQUENCE item to represent a block of trials.\n2. Inside the SEQUENCE, add one LOOP item for the addition problems (*addition_loop*) and another LOOP item for the subtraction problems (*subtraction_loop*).\n3. After the *subtraction_loop*, add a linked copy of the *addition_loop* so that it occurs twice, once at the start, and once at the end of the SEQUENCE.\n4. Use `subject_parity == \"even\"` as the run-if expression for the first *addition_loop*, and `subject_parity == \"odd\"` for the second *addition_loop*. This way, the order of the LOOPs will be counterbalanced between participants.\n5. Add a SEQUENCE item inside each LOOP to represent a single trial.",
    "title": "How to group and randomize math problems by operation type",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to create trials of ascending difficulty\n\nTo create blocks of trials of ascending difficulty\n\n1. Prepare a LOOP table (*block_loop*) that defines trials of various levels of difficulty, such as math problems of different difficulty.\n2. In the LOOP table, add a column called `difficulty` that contains a numeric score for the difficulty of each trial.\n3. Add the script of the LOOP, and just before the line that contains the `run` command use the `sortby` advanced LOOP operation to sort the table by difficulty:\n    ```\n    sortby difficulty\n    ```\n4. Add a SEQUENCE (*trial_sequence*) to the LOOP, and use this to implement your trials based on the variables defined in the LOOP.",
    "title": "How to create trials of ascending difficulty",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to set up a GazePoint eye tracker in OpenSesame\n\nTo set up a GazePoint eye tracker in OpenSesame:\n\n1. Install the necessary GazePoint drivers and software on your computer.\n2. In OpenSesame, add a PYGAZE_INIT item to the start of your experiment.\n3. In the PYGAZE_INIT item properties, select \"OpenGaze\" as the eye tracker type.\n4. Configure the OpenGaze settings according to your preferences and hardware setup.\n5. Add a PYGAZE_START_RECORDING item before the trial sequence to start recording eye tracking data.\n6. Add a PYGAZE_LOG item at the end of the trial sequence to log experimental variables to the log file.\n7. Add a PYGAZE_STOP_RECORDING item after the trial sequence to stop recording eye tracking data.\n8. You can also use the 'Eye tracking template', which already contains the basic structure of an eye-tracking experiment.",
    "title": "How to set up a GazePoint eye tracker in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to display multiple images and play audio simultaneously in OpenSesame\n\nTo display multiple images and play audio simultaneously in OpenSesame:\n\n1. Create a sketchpad item and add image elements for each of the four pictures you want to display.\n2. Adjust the position and size of the image elements to arrange them on the screen as desired.\n3. Create a sampler item and specify the audio file you want to play.\n4. If you want the sketchpad to be shown when the sampler starts playing and to remain visible until the sampler is done playing, insert the sketchpad and set the duration of the sketchpad to 0, and have this followed by the sampler and set the duration of the sampler to 'sound'.",
    "title": "How to display multiple images and play audio simultaneously in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to define time windows (or: epochs, or: phases) for eye tracking analysis in OpenSesame\n\nTo define time windows (or: epochs, or: phases) for eye tracking analysis in OpenSesame:\n\n1. After each event that corresponds to the start of a time window, send a message to the eye-tracking log file.\n2. You can log messages using the PYGAZE_LOG item or in an INLINE_SCRIPT item using the `eyetracker.log()` function.\n3. Make sure that the log messages match the assumption of the analysis pipeline that you intend to use. For example, if you want to use the `eyelinkparser`, indicate the start of each phase using a 'start_phase cue' message, where cue stands for the name of the phase.",
    "title": "How to define time windows (or: epochs, or: phases) for eye tracking analysis in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to manually update OpenSesame packages\n\nOpenSesame includes an automatic updater, which starts in the background when you launch the program. It is recommended to update packages through the automatic updater. However, if you wish, you can also manually update packages as follows:\n\n1. Open the console in OpenSesame (View -> Show console).\n2. `pip` is the command to execute the standard Python packaging tool, and is always available.\n3. You can update packages using `pip` using the following command: `pip install package_name --upgrade`\n4. `conda` is the command to execute the Anaconda packaging tool, and is available if you are using the standard Windows or Mac OS packages, or if you have installed OpenSesame in a custom anaconda environment.\n5. You can update packages using `pip` using the following command: `conda update package_name`\n6. In some cases, you have to prefix the `conda` and `pip` commands with a `!` to run them in the OpenSesame console: `!conda` or `!pip`\n7. Restart OpenSesame for the updates to take effect.",
    "title": "How to manually update OpenSesame packages",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to report bugs or issues with OpenSesame\n\nTo report bugs or issues with OpenSesame:\n\n1. Go to the OpenSesame forum at https://forum.cogsci.nl/.\n2. Check if the issue has already been reported by searching the forum for relevant keywords.\n3. If the issue has not been reported, create a new discussion.\n4. Provide a clear and descriptive title for your topic.\n5. In the topic description, include details about the issue, such as the version of OpenSesame, your operating system, and any error messages.\n6. If possible, attach any relevant files, such as screenshots or log files, to help the developers understand and reproduce the issue.\n7. Submit the topic and wait for a response from the OpenSesame community or developers.",
    "title": "How to report bugs or issues with OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to set a time limit for a form in OpenSesame\n\nTo set a time limit for a form in OpenSesame:\n\n1. Add a `form_base` item to your experiment.\n2. In the form's script, add a line that specifies the timeout in milliseconds, e.g. `set timeout 3000`\n3. The form will now automatically end after the specified time limit or when the participant submits their response.",
    "title": "How to set a time limit for a form in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to determine whether responses in a form are correct\n\nUnlike KEYBOARD_RESPONSE items and other response items, forms do not automatically code whether a response was correct or not. Therefore, to accomplish this, you need to perform the following steps:\n\n1. Create a loop table with a column for the correct answers (e.g., `correct_response`).\n2. In each row of the loop table, enter the correct answer for the corresponding trial.\n3. Add a `form_base` item to your experiment and place it inside the loop.\n4. In the form's controls, add an input widget (e.g., `text_input`) for the participant's response.\n5. Set the input widget's `var` property to a unique value (e.g., `'participant_response'`).\n6. After the form is submitted, compare the participant's response (`participant_response`) with the correct answer for the current trial (`correct_answer`) using an `if` statement in the run phase of an INLINE_SCRIPT item that follows the form:\n    ```python\n    if participant_response == correct_response:\n        correct = 1\n    else:\n        correct = 0\n    ```",
    "title": "How to determine whether responses in a form are correct",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to troubleshoot an experiment that fails to open correctly\n\nWhen an experiment fails to open correctly in OpenSesame, you can take the following steps to troubleshoot the issue:\n\n1. Check that you are using the most recent version of OpenSesame. If you are using an outdated version, the experiment may not be compatible.\n2. If you are using a recent version of OpenSesame, close OpenSesame completely and then re-open the experiment.\n3. Check the debug window (View \u2192 Show console) for error messages that may indicate why the experiment is failing to open.\n5. If you still cannot get the experiment to open correctly, try downloading the experiment again. The downloaded file may have been corrupted.\n6. If problems persist, contact the original author of the experiment for further assistance.",
    "title": "How to troubleshoot an experiment that fails to open correctly",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to find help when working with OpenSesame\n\nIf you need help with OpenSesame, there are several places you can look:\n\n1. Consult the built-in help documentation by clicking the help buttons that appear throughout the interface, or by clicking Help in the main menu. This will open the documentation in your web browser.\n2. Visit the documentation website at [osdoc.cogsci.nl](https://osdoc.cogsci.nl). This site contains an extensive manual as well as several step-by-step tutorials.\n3. Watch video tutorials on the [YouTube channel](https://www.youtube.com/sebastiaanmathot). These videos cover many basic topics to help you get started with OpenSesame.\n4. Ask a question on the [OpenSesame forum](https://forum.cogsci.nl). This forum is the main place for getting personalized help with OpenSesame. Be sure to include enough details, such as a description of what you are trying to achieve, and screenshots of things that you need help with.\n5. Ask me! As an AI assistant with access to the OpenSesame documentation, I will be able to help you with many things.",
    "title": "How to find help when working with OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to share an experiment with others\n\nTo share an experiment with others, so that they can run and/ or inspect the experiment themselves, you can take the following steps:\n\n1. In OpenSesame, open the experiment that you would like to share.\n2. Make sure that the experiment contains no sensitive information, such as participant data.\n3. Save the experiment and close it.\n4. Locate the experiment file (`.osexp`) on your computer.\n5. Upload this file to a file sharing service, such as Google Drive, Dropbox, or the Open Science Framework (OSF).\n6. Once the upload is complete, make sure that the file is shared with the intended recipients.\n7. Send the download link to the people with whom you want to share the experiment.\n8. The recipients can then download the experiment and open it in their own copy of OpenSesame.",
    "title": "How to share an experiment with others",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to import (open) an experiment into OpenSesame\n\nTo import (open) an experiment into OpenSesame, for example an experiment that someone else has shared with you, take the following steps:\n\n1. Download the experiment file, which should have the `.osexp` extension, to your computer.\n2. Launch OpenSesame.\n3. In the menu, click on File \u2192 Open and browse to the location where you have downloaded the `.osexp` file.\n4. Select the `.osexp` file and click on 'Open'.\n5. The downloaded experiment will now open in OpenSesame.",
    "title": "How to import (open) an experiment into OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to get the coordinates of the last character in a Text element\n\nTo get the coordinates of the last character in a Text element:\n\n1. Create a Text element on your canvas with the desired sentence except for the last character. So if you want the coordinates of the 'i' in 'sigmundai', you would use the string 'sigmunda'.\n2. Use the `boundingbox` property of the Text element to get the bounding box of the entire text string. The bounding box is a tuple of four values: (left, top, right, bottom).\n3. The x-coordinate of the last character (i.e. the 'i' in this example) will be approximately equal to the `right` value of the bounding box.\n4. To get the y-coordinate of the last character, you can use the `top` or `bottom` value of the bounding box, depending on whether you want the coordinate of the top or bottom of the character.\n5. If needed, you can adjust the x-coordinate by subtracting a small value to account for any padding on the right side of the text.\n\n```python\nmy_text = 'sigmundai'\nmy_canvas = Canvas()\nmy_canvas['sentence'] = Text(my_text[:-1])\nbbox = my_canvas['sentence'].rect  # important: not bounding_box\nlast_char_x = bbox[2]  # right coordinate of the bounding box\nlast_char_y = bbox[1]  # top coordinate of the bounding box\n```",
    "title": "How to get the coordinates of the last character in a Text element",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to calculate the width of a Text element\n\nTo calculate the width of a Text element:\n\n1. Create a Canvas object.\n3. Calculate the width of a text (without rendering it) using the `text_size()` function.\n\n```python\nmy_text = 'sigmundai'\nmy_canvas = Canvas()\nwidth, height = my_canvas.text_size(my_text)\n```",
    "title": "How to calculate the width of a Text element",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to adjust the position of a Text element based on its length\n\nTo adjust the position of a Text element based on its length:\n\n1. Create a Text element on your canvas with the desired sentence.\n2. Use the `boundingbox` property of the Text element to get the bounding box of the entire text string.\n3. Calculate the width of the Text element by subtracting the `left` value from the `right` value of the bounding box.\n4. Set the `x` property of the Text element to the negative half of the text width to center the text horizontally on the canvas.\n5. If needed, you can also adjust the `y` property of the Text element to vertically position the text as desired.\n\n```python\nmy_text = 'sigmundai'\nmy_canvas = Canvas()\nmy_canvas['sentence'] = Text(my_text[:-1], center=False)\nbbox = my_canvas['sentence'].rect  # important: not bounding_box\ntext_width = bbox[2] - bbox[0]  # right - left\nmy_canvas['sentence'].x = -text_width # move the text left so that it runs until the center of the screen\nmy_canvas['sentence'].y = 0  # set the vertical position as needed\n```",
    "title": "How to adjust the position of a Text element based on its length",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to define and use a class in an OpenSesame inline_script\n\nClasses in OpenSesame inline_script work the same way as classes in regular Python. To define a class in an inline_script:\n\n1. Add an `inline_script` item to your experiment.\n2. In the `inline_script`, define your class using the `class` keyword followed by the class name (e.g., `class MyClass:`).\n3. Inside the class definition, create an `__init__` method to initialize the class's attributes (e.g., `def __init__(self, attribute1, attribute2):`).\n4. Define any additional methods within the class that perform specific actions or calculations.\n5. Outside the class definition, create an instance of the class by calling the class name and passing any required arguments (e.g., `my_instance = MyClass(arg1, arg2)`).\n6. Use the instance to access the class's attributes and methods (e.g., `my_instance.attribute1`, `my_instance.method()`).\n7. Defining classes in inline_scripts can help organize and modularize your code, making it easier to maintain and reuse.",
    "title": "How to define and use a class in an OpenSesame inline_script",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to use a response in a run-if expression\n\nTo use a response collected in a KEYBOARD_RESPONSE item in a run-if expression to select which item is run:\n\n1. In a SEQUENCE item, set the run-if expression of one child item to `response == 'left'` to execute it only if the left arrow was pressed.  \n2. Set the run-if statement of another child item to `response == 'right'` to execute it only if the right arrow was pressed.\n3. Run-if expressions should be valid Python expressions.",
    "title": "How to use a response in a run-if expression",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to use JavaScript code in an OSWeb experiment\n\nTo use JavaScript code in an experiment running in OSWeb:\n\n1. Insert an INLINE_JAVASCRIPT item into your experiment\n2. For code that needs to be executed during preparation (for example the preparation of a trial in the case of a trial SEQUENCE), use the 'Prepare' phase\n3. For code that needs to be executed during executing, use the 'Run' phase\n4. Avoid naming conflicts with variables defined in the other parts of the experiment\n5. Global variables from INLINE_JAVASCRIPT items are also available in the user interface, for example in run-if expressions\n6. Variables from the user interface, for example response variables, are available as global variables in INLINE_JAVASCRIPT items",
    "title": "How to use JavaScript code in an OSWeb experiment",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to show a form with image and text input in OSWeb\n\nTo create a recall trial where an image is shown and the participant types in a response in OSWeb, you can use an INLINE_HTML item with the following code:\n\n\n```html\n<input type='text' name='text_response'>\n<img id='my_image_element'>\n<input type='submit' value='ok'>\n\n<script>\n// Assume that the variable `my_image` defines the name of the image in the file pool\ndocument.getElementById('my_image_element').src = pool[my_image].data.src\n</script>\n```",
    "title": "How to show a form with image and text input in OSWeb",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to run an experiment in a web browser using OSWeb\n\nTo run an experiment in a web browser using OSWeb, follow these steps:\n\n1. Open the Experiment Properties and select 'In a browser with OSWeb (osweb)' in the 'Run experiment' section.\n2. Click any of the 'Run' buttons to start the experiment.\n3. If the experiment is not compatible with OSWeb, an error message will appear that details the compatibility issues. \n4. If there are no compatibility issues, the experiment will open in a new browser window. Note that even though the experiment is running in a web browser, it is still executing locally on your own computer.\n5. When the experiment is finished, the data will be downloaded in `.json` format. This data file can then be converted to `.xlsx` or `.csv` format for further analysis.",
    "title": "How to run an experiment in a web browser using OSWeb",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to access the OSWeb control panel\n\nFor more control over OSWeb experiments, you can access the OSWeb and JATOS control panel:\n\n1. Click on the Tools menu\n2. Select 'OSWeb and JATOS control panel'\n3. The OSWeb and JATOS control panel will appear, offering configuration options such as: \n   - Possible subject numbers when running in JATOS\n   - Enabling fullscreen mode \n   - Showing the OSWeb welcome screen\n   - Bypassing compatibility checks\n   - Customizing welcome text\n   - Specifying external JavaScript libraries to load",
    "title": "How to access the OSWeb control panel",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to host an experiment online using JATOS / MindProbe\n\nTo host an experiment online so that it can be run by participants, you need to publish it to JATOS:\n\n1. In OpenSesame, open your experiment and check that it is compatible with OSWeb \n2. In the OSWeb and JATOS control panel, configure your JATOS server (such as https://jatos.mindprobe.eu) and your API token, which you can generate by logging into your JATOS server in a web browser.\n3. In the OpenSesame menu, select 'Save and publish to JATOS' (or 'Save and publish to MindProbe' depending on which server you have configured).\n4. Your experiment will now be uploaded to your JATOS server.\n9. Once uploaded, you can generate links by logging into your JATOS server in a web browser to allow participants to run your experiment in a web browser\n\nAlternatively, you can export the experiment to a JATOS archive (jzip) using the OSWeb and JATOS control panel, and import this archive through the JATOS server.",
    "title": "How to host an experiment online using JATOS / MindProbe",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to download an experiment from JATOS / MindProbe\n\n2. In the OSWeb and JATOS control panel, configure your JATOS server (such as https://jatos.mindprobe.eu) and your API token, which you can generate by logging into your JATOS server in a web browser.\n3. In the OpenSesame menu, select 'Open from JATOS' (or 'Open from MindProbe' depending on which server you have configured).\n4. Select an experiment from the list that appears.\n5. The experiment will now be downloaded from your JATOS server.\n6. Once downloaded, the experiment will be opened in OpenSesame.\n\nAlternatively, you can export the experiment from the JATOS server, and import it as a JATOS archive (jzip) using the OSWeb and JATOS control panel.",
    "title": "How to download an experiment from JATOS / MindProbe",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to set up response keys in OpenSesame\n\nTo set up response keys in OpenSesame:\n\n1. Create a keyboard_response item in your experiment.\n2. In the keyboard_response item properties, specify the allowed keys in the \"Allowed responses\" field (e.g., 'z;/').\n3. Set the timeout duration in the \"Timeout\" field to limit the response window (e.g., '2500' for 2500ms).\n4. Add the keyboard_response item to your trial sequence.\n5. Run your experiment and test if the response keys are working as expected.",
    "title": "How to set up response keys in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to debug response key issues in OpenSesame\n\nTo debug response key issues in OpenSesame:\n\n1. Double-check that the response keys are correctly specified in the keyboard_response item properties.\n2. Ensure that the keys are not mapped to any other functions or shortcuts in your operating system or other software.\n3. Test your experiment with different response keys to isolate the issue.\n4. Print the values of response variables (e.g., 'response', 'response_time') to the debug window, or monitor them in the Variable explorer, to monitor their values during the experiment.\n5. Check the console for any error messages related to the keyboard_response item or response handling.",
    "title": "How to debug response key issues in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to use audio stimuli in OpenSesame\n\nTo use audio stimuli in OpenSesame:\n\n1. Import your audio files into the file pool.\n2. Create a sampler item in your experiment.\n3. In the sampler item properties, select the audio file from the file pool.\n4. Set the duration and other playback settings for the audio stimulus.\n5. If you want participants to press a key in response to the sound, add a keyboard_response item after the sampler item in the trial sequence.",
    "title": "How to use audio stimuli in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to troubleshoot timing issues in OpenSesame\n\nTo troubleshoot timing issues in OpenSesame:\n\n1. Close any unnecessary background applications that may interfere with the timing of your experiment.\n2. Use a high-precision backend, such as 'psycho', for better timing accuracy.\n3. Record the actual timing of events and compare them with the expected timing. You can do this with the `clock.time()` function `inline_script` items or by relying on onset time variables that are automatically created by OpenSesame. For example, the onset time of a sketchpad called 'target' is stored as the variable 'time_target'.",
    "title": "How to troubleshoot timing issues in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to play a video file for a random duration in OpenSesame\n\nTo play a video file for a randomly selected duration in OpenSesame:\n\n1. In an INLINE_SCRIPT item, create a list of possible durations, e.g., `durations = [300, 350, 400, 450, 500]`\n2. Use `random.choice(durations)` to randomly select a duration from the list and store it in a variable, e.g., `video_duration = random.choice(durations)`\n3. In the MEDIA_PLAYER_MPY item, set the duration field to `{video_duration}`",
    "title": "How to play a video file for a random duration in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to optimize video playback performance in OpenSesame\n\nTo optimize video playback performance in OpenSesame:\n\n1. Ensure that your video files are in a format that is well-supported by the video backend you are using (e.g., `.mp4` for the `mpy` backend)\n2. Compress your video files to reduce their file size while maintaining acceptable quality, using tools like FFmpeg or Handbrake\n3. Use a reasonable frame rate for your videos (e.g., 30 fps) to balance smoothness and performance\n4. If possible, use a smaller video resolution to reduce the processing load on the computer",
    "title": "How to optimize video playback performance in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to randomly select images and videos in OpenSesame\n\nTo randomly select images and videos in OpenSesame:\n\n1. In an INLINE_SCRIPT item, create separate lists for your image and video files, e.g., `images = [\"image1.png\", \"image2.png\", \"image3.png\"]` and `videos = [\"video1.mp4\", \"video2.mp4\", \"video3.mp4\"]`\n2. Use `random.choice(images)` to randomly select an image file from the `images` list and store it in a variable, e.g., `selected_image = random.choice(images)`\n3. Similarly, use `random.choice(videos)` to randomly select a video file from the `videos` list and store it in a variable, e.g., `selected_video = random.choice(videos)`\n4. In a SKETCHPAD item, set the image source to the `{selected_image}` variable to display the randomly chosen image\n5. In the MEDIA_PLAYER_MPY item, set the video source to the `{selected_video}` variable to play the randomly chosen video",
    "title": "How to randomly select images and videos in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to update packages in OpenSesame\n\nTo update OpenSesame, take the following steps:\n\n1. Launch OpenSesame. An automatic updater will starting checking for updates in the background. This may take a few minutes.\n2. If no updates are available, nothing will happen.\n3. If updates are available, a green update button marked \"Install updates \u2026\" will appear in the main toolbar.\n3. Click the green update button to open the automatic updater.\n4. Within the automatic updater, review the script that indicates which packages will be updated. If necessary, modify the script.\n5. Click the 'Run update script' button to perform the updates. The updates will be executed in the OpenSesame console.\n6. Once the updates have been completed, restart OpenSesame.",
    "title": "How to update packages in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to create an animated Canvas with Python inline_script\n\nTo create an animated Canvas with Python inline_script, you can dynamically update the properties of Canvas elements in between subsequent calls to `show()`. For example, to create an animation of a moving circle, you could use the following script:\n\n```python\nanimated_canvas = Canvas()\nanimated_canvas['circle'] = Circle(x=-100, y=0, r=10)\nfor x in range(-100, 101):\n    animated_canvas['circle'].x = x\n    animated_canvas.show()\n    clock.sleep(10)\n```",
    "title": "How to create an animated Canvas with Python inline_script",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to avoid the last display of a trial from being shown for too long\n\nIf a visual stimulus is shown at the end of a trial, it is not automatically removed when the trial ends. Rather, it stays on the screen until a new display is shown at the start of the next trial, which due to intertrial preparation time may take a while. As a result, if a trial ends with a KEYBOARD_RESPONSE, the experiment can seem not react to the key press. To avoid this, simply add a blank SKETCHPAD at the end of the trial. This will ensure that the trial ends with a blank display, and avoid the experiment from feeling sluggish or delayed to the participantl.",
    "title": "How to avoid the last display of a trial from being shown for too long",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to register key presses continuously while presenting a series of sketchpad items\n\nIf you want to register key pressed continuously, while at the same presenting a series of sketchpad items, you need to use a `coroutines` item. This allows you to run multiple items (seemingly) in parallel. For example:\n\n1. Insert a `coroutines` item into the trial sequence.\n2. Set the duration of the `coroutines`, for example to 5000 ms.\n3. Add a `keyboard_response` to the `coroutines` and let it run for the entire duration of the `coroutines` by setting the start time to 0 and the end time to 5000 ms.\n4. Add multiple `sketchpad` items to the `coroutines` and use the start times for these items to show them at the appropriate moments.",
    "title": "How to register key presses continuously while presenting a series of sketchpad items",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to create a Run-Only File in OpenSesame\n\nIn some cases, you want to provide participants with a file that they can execute directly in order to start the experiment. There are a few ways to do this:\n\n- Export the experiment to HTML using the OSWeb and JATOS control panel. This will generate a single HTML file that participants can double-click to launch it in a browser. This requires that the experiment is compatible with OSWeb.\n- Create a Windows batch file that uses opensesamerun to launch the experiment directly. This requires that the participant is running Windows. The best way to do this is to create your own version of the 'no installation required' `zip` package of OpenSesame, and include the batch file in this package.\n   ```\n    opensesamerun your_experiment.osexp -s 1 -l your-logfile.csv -f\n   ```\n- Create a Python script that launches the experiment directly using OpenSesame as a Python module. This requires a Python environment with OpenSesame installed, and a way to easily launch the Python script.\n   ```\n    from libopensesame.python_workspace_api import Experiment\n    exp, win, clock, log = Experiment(osexp_path='my_experiment.osexp', subject_nr=2)\n    exp.run()\n    ```\n\nIn all cases, provide clear instructions to the participant on how they can launch the experiment!",
    "title": "How to create a Run-Only File in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to run OpenSesame on Windows 7\n\nThe last version of Python to support Windows 7 was Python 3.8. Because the OpenSesame packages for Windows are built using Python 3.11, they do not run on Windows 7. To run OpenSesame on Windows 7:\n\n- Download the last version of Anaconda (2019.10) that supports Windows 7 from here: <https://docs.anaconda.com/free/anaconda/install/old-os/>\n- In Anaconda, create a Python 3.8 environment:\n    ```\n    conda create -n opensesame_py38 python=3.8\n    ```\n- Inside this Anaconda environment, install OpenSesame as explained on the download page: <https://osdoc.cogsci.nl/4.0/download/#anaconda-cross-platform>\n- You can now start OpenSesame from this Anaconda environment.",
    "title": "How to run OpenSesame on Windows 7",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to give feedback on the participant's accuracy\n\nUnderstanding the meaning of the variables `acc`, `accuracy`, `correct`, and `correct_response`:\n\n- The correct response is stored in the variable `correct_response`. This variable needs to be defined in the experiment, for example in the table of the BLOCK_LOOP, and contains for example the name of the key that the participant is supposed to press on a trial. If `correct_response` is defined, response items such as the KEYBOARD_RESPONSE, will automatically determine whether a response is correct.\n- The participant's accuracy is stored in the variable `acc` and `accuracy` (which are aliases) as a percentage value between 0 and 100.\n- The participant's accuracy is a running average since the last reset of feedback variables.\n- Feedback variables can be reset by the FEEDBACK and RESET_FEEDBACK items.\n- The correctness of the participant's last response is stored as the variable `correct` as 1 (correct) or 0 (incorrect).\n\nTo provide feedback on the participant's accuracy (percentage correct) after several trials:\n\n- Add a RESET_FEEDBACK item at the point from which you want to provide feedback. This can for example be at the start of each block, as the first item in the *block_sequence*, in case you want to provide feedback per block.\n- At the end of each block, add a FEEDBACK item with the text: `Your accuracy was {acc}%`.\n\nTo provide feedback on the participant's correctness (correct vs incorrect) after each trial:\n\n- Add two SKETCHPAD items to the end of the *trial_sequence*.\n- Rename one SKETCHPAD to *correct_sketchpad* and add content that you want to show after a correct response, such as a green fixation dot.\n- Rename the other SKETCHPAD to *incorrect_sketchpad* and add content that you want to show after an error, such as a red fixation dot.\n- In the *trial_sequence*, use run-if expressions to show the correct SKETCHPAD depending on the participants response. For *correct_sketchpad* this should be `correct == 1`. For *incorrect_sketchpad* this should be `correct == 0`.",
    "title": "How to give feedback on the participant's accuracy",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to log variables that are defined in a Python INLINE_SCRIPT item\n\nThe LOGGER item determines which variables are logged the first time that it is executed. The LOGGER cannot automatically detect variables that will be defined later on in a Python INLINE_SCRIPT. Therefore, if you define a new variable in a Python INLINE_SCRIPT item after a LOGGER item has already been executed, this new variable will not be included in the log file. To work around this, you can add an initializing script to the start of the experiment and already assign a dummy value to the variable there, so that the LOGGER will be aware that the variable exists:\n    ```python\n    my_future_variable = 'some dummy value'\n    ```",
    "title": "How to log variables that are defined in a Python INLINE_SCRIPT item",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to change the language in OpenSesame\n\nTo change the language of the user interface in OpenSesame:\n\n1. Go to Menu \u2192 Tools \u2192 Preferences.\n2. In the Preferences window, select the 'Common settings' tab.\n3. In the section 'Application appearance', under 'Language', choose your desired language from the dropdown menu.\n4. The '[Default]' language corresponds to the language of the operating system.\n5. Restart OpenSesame to have the change take effect.",
    "title": "How to change the language in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to debug errors when running an experiment in a browser with OSWeb\n\nWhen an OSWeb experiment doesn't run as expected, there are a few things that you can do:\n\n1. Make sure that you are running the latest versions of OpenSesame and OSWeb. OpenSesame 4 has an automatic updater, which will notify you of any available updates. This notification may take a few minutes to appear after you have started OpenSesame.\n2. Check for error messages in the browser console. See also: <https://osdoc.cogsci.nl/4.0/manual/debugging/>\n3. Make sure that your experiment is compatible with OSWeb. See also: <https://osdoc.cogsci.nl/4.0/manual/osweb/osweb/>",
    "title": "How to debug errors when running an experiment in a browser with OSWeb",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to give feedback by showing an image after a response, with the specific image depending on which key was pressed\n\nTo provide feedback by showing an image after a response:\n\n1. Insert a KEYBOARD_RESPONSE item in the *trial_sequence* to collect a key press.\n2. In the \"Allowed responses\" field of the KEYBOARD_RESPONSE, specify which keys should be accepted. This should be a semicolon-separated list, for example \"left;right\".\n3. After the KEYBOARD_RESPONSE, insert one SKETCHPAD item for each feedback image that might be presented. For example, you might create a *left_sketchpad* item that shows the image `left_feedback.png`, and a *right_sketchpad* item that shows the image `right_feedback.png`. The image files should be in the file pool.\n4. In the *trial_sequence*, use Run-If expressions to determine which item should be run on a given trial: `response == \"left\"` for *left_sketchpad* and `response == \"right\"` for *right_sketchpad*. The `response` variable is automatically set by the KEYBOARD_RESPONSE item.",
    "title": "How to give feedback by showing an image after a response, with the specific image depending on which key was pressed",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to use a pandas DataFrame for the loop table\n\nThe data structure used by LOOP items is a DataMatrix, which is an alternative to pandas DataFrame and a bit more light-weight and intuitive. If you want to use a pandas DataFrame to populate a LOOP table, you first need to convert it to a DataMatrix, and then assign it to the `dm` property of the LOOP item. You need to do this in the Prepare phase of an INLINE_SCRIPT that comes before the LOOP item that it modifies.\n\n```python\nimport pandas as pd\nfrom datamatrix import convert as cnv\n\n# Create a dummy DataFrame with two rows and one column called `cond`\ndf = pd.DataFrame(data=dict(cond=['a', 'b']))\n# Convert the DataFrame to a DataMatrix and assign it to the loop table of\n# the block_loop item\nitems['block_loop'].dm = cnv.from_pandas(df)\n```",
    "title": "How to use a pandas DataFrame for the loop table",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to fix a blank screen or \"Your browser does not support WebGL\" message when starting an OSWeb experiment in a browser\n\nOSWeb requires WebGL, which is a technology for rendering visual stimuli in a browser. If your browser or operating system does not support WebGL, the experiment will not run. Usually, you will see an error message stating that \"Your browser does not support WebGL\". Sometimes you will simply see a blank screen, in which case you can check the browser console for specific error messages.",
    "title": "How to fix a blank screen or \"Your browser does not support WebGL\" message when starting an OSWeb experiment in a browser",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to convert Python inline_script to inline_javascript for OSWeb\n\nWhen converting Python inline_script from a lab-based experiment to inline_javascript for an OSWeb experiment in a browser, a few things are important:\n\n- Certain classes objects and objects are not available in inline_jascript. Specifically, there is no javascript equivalent of `Keyboard`, `Mouse`, `Sampler`, and `clock`. Therefore, equivalent GUI items must be used instead. For example, you cannot Python inline_script that uses a Keyboard object to an inline_javascript object; instead, you have to use the KEYBOARD_RESPONSE item in the GUI.\n- JavaScript is asynchronous, which means it is not possible to implement function calls that block or pause execution.",
    "title": "How to convert Python inline_script to inline_javascript for OSWeb",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to run an OSWeb experiment without an internet connection\n\nOSWeb experiments are typically run online using a JATOS server such as MindProbe.eu. However, it is also possible to run an OSWeb experiment without an internet connection (offline):\n\n- Make sure that the experiment is compatible with OSWeb\n- Open Menu -> Tools -> OSWeb and JATOS control panel\n- Click 'Export to HTML'\n- Save the resulting HTML file somewhere\n- Open the HTML experiment file in a browser to start it\n- When the experiment is done, the data will appear as a download in the browser",
    "title": "How to run an OSWeb experiment without an internet connection",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to pass variables as URL parameters to an OSWeb experiment\n\nYou can pass variables to an OSWeb experiment that runs online in a browser as URL parameters. If the experiment is hosted on a JATOS server, the parameter is available in `jaros.urlQueryParameters`. If the experiment is running as a standalone HTML file (e.g. during testing), the parameter is available through the `URLSearchParams` class.\n\nThe example below shows how you can get the `task` URL parameter in a way that works both when running the experiment through JATOS and when running it standalone.\n\n```js\n// Check if the task was passed a url parameter through JATOS\nif ((typeof jatos !== 'undefined') && ('task' in jatos.urlQueryParameters)) {\n    task = Number(jatos.urlQueryParameters['task'])\n    console.log(`task ${task} was specified as a JATOS URL query`)\n// Else check if it was passed as a regular parameter (for testing)\n// and fall back to 0 if no parameter was specified.\n} else {\n    const urlParams = new URLSearchParams(window.location.search)\n    task = Number(urlParams.get('task') || 0)\n    if (task === 0) {\n        console.log('no task was specified')\n    } else {\n        console.log(`task ${task} was specified as a regular URL query`)\n    }\n}\n```",
    "title": "How to pass variables as URL parameters to an OSWeb experiment",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to pass variables from an OSWeb experiment to another URL\n\nIf you are hosting an OSWeb experiment on a JATOS server, you can specify an end-redirect URL. This URL is a link that is opened when the experiment is successfully completed. This is generally used to communicate to a participant platform such as Prolific, MTurk, or Sona Systems that the participant has completed the experiment. You can also include URL parameters in this link like this: `https://endredirect.url/?task=[task]`. In this example, `task` is assumed to be a URL query parameter that was passed to JATOS when the experiment was launched, and is automatically included in the end-redirect url.",
    "title": "How to pass variables from an OSWeb experiment to another URL",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to draw onto a SKETCHPAD's Canvas using INLINE_JAVASCRIPT in OSWeb\n\nEach SKETCHPAD in OSWeb has a canvas property. It is possible to draw onto this using INLINE_JAVASCRIPT. However, this requires hacking into the OSWeb internals. So this may break in the future, and you should only do this if any other solution is impractical!\n\nThe trick is to create an empty Canvas in an inline_javascript item, and then change it's internal _canvas property to the canvas of a sketchpad . You would need to do this after the sketchpad has been prepared, but before it has actually been shown. Here's the general idea (using the canvas from *my_sketchpad*):\n\n```js\nsketchpadItem = 'my_sketchpad'  \\\\ the name of the sketchpad item\nmyCanvas = Canvas()\nmyCanvas._canvas = runner._itemStore._items[sketchpadItem].canvas\nmyCanvas.text({'text': 'Some additional text!'})\n```",
    "title": "How to draw onto a SKETCHPAD's Canvas using INLINE_JAVASCRIPT in OSWeb",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to make sure that whitespace is taken into account when calculating text size\n\nWhitespace at the end or start of a text string is not normally taken into account when calculating text size, because the size is based on the visible part of the text. \n\nA trick to work around this is by using a visible character, and then give this character the color of the background. For example, the text string below would appear as though there is a space between 'before' and 'after', altough really it's an underscore that's not visible because it has the background color. The main reason to do this is to make sure that trailing or starting whitespace is taken into account when calculating the text size.\n\n```\nbefore<span style=\"color:{background};\">_</span>after\n```",
    "title": "How to make sure that whitespace is taken into account when calculating text size",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to fix problems when trying to update packages using conda\n\nThe automatic updater generates a `conda` command to update a selection of relevant packages. You can also manually use `conda` to update packages in the OpenSesame environment, which is really an Anaconda environment. If problems occurs during updating, then this may happen for a number of reasons. For example, the Anaconda environment may be corrupted, or there may be dependency issues (conflicts) between packages. Points to consider:\n\n- `conda` often recommends updating `conda` itself. If update problems only happens when you try to manually update the `conda` package itself, then you can usually ignore this. There is usually no reason to update `conda` itself.\n- If update problems also happen when you try to perform the update script that is suggested by the automatic updater of OpenSesame itself, then that's problematic because you won't be able to update important packages. In that case, you can consider redownloading OpenSesame so that you can start from a clean environment.\n- The error message often contains useful information. Including this in your question is helpful.",
    "title": "How to fix problems when trying to update packages using conda",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to check for updates\n\nIt often takes a long time before update notifications appear after starting OpenSesame. However, the updater always starts checking immediately when OpenSesame is started. The reason that it takes so long for is that conda, which manages the packages (together with pip ), is very slow. For this reason, there's no option to deliberately check for updates.",
    "title": "How to check for updates",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to add line breaks in OpenSesame text\n\nTo add line breaks in OpenSesame text:\n\n1. Open the item (e.g., sketchpad, form_text_input, etc.) where you want to add line breaks.\n2. When entering text, you can typically enter multiple lines in the text input, and line breaks will be automatically inserted.\n3. When editing the script of an item, you need to manually indicate line breaks as shown below.\n4. In the item script, locate the text field where you need to insert line breaks.\n5. To add a line break, use the HTML tag `<br>` at the point where you want the text to start on a new line.\n6. If you need multiple consecutive line breaks, use multiple `<br>` tags.\n7. Save the changes to the item.\n8. Run the experiment to verify that the line breaks appear as expected.\n\nImportant side note: When running an experiment on the desktop, long lines are automatically wrapped so that they run out of the screen. However, when running an experiment in a browser with OSWeb, this doesn't happen, and you need to explicitly indicate line breaks to avoid lines from running out of the screen.",
    "title": "How to add line breaks in OpenSesame text",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to format text in OpenSesame using HTML tags\n\nOpenSesame supports regular HTML formatting for text. To format text in OpenSesame using HTML tags:\n\n1. Identify the item (e.g., sketchpad, form_text_input, etc.) where you want to format the text.\n2. Use the appropriate HTML tags to format the text:\n   - For bold text, use `<b>text</b>`\n   - For italic text, use `<i>text</i>`\n   - For underlined text, use `<u>text</u>`\n   - For text color, use `<span style=\"color: red;\">text</span>` (replace \"red\" with the desired color)\n3. Apply the HTML tags around the text you want to format.\n4. Save the changes to the item.\n5. Run the experiment to verify that the text formatting appears as expected.",
    "title": "How to format text in OpenSesame using HTML tags",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to debug text encoding issues in OpenSesame\n\nOpenSesame assumes that text is encoded in UTF-8 format and also uses UTF-8 for the log file.\n\nIf you find that text from a file, for example a source file for a LOOP table, is incorrectly encoded (because non-ASCII characters are not shown correctly), this generally means that the file uses a different file encoding. In that case, change the character encoding of the file to UTF-8, which is something that most text editors allow you to do. \n\nSimilarly, if you open an OpenSesame log file and find that it is incorrectly encoded (because non-ASCII characters are not shown correctly), indicate in the text editor or spreadsheet that the file is encoded using UTF-8.\n\nCharacter-encoding issues are especially common on Windows, because most versions of Windows do not use UTF-8 encoding by default.",
    "title": "How to debug text encoding issues in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to create an experiment with different lists for different participants in OpenSesame\n\nTo create an experiment with multiple lists, varied per participant, in OpenSesame:\n\n1. Prepare your lists as `.csv` or `.xlsx` spreadsheets and put them in the file pool.\n2. Make sure the lists have regular names, such as `list-0.csv`, `list-1.csv`, etc.\n3. Add a LOOP item (*block_loop*) to experiment.\n4. In the LOOP, select File under Source.\n5. In the File input that now appears, indicate an expression that selects the correct list. For example, if you have four lists (0, 1, 2, 3) that you want to counterbalance based on the subject number, then you could use the following expression:\n    ```\n    list-{subject_nr % 4}.csv\n    ```\n6. Add a SEQUENCE (*trial_sequence*) to the LOOP, and use this to implement your trial.",
    "title": "How to create an experiment with different lists for different participants in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to examine the data after running an experiment online\n\nTo examine the data collected by an online experiment hosted through JATOS/ MindProbe:\n\n1. Log in to the JATOS server where the study is hosted, for example MindProbe.eu\n2. Navigate to the study and open the Study results page\n3. Click on 'Export Results' and select the file format (e.g. JATOS Results Archive or Data only)\n4. In OpenSesame, open the OSWeb and JATOS control panel, and use the convert OSWeb results to .csv/ .xlsx option\n4. Open the converted .csv / .xlsx file in a spreadsheet or text editor \n5. Each row corresponds to one variable logging operation, which is typically one trial (although that depends on the structure of your experiment)\n6. Check that all expected variables are present and have sensible values\n7. Look for missing values, unexpected repetitions, or other anomalies\n8. If data appears to be missing or incorrect, proceed to further troubleshooting",
    "title": "How to examine the data after running an experiment online",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to troubleshoot data logging issues in online experiments\n\nIf an experiment hosted online through JATOS/ MindProbe is not correctly logging data, you can troubleshoot by:\n\n1. Running the experiment locally, after enabling in OSWeb by selecting 'In a browser with OSWeb' in the experiment properties, to check for error messages in the browser console (F12)  \n2. Checking that all variables are initialized with default values at the start of the experiment \n3. Verifying that variables are set correctly in each trial, for example in an INLINE_JAVASCRIPT item\n4. Confirming that a LOGGER is executed at the end of each trial to write variables to the log \n5. Checking that no JATOS or JavaScript errors occur in the browser console when the experiment is run on JATOS\n6. Testing whether data is stored correctly if the experiment is aborted or navigated away from prematurely",
    "title": "How to troubleshoot data logging issues in online experiments",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to find Eye Trackers compatible with OpenSesame\n\nTo find Eye Trackers that are compatible with OpenSesame:\n\n1. Visit the OpenSesame website (https://osdoc.cogsci.nl/).\n2. Look for the \"Eye tracking\" category in the documentation under Manual.\n3. Review the list of Eye Trackers that are currently supported by OpenSesame. This list includes popular brands such as EyeLink, SMI, and Tobii.\n4. Check the specific models and versions of each Eye Tracker brand to ensure compatibility with your setup.\n5. If your Eye Tracker is not listed, search the OpenSesame forums or contact the developers to inquire about potential support for your specific device.",
    "title": "How to find Eye Trackers compatible with OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to set up an Eye Tracker in OpenSesame\n\nTo set up an Eye Tracker in OpenSesame:\n\n1. Ensure that your eye tracker is supported by OpenSesame.\n2. Install the required Eye Tracker drivers and software on your computer, following the manufacturer's instructions.\n3. Connect your Eye Tracker to your computer using the appropriate cables or wireless connections.\n4. Launch OpenSesame and create a new experiment or open an existing one.\n5. Add a `pygaze_init` item to your experiment sequence to initialize the Eye Tracker connection.\n6. Configure the `pygaze_init` item by selecting your Eye Tracker brand and model from the dropdown menu and specifying any additional settings (e.g., calibration type, sample rate).\n7. Add a `pygaze_calibrate` item to your experiment sequence to perform the necessary calibration procedure for your Eye Tracker.\n8. Use `pygaze_start_recording` and `pygaze_stop_recording` items to control when the Eye Tracker starts and stops collecting data during your experiment.\n9. You can also start from the \"Eye Tracking Template\", which already provides the basic structure of an eye tracking experiment.",
    "title": "How to set up an Eye Tracker in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to migrate an OpenSesame experiment from older version (3.2 or 3.3) to version 4.0\n\nTo migrate an OpenSesame experiment from an older version to version 4.0:\n\n1. Review the 4.0 release notes at: https://osdoc.cogsci.nl/4.0/notes/400/\n2. Open the experiment in OpenSesame 4.0.\n3. Review the script for any deprecated functions or syntax changes.\n4. In inline_script tiems, remove any `exp.` or `var.` prefixes before variable names. In OpenSesame 4.0, variables are globals and not properties of the `var` or `exp` object.\n5. Replace `self.sleep()` with `clock.sleep()` for pausing execution.\n6. Test the script thoroughly to ensure all functionality works as expected.\n7. Save the updated script and use it in your experiment.",
    "title": "How to migrate an OpenSesame experiment from older version (3.2 or 3.3) to version 4.0",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to replace the deprecated `self.copy_sketchpad()` function\n\nTo replace the deprecated `self.copy_sketchpad()` function:\n\n1. Identify where `self.copy_sketchpad()` is used in your script.\n2. Remove the `self.` prefix. The function is simply called `copy_sketchpad()` in recent versions of OpenSesame.\n3. Repeat this process for all occurrences of `self.copy_sketchpad()` in your script.",
    "title": "How to replace the deprecated `self.copy_sketchpad()` function",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to pause execution in OpenSesame 4.0\n\nTo pause execution in OpenSesame 4.0:\n\n\n1. Identify where you need to pause execution in your script.\n2. Use `clock.sleep()` (e.g., `clock.sleep(1000)` to pause for 1000 milliseconds, or 1 second).\n3. Ensure that the pause duration is specified in milliseconds.\n4. Use `clock.sleep()` consistently throughout your script for any pauses in execution. Do not use `self.sleep()`, which is deprecated, or `time.sleep()`, which is from the Python standard library and is not optimized for accurate timing.",
    "title": "How to pause execution in OpenSesame 4.0",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to set up an external response button box in OpenSesame\n\nThere are different kinds of response button boxes, which differ in how OpenSesame uses them.\n\n- A button box that acts as a regular keyboard can be used with the `keyboard_response` item. This is the most common. To find out what the buttons are called (e.g. 1, 2, and 3), you can create a simple experiment in which you collect a button press with a `keyboard_response` item and then show the `response` on a `feedback` item immediately after.\n- A button box that acts a serial-reponse (SR) box can be used with the `srbox` plug-in. The SRBox is an older button box that was developed by psychology software tools. Some other button boxes produced by other manufacturers are based on the `srbox` and can be used in the same way.\n- Any other type of button box. Visit the website of the manufacturer to find out whether and how you can use the button box in Python. And then use an `inline_script` to use the button box in your experiment.",
    "title": "How to set up an external response button box in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to create a spelling bee task in OpenSesame\n\nTo create a spelling bee task in OpenSesame:\n\n1. Create a block_loop item and define your word list as a variable (e.g., `word`).\n2. Add a sampler item to the trial sequence to present the word to be spelled. Set the sound file to '{word}.wav' to use the current word from the block_loop.\n3. Add a `form_text_input` item to collect the participant's response.\n4. Add an `inline_script` item to process the participant's response and check if it matches the correct spelling of the word.\n5. Add a feedback item (e.g., sketchpad or sampler) to provide feedback on the participant's performance (correct/incorrect).",
    "title": "How to create a spelling bee task in OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to use a form_text_input item to collect typed responses\n\nTo use a `form_text_input` item to collect typed responses:\n\n1. Add a `form_text_input` item to your trial sequence.\n2. In the question field, enter the question or prompt for the participant (e.g., \"Please type the word you heard:\").\n3. Set the 'Timeout' to a suitable duration (e.g., 10000 ms) or 'infinite' if you don't want a timeout.",
    "title": "How to use a form_text_input item to collect typed responses",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to compare the participant's response to the correct answer using Python inline script\n\nTo compare the participant's response to the correct answer using Python inline script:\n\n```python\nif response == correct_response:\n    feedback_msg = \"Correct!\"\n    correct = 1\nelse:\n    feedback_msg = \"Incorrect. The correct spelling is: \" + correct_response\n    correct = 0\n```\n\n1. Assume that the participant's response is stored in a variable named 'response' and the correct answer is stored in a variable named 'correct_response'.\n2. Use an if-else statement to compare the 'response' to the 'correct_response'.\n3. If the response matches the correct answer, set the feedback message to \"Correct!\" and the 'correct' variable to 1.\n4. If the response does not match the correct answer, set the feedback message to \"Incorrect. The correct spelling is: \" followed by the correct answer, and set the 'correct' variable to 0.\n5. Use the 'feedback_msg' variable in a feedback item to display the appropriate message to the participant.",
    "title": "How to compare the participant's response to the correct answer using Python inline script",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to log the participant's response, correctness, and other trial information\n\nTo log the participant's response, correctness, and other trial information:\n\n1. Add a logger item to your trial sequence, typically at the end of the trial.\n2. In the 'Include' field, specify the variables you want to log (e.g., response, correct, RT, word). Alternatively, enable 'Automatically log all variables' to log all variables without specifying them individually.\n3. The location of the log file is specified when the experiment is started.\n4. The format of the log file is a utf-8 encoded `.csv` file.",
    "title": "How to log the participant's response, correctness, and other trial information",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to provide visual feedback using a feedback item\n\nTo provide visual feedback using a feedback item:\n\n1. Add a feedback item to your trial sequence, typically after the response processing inline_script.\n2. In the feedback item, create a text element by clicking the 'Draw textline' button.\n3. Set the 'Text' field to '{feedback_msg}', assuming you have defined the feedback message elsewhere in the experiment, for example in an inline_script item.\n4. Adjust the font, size, and color of the text as desired.\n5. Set the 'Duration' of the feedback item to a suitable value (e.g., 1000 ms) to control how long the feedback is displayed.",
    "title": "How to provide visual feedback using a feedback item",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to troubleshoot OpenSesame experiments that fail to open\n\nTo troubleshoot OpenSesame experiments that fail to open:\n\n1. Check the console for specific error messages that indicate the cause of the failure.\n2. If possible, open a backup copy of the experiment from before the error occurred.\n3. Try running the experiment on a different computer or with a different version of OpenSesame to isolate the issue.",
    "title": "How to troubleshoot OpenSesame experiments that fail to open",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to create backups of OpenSesame experiments\n\nOpenSesame automatically creates backups periodically. You can find those under Tools > Open backup folder. To create additional backups of OpenSesame experiments:\n\n1. Use the \"Save as...\" option in OpenSesame to create a copy of your experiment before making significant changes.\n2. Store backup copies of your experiment on a separate storage device or cloud service for added protection.\n3. Consider using version control software like Git, the OSF, or JATOS to track changes and revert to previous versions if needed.",
    "title": "How to create backups of OpenSesame experiments",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to set up an SMI RED 500 eye tracker with OpenSesame\n\nTo set up an SMI RED 500 eye tracker with OpenSesame:\n\n1. Install the iView X SDK on a Windows computer, as it is required for the SMI RED 500 eye tracker to communicate with OpenSesame.\n2. Install OpenSesame on the same Windows computer.\n3. Install the PyGaze library in OpenSesame (it is bundled in the default window package), which will be used to interact with the iView X SDK and the SMI RED 500 eye tracker.\n4. Connect the SMI RED 500 eye tracker to the Windows computer using the appropriate cables.\n5. Launch the iView X SDK server to establish communication between the eye tracker and the computer.\n6. Use the PyGaze items within OpenSesame to calibrate the eye tracker and collect eye tracking data during your experiment.",
    "title": "How to set up an SMI RED 500 eye tracker with OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  },
  {
    "content": "# How to explore eye tracking solutions for OpenSesame\n\nTo explore eye tracking solutions for OpenSesame:\n\n1. Research eye trackers that are compatible with OpenSesame, such as EyeLink, EyeTribe, GazePoint, SMI, or Tobii.\n2. Investigate if these eye trackers have cross-platform compatibility (e.g., Windows, macOS, Linux) and if they require proprietary software.\n3. Compare the features, accuracy, and pricing of these alternative eye trackers to determine if they meet your research requirements and budget.\n4. Reach out to the OpenSesame community or the manufacturers of the eye trackers for guidance and support in integrating these devices with OpenSesame.",
    "title": "How to explore eye tracking solutions for OpenSesame",
    "topics": [
      "opensesame"
    ],
    "collection": "opensesame",
    "howto": true,
    "source": "howtos",
    "foundation": false
  }
]